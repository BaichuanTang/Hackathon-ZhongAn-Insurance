{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb  \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV  # Perforing grid search\n",
    "from sklearn.metrics import classification_report\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./hackathon_datasets/train/ClaimInfo_Training.csv') \n",
    "\n",
    "def apply_datetime(x: pd.Series):\n",
    "    return pd.to_datetime(x,format='%Y-%m-%d %H:%M:%S')\n",
    "datetime_cols=['report_date','accident_date','policy_effective_date','original_policy_effective_date','policy_expiry_date','birth_date']\n",
    "for i in datetime_cols:\n",
    "    df[i]=apply_datetime(df[i])\n",
    "\n",
    "df['birth_date']=df['birth_date'].apply(lambda x:x.year-2000)\n",
    "df['time_f1']=(df['accident_date']-df['report_date']).apply(lambda x:x.days)\n",
    "df['time_f2']=(df['policy_effective_date']-df['report_date']).apply(lambda x:x.days)\n",
    "df['time_f3']=(df['original_policy_effective_date']-df['policy_effective_date']).apply(lambda x:x.days)\n",
    "df['time_f4']=(df['policy_expiry_date']-df['policy_effective_date']).apply(lambda x:x.days)-365\n",
    "df=df.drop(['report_date','accident_date','policy_effective_date','original_policy_effective_date','policy_expiry_date'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失值处理----待完成  \n",
    "生成新特征&去除原有特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数空值 改为0\n",
    "zero_cols=['history_claimed_amount','history_paid_amount',\n",
    "           'history_inpatient_days','history_max_inpatient_days','history_inpatient_bill_amount','history_inpatient_paid_amount',\n",
    "           'history_disease_inpatient_days','history_disease_max_inpatient_days','history_disease_inpatient_bill_amount','history_disease_inpatient_paid_amount',\n",
    "           'history_outpatient_bill_amount','history_outpatient_paid_amount',\n",
    "           'history_disease_outpatient_bill_amount','history_disease_outpatient_paid_amount',\n",
    "           'last_year_inpatient_days','last_year_max_inpatient_days','last_year_inpatient_bill_amount','last_year_inpatient_paid_amount',\n",
    "          'last_year_disease_inpatient_days','last_year_disease_max_inpatient_days','last_year_disease_inpatient_bill_amount','last_year_disease_inpatient_paid_amount',\n",
    "          'last_year_outpatient_bill_amount','last_year_outpatient_paid_amount',\n",
    "          'last_year_disease_outpatient_bill_amount','last_year_disease_outpatient_paid_amount']\n",
    "\n",
    "#序列号空值 改为-1\n",
    "minus_one_cols=['history_inpatient_number','history_disease_inpatient_number','history_outpatient_number','history_disease_outpatient_number',\n",
    "                   'last_year_inpatient_number','last_year_disease_inpatient_number','last_year_outpatient_number','last_year_disease_outpatient_number']\n",
    "\n",
    "def handle_missing(df):\n",
    "    unk_cols=['report_source','accident_type','product_name','partner_name','relation_to_holder']\n",
    "    for i in unk_cols:\n",
    "        df[i]=df[i].fillna('UNK')\n",
    "        \n",
    "    #fill social_security_flag to N if NA, known as not have ssn\n",
    "    df['social_security_flag'] = df['social_security_flag'].fillna('N')\n",
    "    \n",
    "    for i in zero_cols:\n",
    "        df[i]=df[i].fillna(0)\n",
    "        \n",
    "    for i in minus_one_cols:\n",
    "        df[i]=df[i].fillna(-1)\n",
    "    #考虑将来把minus_one_cols他们独热编码 \n",
    "    return df\n",
    "\n",
    "#改成比例，注意除0\n",
    "def add_ratio(df):\n",
    "    df2=pd.DataFrame()\n",
    "    df2['ratio_f1']=df['history_paid_amount']/(df['history_claimed_amount']+0.00001)\n",
    "    df2['ratio_f2']=df['history_max_inpatient_days']/(df['history_inpatient_days']+0.00001)\n",
    "    df2['ratio_f3']=df['history_inpatient_paid_amount']/(df['history_inpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f4']=df['history_disease_max_inpatient_days']/(df['history_disease_inpatient_days']+0.00001)\n",
    "    df2['ratio_f5']=df['history_disease_inpatient_paid_amount']/(df['history_disease_inpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f6']=df['history_outpatient_paid_amount']/(df['history_outpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f7']=df['history_disease_outpatient_paid_amount']/(df['history_disease_outpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f8']=df['last_year_max_inpatient_days']/(df['last_year_inpatient_days']+0.00001)\n",
    "    df2['ratio_f9']=df['last_year_inpatient_paid_amount']/(df['last_year_inpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f10']=df['last_year_disease_max_inpatient_days']/(df['last_year_disease_inpatient_days']+0.00001)\n",
    "    df2['ratio_f11']=df['last_year_disease_inpatient_paid_amount']/(df['last_year_disease_inpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f12']=df['last_year_outpatient_paid_amount']/(df['last_year_outpatient_bill_amount']+0.00001)\n",
    "    df2['ratio_f13']=df['last_year_disease_outpatient_paid_amount']/(df['last_year_disease_outpatient_bill_amount']+0.00001)\n",
    "    return df2\n",
    "\n",
    "df=handle_missing(df)\n",
    "df2=add_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step2 在claim_billing_info表中统计每个数字的和、总次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux= pd.read_csv('./hackathon_datasets/train/ClaimBillingInfo_Training.csv') \n",
    "df_aux2= pd.read_csv('./hackathon_datasets/train/DiseaseInfo_Training.csv')\n",
    "df_aux3= pd.read_csv('./hackathon_datasets/train/MedicineFeeInfo_Training.csv')\n",
    "df_aux=df_aux.merge(df_aux2).merge(df_aux3)\n",
    "df_aux=pd.concat([df_aux.groupby(['report_no'])['billing_no'].agg(len),pd.concat([df_aux,pd.get_dummies(df_aux.charge_type),pd.get_dummies(df_aux.billing_type),pd.get_dummies(df_aux['100major_disease_flag'],prefix='major100'),pd.get_dummies(df_aux.chronic_disease_type,prefix='chronic'),pd.get_dummies(df_aux.focus_disease_inpatient_flag,prefix='focus'),pd.get_dummies(df_aux.medicine_fee_category)],axis=1).groupby(['report_no']).agg('sum'),],axis=1)\n",
    "df=df.merge(df_aux.reset_index(),'outer',on=['report_no']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还需要做的特征工程：1.把charge_type独热后也sum进来\n",
    "2.把剩下两张表也加进来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minus_one_cols OneHot化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记得加上 不平衡样本的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=df.iloc[:,2:]\n",
    "train_y=df.iloc[:,1]\n",
    "\n",
    "train_cols=train_x.columns\n",
    "\n",
    "'''\n",
    "#注意 现在用的众数填充，将来会针对填充  ---8.25update 已改\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp.fit(train_x)\n",
    "train_x_imputed=imp.transform(train_x)\n",
    "train_x=pd.DataFrame(train_x_imputed,columns=train_cols)\n",
    "'''\n",
    "\n",
    "#注意  不只是文字 还可能有其他的哑变量--后续提升\n",
    "one_hot_cols=['report_source','accident_type','relation_to_reporter','product_name','partner_name','relation_to_holder','renewal_flag','social_security_flag','gender']\n",
    "ohe=OneHotEncoder(handle_unknown='ignore')\n",
    "ohe=OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "ohe.fit(train_x[one_hot_cols].values)\n",
    "train_x_ohe=ohe.transform(train_x[one_hot_cols].values)\n",
    "\n",
    "train_x=pd.concat([train_x.drop(one_hot_cols,axis=1),pd.DataFrame(train_x_ohe)],axis=1).astype(float)\n",
    "\n",
    "\n",
    "#下面用concat再加上新生成的\n",
    "X, val_X, y, val_y = train_test_split(  \n",
    "    pd.concat([train_x,df2],axis=1),  \n",
    "    train_y,  \n",
    "    test_size=0.2,  \n",
    "    random_state=1,  \n",
    "    stratify=train_y # 这里保证分割后y的比例分布与原数据一致  \n",
    ")  \n",
    "\n",
    "X_train = X  \n",
    "y_train = y  \n",
    "X_test = val_X  \n",
    "y_test = val_y  \n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)  \n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)  \n",
    "\n",
    "params = {  \n",
    "    'boosting_type': 'gbdt',  \n",
    "    'objective': 'binary',  \n",
    "    'metric': {'binary_logloss', 'auc'},  #二进制对数损失\n",
    "    'max_depth': 7,  \n",
    "    'num_leaves': 100,     \n",
    "    'min_data_in_leaf': 300,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'feature_fraction': 0.6,  \n",
    "    'bagging_fraction': 0.9,  \n",
    "    'bagging_freq': 5,  \n",
    "    'lambda_l1': 1,    \n",
    "    'lambda_l2': 0.01,  # 越小l2正则程度越高  \n",
    "    'min_gain_to_split': 0.3, \n",
    "    'verbose': 0,  \n",
    "    'is_unbalance': True  \n",
    "}  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'max_depth': 7,  \\n'num_leaves': 80,     \\n'min_data_in_leaf': 450,  \\n'learning_rate': 0.1,  \\n'feature_fraction': 0.8,  \\n'bagging_fraction': 0.9,  \\n'bagging_freq': 5,  \\n'lambda_l1': 1,    \\n'lambda_l2': 0.001,  # 越小l2正则程度越高  \\n'min_gain_to_split': 0.3,  \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    '''\n",
    "    'max_depth': 7,  \n",
    "    'num_leaves': 80,     \n",
    "    'min_data_in_leaf': 450,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'feature_fraction': 0.8,  \n",
    "    'bagging_fraction': 0.9,  \n",
    "    'bagging_freq': 5,  \n",
    "    'lambda_l1': 1,    \n",
    "    'lambda_l2': 0.001,  # 越小l2正则程度越高  \n",
    "    'min_gain_to_split': 0.3,  \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.800044\tvalid_0's binary_logloss: 0.479035\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[2]\tvalid_0's auc: 0.818509\tvalid_0's binary_logloss: 0.462797\n",
      "[3]\tvalid_0's auc: 0.826971\tvalid_0's binary_logloss: 0.452815\n",
      "[4]\tvalid_0's auc: 0.829169\tvalid_0's binary_logloss: 0.447376\n",
      "[5]\tvalid_0's auc: 0.833897\tvalid_0's binary_logloss: 0.444219\n",
      "[6]\tvalid_0's auc: 0.838281\tvalid_0's binary_logloss: 0.442147\n",
      "[7]\tvalid_0's auc: 0.840397\tvalid_0's binary_logloss: 0.440864\n",
      "[8]\tvalid_0's auc: 0.841001\tvalid_0's binary_logloss: 0.440739\n",
      "[9]\tvalid_0's auc: 0.841432\tvalid_0's binary_logloss: 0.440652\n",
      "[10]\tvalid_0's auc: 0.842536\tvalid_0's binary_logloss: 0.44236\n",
      "[11]\tvalid_0's auc: 0.842841\tvalid_0's binary_logloss: 0.443377\n",
      "[12]\tvalid_0's auc: 0.844134\tvalid_0's binary_logloss: 0.444256\n",
      "[13]\tvalid_0's auc: 0.84547\tvalid_0's binary_logloss: 0.445161\n",
      "[14]\tvalid_0's auc: 0.846871\tvalid_0's binary_logloss: 0.446469\n",
      "[15]\tvalid_0's auc: 0.847841\tvalid_0's binary_logloss: 0.447344\n",
      "[16]\tvalid_0's auc: 0.849039\tvalid_0's binary_logloss: 0.448667\n",
      "[17]\tvalid_0's auc: 0.850262\tvalid_0's binary_logloss: 0.449385\n",
      "[18]\tvalid_0's auc: 0.850835\tvalid_0's binary_logloss: 0.450687\n",
      "[19]\tvalid_0's auc: 0.85123\tvalid_0's binary_logloss: 0.451514\n",
      "[20]\tvalid_0's auc: 0.852014\tvalid_0's binary_logloss: 0.452421\n",
      "[21]\tvalid_0's auc: 0.852567\tvalid_0's binary_logloss: 0.453148\n",
      "[22]\tvalid_0's auc: 0.852991\tvalid_0's binary_logloss: 0.453624\n",
      "[23]\tvalid_0's auc: 0.853226\tvalid_0's binary_logloss: 0.45409\n",
      "[24]\tvalid_0's auc: 0.853764\tvalid_0's binary_logloss: 0.4544\n",
      "[25]\tvalid_0's auc: 0.854278\tvalid_0's binary_logloss: 0.454741\n",
      "[26]\tvalid_0's auc: 0.854538\tvalid_0's binary_logloss: 0.455149\n",
      "[27]\tvalid_0's auc: 0.854963\tvalid_0's binary_logloss: 0.45549\n",
      "[28]\tvalid_0's auc: 0.855274\tvalid_0's binary_logloss: 0.456005\n",
      "[29]\tvalid_0's auc: 0.855448\tvalid_0's binary_logloss: 0.456306\n",
      "[30]\tvalid_0's auc: 0.855755\tvalid_0's binary_logloss: 0.45653\n",
      "[31]\tvalid_0's auc: 0.856304\tvalid_0's binary_logloss: 0.456147\n",
      "[32]\tvalid_0's auc: 0.856868\tvalid_0's binary_logloss: 0.455846\n",
      "[33]\tvalid_0's auc: 0.85727\tvalid_0's binary_logloss: 0.455623\n",
      "[34]\tvalid_0's auc: 0.857559\tvalid_0's binary_logloss: 0.455463\n",
      "[35]\tvalid_0's auc: 0.857949\tvalid_0's binary_logloss: 0.455304\n",
      "[36]\tvalid_0's auc: 0.858039\tvalid_0's binary_logloss: 0.455239\n",
      "[37]\tvalid_0's auc: 0.858473\tvalid_0's binary_logloss: 0.455012\n",
      "[38]\tvalid_0's auc: 0.858836\tvalid_0's binary_logloss: 0.454878\n",
      "[39]\tvalid_0's auc: 0.859336\tvalid_0's binary_logloss: 0.454698\n",
      "[40]\tvalid_0's auc: 0.859638\tvalid_0's binary_logloss: 0.454205\n",
      "[41]\tvalid_0's auc: 0.859835\tvalid_0's binary_logloss: 0.453833\n",
      "[42]\tvalid_0's auc: 0.860415\tvalid_0's binary_logloss: 0.453065\n",
      "[43]\tvalid_0's auc: 0.860498\tvalid_0's binary_logloss: 0.4527\n",
      "[44]\tvalid_0's auc: 0.860751\tvalid_0's binary_logloss: 0.452124\n",
      "[45]\tvalid_0's auc: 0.861047\tvalid_0's binary_logloss: 0.451592\n",
      "[46]\tvalid_0's auc: 0.861381\tvalid_0's binary_logloss: 0.451237\n",
      "[47]\tvalid_0's auc: 0.861612\tvalid_0's binary_logloss: 0.450849\n",
      "[48]\tvalid_0's auc: 0.861916\tvalid_0's binary_logloss: 0.450412\n",
      "[49]\tvalid_0's auc: 0.8621\tvalid_0's binary_logloss: 0.450133\n",
      "[50]\tvalid_0's auc: 0.862186\tvalid_0's binary_logloss: 0.449746\n",
      "[51]\tvalid_0's auc: 0.862645\tvalid_0's binary_logloss: 0.449064\n",
      "[52]\tvalid_0's auc: 0.862865\tvalid_0's binary_logloss: 0.448736\n",
      "[53]\tvalid_0's auc: 0.862956\tvalid_0's binary_logloss: 0.448509\n",
      "[54]\tvalid_0's auc: 0.863007\tvalid_0's binary_logloss: 0.448388\n",
      "[55]\tvalid_0's auc: 0.863162\tvalid_0's binary_logloss: 0.448019\n",
      "[56]\tvalid_0's auc: 0.863173\tvalid_0's binary_logloss: 0.447859\n",
      "[57]\tvalid_0's auc: 0.863421\tvalid_0's binary_logloss: 0.447577\n",
      "[58]\tvalid_0's auc: 0.863558\tvalid_0's binary_logloss: 0.447314\n",
      "[59]\tvalid_0's auc: 0.863571\tvalid_0's binary_logloss: 0.447219\n",
      "[60]\tvalid_0's auc: 0.86408\tvalid_0's binary_logloss: 0.446438\n",
      "[61]\tvalid_0's auc: 0.864278\tvalid_0's binary_logloss: 0.445845\n",
      "[62]\tvalid_0's auc: 0.864254\tvalid_0's binary_logloss: 0.44527\n",
      "[63]\tvalid_0's auc: 0.864398\tvalid_0's binary_logloss: 0.444844\n",
      "[64]\tvalid_0's auc: 0.864559\tvalid_0's binary_logloss: 0.44435\n",
      "[65]\tvalid_0's auc: 0.864781\tvalid_0's binary_logloss: 0.443688\n",
      "[66]\tvalid_0's auc: 0.864997\tvalid_0's binary_logloss: 0.443317\n",
      "[67]\tvalid_0's auc: 0.865349\tvalid_0's binary_logloss: 0.442834\n",
      "[68]\tvalid_0's auc: 0.865535\tvalid_0's binary_logloss: 0.442421\n",
      "[69]\tvalid_0's auc: 0.865557\tvalid_0's binary_logloss: 0.442265\n",
      "[70]\tvalid_0's auc: 0.865671\tvalid_0's binary_logloss: 0.441752\n",
      "[71]\tvalid_0's auc: 0.865697\tvalid_0's binary_logloss: 0.441446\n",
      "[72]\tvalid_0's auc: 0.865758\tvalid_0's binary_logloss: 0.441158\n",
      "[73]\tvalid_0's auc: 0.865819\tvalid_0's binary_logloss: 0.441026\n",
      "[74]\tvalid_0's auc: 0.865839\tvalid_0's binary_logloss: 0.440857\n",
      "[75]\tvalid_0's auc: 0.86601\tvalid_0's binary_logloss: 0.440507\n",
      "[76]\tvalid_0's auc: 0.866105\tvalid_0's binary_logloss: 0.440155\n",
      "[77]\tvalid_0's auc: 0.866153\tvalid_0's binary_logloss: 0.439959\n",
      "[78]\tvalid_0's auc: 0.866216\tvalid_0's binary_logloss: 0.439863\n",
      "[79]\tvalid_0's auc: 0.866319\tvalid_0's binary_logloss: 0.439581\n",
      "[80]\tvalid_0's auc: 0.866519\tvalid_0's binary_logloss: 0.439251\n",
      "[81]\tvalid_0's auc: 0.86662\tvalid_0's binary_logloss: 0.439002\n",
      "[82]\tvalid_0's auc: 0.86674\tvalid_0's binary_logloss: 0.438707\n",
      "[83]\tvalid_0's auc: 0.866757\tvalid_0's binary_logloss: 0.438504\n",
      "[84]\tvalid_0's auc: 0.866817\tvalid_0's binary_logloss: 0.438224\n",
      "[85]\tvalid_0's auc: 0.866842\tvalid_0's binary_logloss: 0.438082\n",
      "[86]\tvalid_0's auc: 0.866943\tvalid_0's binary_logloss: 0.437764\n",
      "[87]\tvalid_0's auc: 0.867083\tvalid_0's binary_logloss: 0.437279\n",
      "[88]\tvalid_0's auc: 0.867114\tvalid_0's binary_logloss: 0.43716\n",
      "[89]\tvalid_0's auc: 0.86723\tvalid_0's binary_logloss: 0.43684\n",
      "[90]\tvalid_0's auc: 0.867222\tvalid_0's binary_logloss: 0.436588\n",
      "[91]\tvalid_0's auc: 0.867216\tvalid_0's binary_logloss: 0.436415\n",
      "[92]\tvalid_0's auc: 0.867324\tvalid_0's binary_logloss: 0.436184\n",
      "[93]\tvalid_0's auc: 0.867459\tvalid_0's binary_logloss: 0.435968\n",
      "[94]\tvalid_0's auc: 0.867495\tvalid_0's binary_logloss: 0.4359\n",
      "[95]\tvalid_0's auc: 0.867566\tvalid_0's binary_logloss: 0.435763\n",
      "[96]\tvalid_0's auc: 0.867718\tvalid_0's binary_logloss: 0.435596\n",
      "[97]\tvalid_0's auc: 0.867814\tvalid_0's binary_logloss: 0.435535\n",
      "[98]\tvalid_0's auc: 0.867764\tvalid_0's binary_logloss: 0.435618\n",
      "[99]\tvalid_0's auc: 0.867814\tvalid_0's binary_logloss: 0.435559\n",
      "[100]\tvalid_0's auc: 0.867726\tvalid_0's binary_logloss: 0.435641\n",
      "[101]\tvalid_0's auc: 0.867838\tvalid_0's binary_logloss: 0.435308\n",
      "[102]\tvalid_0's auc: 0.867899\tvalid_0's binary_logloss: 0.435173\n",
      "[103]\tvalid_0's auc: 0.867878\tvalid_0's binary_logloss: 0.435036\n",
      "[104]\tvalid_0's auc: 0.867839\tvalid_0's binary_logloss: 0.434913\n",
      "[105]\tvalid_0's auc: 0.867829\tvalid_0's binary_logloss: 0.434751\n",
      "[106]\tvalid_0's auc: 0.867877\tvalid_0's binary_logloss: 0.434779\n",
      "[107]\tvalid_0's auc: 0.868002\tvalid_0's binary_logloss: 0.43472\n",
      "[108]\tvalid_0's auc: 0.868014\tvalid_0's binary_logloss: 0.434712\n",
      "[109]\tvalid_0's auc: 0.868036\tvalid_0's binary_logloss: 0.434748\n",
      "[110]\tvalid_0's auc: 0.868088\tvalid_0's binary_logloss: 0.434742\n",
      "[111]\tvalid_0's auc: 0.86819\tvalid_0's binary_logloss: 0.434387\n",
      "[112]\tvalid_0's auc: 0.868228\tvalid_0's binary_logloss: 0.433978\n",
      "[113]\tvalid_0's auc: 0.868228\tvalid_0's binary_logloss: 0.433742\n",
      "[114]\tvalid_0's auc: 0.868227\tvalid_0's binary_logloss: 0.433537\n",
      "[115]\tvalid_0's auc: 0.868242\tvalid_0's binary_logloss: 0.433351\n",
      "[116]\tvalid_0's auc: 0.868284\tvalid_0's binary_logloss: 0.433141\n",
      "[117]\tvalid_0's auc: 0.868276\tvalid_0's binary_logloss: 0.432991\n",
      "[118]\tvalid_0's auc: 0.868273\tvalid_0's binary_logloss: 0.432769\n",
      "[119]\tvalid_0's auc: 0.868259\tvalid_0's binary_logloss: 0.432703\n",
      "[120]\tvalid_0's auc: 0.868381\tvalid_0's binary_logloss: 0.432417\n",
      "[121]\tvalid_0's auc: 0.868522\tvalid_0's binary_logloss: 0.432062\n",
      "[122]\tvalid_0's auc: 0.868519\tvalid_0's binary_logloss: 0.431923\n",
      "[123]\tvalid_0's auc: 0.868593\tvalid_0's binary_logloss: 0.4317\n",
      "[124]\tvalid_0's auc: 0.868636\tvalid_0's binary_logloss: 0.431485\n",
      "[125]\tvalid_0's auc: 0.868667\tvalid_0's binary_logloss: 0.431245\n",
      "[126]\tvalid_0's auc: 0.868798\tvalid_0's binary_logloss: 0.431097\n",
      "[127]\tvalid_0's auc: 0.86882\tvalid_0's binary_logloss: 0.431176\n",
      "[128]\tvalid_0's auc: 0.868981\tvalid_0's binary_logloss: 0.431132\n",
      "[129]\tvalid_0's auc: 0.868976\tvalid_0's binary_logloss: 0.431232\n",
      "[130]\tvalid_0's auc: 0.86904\tvalid_0's binary_logloss: 0.431066\n",
      "[131]\tvalid_0's auc: 0.869066\tvalid_0's binary_logloss: 0.430831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132]\tvalid_0's auc: 0.869053\tvalid_0's binary_logloss: 0.430675\n",
      "[133]\tvalid_0's auc: 0.869082\tvalid_0's binary_logloss: 0.43051\n",
      "[134]\tvalid_0's auc: 0.86913\tvalid_0's binary_logloss: 0.430366\n",
      "[135]\tvalid_0's auc: 0.869197\tvalid_0's binary_logloss: 0.430077\n",
      "[136]\tvalid_0's auc: 0.869267\tvalid_0's binary_logloss: 0.429839\n",
      "[137]\tvalid_0's auc: 0.869301\tvalid_0's binary_logloss: 0.429721\n",
      "[138]\tvalid_0's auc: 0.869489\tvalid_0's binary_logloss: 0.429435\n",
      "[139]\tvalid_0's auc: 0.869616\tvalid_0's binary_logloss: 0.429043\n",
      "[140]\tvalid_0's auc: 0.869646\tvalid_0's binary_logloss: 0.428878\n",
      "[141]\tvalid_0's auc: 0.869667\tvalid_0's binary_logloss: 0.428719\n",
      "[142]\tvalid_0's auc: 0.869711\tvalid_0's binary_logloss: 0.428617\n",
      "[143]\tvalid_0's auc: 0.869791\tvalid_0's binary_logloss: 0.428363\n",
      "[144]\tvalid_0's auc: 0.869905\tvalid_0's binary_logloss: 0.428213\n",
      "[145]\tvalid_0's auc: 0.869938\tvalid_0's binary_logloss: 0.428141\n",
      "[146]\tvalid_0's auc: 0.869889\tvalid_0's binary_logloss: 0.427919\n",
      "[147]\tvalid_0's auc: 0.869854\tvalid_0's binary_logloss: 0.42779\n",
      "[148]\tvalid_0's auc: 0.869905\tvalid_0's binary_logloss: 0.427344\n",
      "[149]\tvalid_0's auc: 0.86981\tvalid_0's binary_logloss: 0.427234\n",
      "[150]\tvalid_0's auc: 0.869837\tvalid_0's binary_logloss: 0.427012\n",
      "[151]\tvalid_0's auc: 0.869985\tvalid_0's binary_logloss: 0.426758\n",
      "[152]\tvalid_0's auc: 0.870084\tvalid_0's binary_logloss: 0.426542\n",
      "[153]\tvalid_0's auc: 0.87001\tvalid_0's binary_logloss: 0.426544\n",
      "[154]\tvalid_0's auc: 0.869972\tvalid_0's binary_logloss: 0.42652\n",
      "[155]\tvalid_0's auc: 0.869983\tvalid_0's binary_logloss: 0.426353\n",
      "[156]\tvalid_0's auc: 0.870016\tvalid_0's binary_logloss: 0.426079\n",
      "[157]\tvalid_0's auc: 0.86995\tvalid_0's binary_logloss: 0.425859\n",
      "[158]\tvalid_0's auc: 0.869941\tvalid_0's binary_logloss: 0.425574\n",
      "[159]\tvalid_0's auc: 0.869976\tvalid_0's binary_logloss: 0.425269\n",
      "[160]\tvalid_0's auc: 0.870032\tvalid_0's binary_logloss: 0.425008\n",
      "[161]\tvalid_0's auc: 0.87001\tvalid_0's binary_logloss: 0.425191\n",
      "[162]\tvalid_0's auc: 0.869948\tvalid_0's binary_logloss: 0.425217\n",
      "[163]\tvalid_0's auc: 0.869923\tvalid_0's binary_logloss: 0.425275\n",
      "[164]\tvalid_0's auc: 0.869917\tvalid_0's binary_logloss: 0.425351\n",
      "[165]\tvalid_0's auc: 0.869973\tvalid_0's binary_logloss: 0.42538\n",
      "[166]\tvalid_0's auc: 0.869977\tvalid_0's binary_logloss: 0.425391\n",
      "[167]\tvalid_0's auc: 0.869975\tvalid_0's binary_logloss: 0.425228\n",
      "[168]\tvalid_0's auc: 0.869979\tvalid_0's binary_logloss: 0.425108\n",
      "[169]\tvalid_0's auc: 0.86998\tvalid_0's binary_logloss: 0.425041\n",
      "[170]\tvalid_0's auc: 0.870018\tvalid_0's binary_logloss: 0.424959\n",
      "[171]\tvalid_0's auc: 0.87001\tvalid_0's binary_logloss: 0.424998\n",
      "[172]\tvalid_0's auc: 0.870042\tvalid_0's binary_logloss: 0.424939\n",
      "[173]\tvalid_0's auc: 0.870041\tvalid_0's binary_logloss: 0.424988\n",
      "[174]\tvalid_0's auc: 0.870117\tvalid_0's binary_logloss: 0.424923\n",
      "[175]\tvalid_0's auc: 0.870109\tvalid_0's binary_logloss: 0.424901\n",
      "[176]\tvalid_0's auc: 0.870116\tvalid_0's binary_logloss: 0.424793\n",
      "[177]\tvalid_0's auc: 0.870194\tvalid_0's binary_logloss: 0.424698\n",
      "[178]\tvalid_0's auc: 0.870171\tvalid_0's binary_logloss: 0.424738\n",
      "[179]\tvalid_0's auc: 0.870181\tvalid_0's binary_logloss: 0.424723\n",
      "[180]\tvalid_0's auc: 0.870216\tvalid_0's binary_logloss: 0.424627\n",
      "[181]\tvalid_0's auc: 0.870214\tvalid_0's binary_logloss: 0.424538\n",
      "[182]\tvalid_0's auc: 0.870204\tvalid_0's binary_logloss: 0.424425\n",
      "[183]\tvalid_0's auc: 0.87019\tvalid_0's binary_logloss: 0.424241\n",
      "[184]\tvalid_0's auc: 0.870267\tvalid_0's binary_logloss: 0.424025\n",
      "[185]\tvalid_0's auc: 0.870251\tvalid_0's binary_logloss: 0.423858\n",
      "[186]\tvalid_0's auc: 0.870277\tvalid_0's binary_logloss: 0.423612\n",
      "[187]\tvalid_0's auc: 0.870337\tvalid_0's binary_logloss: 0.423475\n",
      "[188]\tvalid_0's auc: 0.870392\tvalid_0's binary_logloss: 0.423257\n",
      "[189]\tvalid_0's auc: 0.870448\tvalid_0's binary_logloss: 0.423091\n",
      "[190]\tvalid_0's auc: 0.870558\tvalid_0's binary_logloss: 0.422904\n",
      "[191]\tvalid_0's auc: 0.870582\tvalid_0's binary_logloss: 0.4229\n",
      "[192]\tvalid_0's auc: 0.870495\tvalid_0's binary_logloss: 0.422954\n",
      "[193]\tvalid_0's auc: 0.870486\tvalid_0's binary_logloss: 0.423006\n",
      "[194]\tvalid_0's auc: 0.870443\tvalid_0's binary_logloss: 0.423079\n",
      "[195]\tvalid_0's auc: 0.870445\tvalid_0's binary_logloss: 0.423006\n",
      "[196]\tvalid_0's auc: 0.870474\tvalid_0's binary_logloss: 0.42291\n",
      "[197]\tvalid_0's auc: 0.870428\tvalid_0's binary_logloss: 0.422904\n",
      "[198]\tvalid_0's auc: 0.87044\tvalid_0's binary_logloss: 0.422817\n",
      "[199]\tvalid_0's auc: 0.870478\tvalid_0's binary_logloss: 0.422716\n",
      "[200]\tvalid_0's auc: 0.87042\tvalid_0's binary_logloss: 0.422637\n",
      "[201]\tvalid_0's auc: 0.870389\tvalid_0's binary_logloss: 0.422313\n",
      "[202]\tvalid_0's auc: 0.870353\tvalid_0's binary_logloss: 0.422147\n",
      "[203]\tvalid_0's auc: 0.870362\tvalid_0's binary_logloss: 0.421986\n",
      "[204]\tvalid_0's auc: 0.870374\tvalid_0's binary_logloss: 0.42187\n",
      "[205]\tvalid_0's auc: 0.870243\tvalid_0's binary_logloss: 0.421687\n",
      "[206]\tvalid_0's auc: 0.87025\tvalid_0's binary_logloss: 0.421493\n",
      "[207]\tvalid_0's auc: 0.870216\tvalid_0's binary_logloss: 0.421502\n",
      "[208]\tvalid_0's auc: 0.870262\tvalid_0's binary_logloss: 0.421418\n",
      "[209]\tvalid_0's auc: 0.870265\tvalid_0's binary_logloss: 0.421211\n",
      "[210]\tvalid_0's auc: 0.87024\tvalid_0's binary_logloss: 0.421151\n",
      "[211]\tvalid_0's auc: 0.870198\tvalid_0's binary_logloss: 0.42112\n",
      "[212]\tvalid_0's auc: 0.870248\tvalid_0's binary_logloss: 0.420988\n",
      "[213]\tvalid_0's auc: 0.870335\tvalid_0's binary_logloss: 0.420707\n",
      "[214]\tvalid_0's auc: 0.870406\tvalid_0's binary_logloss: 0.420471\n",
      "[215]\tvalid_0's auc: 0.870426\tvalid_0's binary_logloss: 0.420425\n",
      "[216]\tvalid_0's auc: 0.870374\tvalid_0's binary_logloss: 0.420372\n",
      "[217]\tvalid_0's auc: 0.870378\tvalid_0's binary_logloss: 0.420215\n",
      "[218]\tvalid_0's auc: 0.870537\tvalid_0's binary_logloss: 0.419873\n",
      "[219]\tvalid_0's auc: 0.870705\tvalid_0's binary_logloss: 0.419561\n",
      "[220]\tvalid_0's auc: 0.870697\tvalid_0's binary_logloss: 0.419462\n",
      "[221]\tvalid_0's auc: 0.870678\tvalid_0's binary_logloss: 0.41932\n",
      "[222]\tvalid_0's auc: 0.870714\tvalid_0's binary_logloss: 0.419188\n",
      "[223]\tvalid_0's auc: 0.870676\tvalid_0's binary_logloss: 0.41909\n",
      "[224]\tvalid_0's auc: 0.870588\tvalid_0's binary_logloss: 0.41899\n",
      "[225]\tvalid_0's auc: 0.870557\tvalid_0's binary_logloss: 0.418944\n",
      "[226]\tvalid_0's auc: 0.870582\tvalid_0's binary_logloss: 0.41881\n",
      "[227]\tvalid_0's auc: 0.870617\tvalid_0's binary_logloss: 0.418635\n",
      "[228]\tvalid_0's auc: 0.870586\tvalid_0's binary_logloss: 0.418536\n",
      "[229]\tvalid_0's auc: 0.870652\tvalid_0's binary_logloss: 0.418368\n",
      "[230]\tvalid_0's auc: 0.870613\tvalid_0's binary_logloss: 0.418312\n",
      "[231]\tvalid_0's auc: 0.870704\tvalid_0's binary_logloss: 0.418111\n",
      "[232]\tvalid_0's auc: 0.870618\tvalid_0's binary_logloss: 0.418096\n",
      "[233]\tvalid_0's auc: 0.870632\tvalid_0's binary_logloss: 0.418037\n",
      "[234]\tvalid_0's auc: 0.870595\tvalid_0's binary_logloss: 0.418004\n",
      "[235]\tvalid_0's auc: 0.870588\tvalid_0's binary_logloss: 0.41798\n",
      "[236]\tvalid_0's auc: 0.87057\tvalid_0's binary_logloss: 0.418002\n",
      "[237]\tvalid_0's auc: 0.870601\tvalid_0's binary_logloss: 0.417942\n",
      "[238]\tvalid_0's auc: 0.870607\tvalid_0's binary_logloss: 0.417944\n",
      "[239]\tvalid_0's auc: 0.870523\tvalid_0's binary_logloss: 0.418026\n",
      "[240]\tvalid_0's auc: 0.870525\tvalid_0's binary_logloss: 0.418021\n",
      "[241]\tvalid_0's auc: 0.870589\tvalid_0's binary_logloss: 0.417947\n",
      "[242]\tvalid_0's auc: 0.870631\tvalid_0's binary_logloss: 0.417865\n",
      "[243]\tvalid_0's auc: 0.870607\tvalid_0's binary_logloss: 0.41794\n",
      "[244]\tvalid_0's auc: 0.870564\tvalid_0's binary_logloss: 0.41797\n",
      "[245]\tvalid_0's auc: 0.870572\tvalid_0's binary_logloss: 0.417921\n",
      "[246]\tvalid_0's auc: 0.870572\tvalid_0's binary_logloss: 0.417936\n",
      "[247]\tvalid_0's auc: 0.870611\tvalid_0's binary_logloss: 0.418016\n",
      "[248]\tvalid_0's auc: 0.87063\tvalid_0's binary_logloss: 0.418025\n",
      "[249]\tvalid_0's auc: 0.870642\tvalid_0's binary_logloss: 0.418091\n",
      "[250]\tvalid_0's auc: 0.870659\tvalid_0's binary_logloss: 0.418093\n",
      "[251]\tvalid_0's auc: 0.87065\tvalid_0's binary_logloss: 0.41804\n",
      "[252]\tvalid_0's auc: 0.870671\tvalid_0's binary_logloss: 0.417908\n",
      "[253]\tvalid_0's auc: 0.870753\tvalid_0's binary_logloss: 0.417764\n",
      "[254]\tvalid_0's auc: 0.87079\tvalid_0's binary_logloss: 0.417692\n",
      "[255]\tvalid_0's auc: 0.870805\tvalid_0's binary_logloss: 0.417667\n",
      "[256]\tvalid_0's auc: 0.870762\tvalid_0's binary_logloss: 0.417586\n",
      "[257]\tvalid_0's auc: 0.870738\tvalid_0's binary_logloss: 0.417509\n",
      "[258]\tvalid_0's auc: 0.870727\tvalid_0's binary_logloss: 0.41745\n",
      "[259]\tvalid_0's auc: 0.870802\tvalid_0's binary_logloss: 0.417205\n",
      "[260]\tvalid_0's auc: 0.870736\tvalid_0's binary_logloss: 0.41716\n",
      "[261]\tvalid_0's auc: 0.870853\tvalid_0's binary_logloss: 0.416965\n",
      "[262]\tvalid_0's auc: 0.870798\tvalid_0's binary_logloss: 0.417023\n",
      "[263]\tvalid_0's auc: 0.870793\tvalid_0's binary_logloss: 0.416997\n",
      "[264]\tvalid_0's auc: 0.870786\tvalid_0's binary_logloss: 0.416964\n",
      "[265]\tvalid_0's auc: 0.870822\tvalid_0's binary_logloss: 0.416905\n",
      "[266]\tvalid_0's auc: 0.870837\tvalid_0's binary_logloss: 0.416528\n",
      "[267]\tvalid_0's auc: 0.870803\tvalid_0's binary_logloss: 0.416372\n",
      "[268]\tvalid_0's auc: 0.870768\tvalid_0's binary_logloss: 0.416253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269]\tvalid_0's auc: 0.870757\tvalid_0's binary_logloss: 0.41599\n",
      "[270]\tvalid_0's auc: 0.870764\tvalid_0's binary_logloss: 0.415883\n",
      "[271]\tvalid_0's auc: 0.870805\tvalid_0's binary_logloss: 0.415794\n",
      "[272]\tvalid_0's auc: 0.870786\tvalid_0's binary_logloss: 0.415779\n",
      "[273]\tvalid_0's auc: 0.8708\tvalid_0's binary_logloss: 0.415785\n",
      "[274]\tvalid_0's auc: 0.870833\tvalid_0's binary_logloss: 0.415582\n",
      "[275]\tvalid_0's auc: 0.870838\tvalid_0's binary_logloss: 0.415553\n",
      "[276]\tvalid_0's auc: 0.870808\tvalid_0's binary_logloss: 0.415353\n",
      "[277]\tvalid_0's auc: 0.870824\tvalid_0's binary_logloss: 0.415105\n",
      "[278]\tvalid_0's auc: 0.870911\tvalid_0's binary_logloss: 0.414844\n",
      "[279]\tvalid_0's auc: 0.870862\tvalid_0's binary_logloss: 0.414704\n",
      "[280]\tvalid_0's auc: 0.870835\tvalid_0's binary_logloss: 0.414514\n",
      "[281]\tvalid_0's auc: 0.870889\tvalid_0's binary_logloss: 0.414571\n",
      "[282]\tvalid_0's auc: 0.870926\tvalid_0's binary_logloss: 0.414594\n",
      "[283]\tvalid_0's auc: 0.870968\tvalid_0's binary_logloss: 0.414593\n",
      "[284]\tvalid_0's auc: 0.87092\tvalid_0's binary_logloss: 0.414683\n",
      "[285]\tvalid_0's auc: 0.871008\tvalid_0's binary_logloss: 0.414614\n",
      "[286]\tvalid_0's auc: 0.871006\tvalid_0's binary_logloss: 0.414593\n",
      "[287]\tvalid_0's auc: 0.87107\tvalid_0's binary_logloss: 0.414396\n",
      "[288]\tvalid_0's auc: 0.871095\tvalid_0's binary_logloss: 0.414242\n",
      "[289]\tvalid_0's auc: 0.871155\tvalid_0's binary_logloss: 0.414028\n",
      "[290]\tvalid_0's auc: 0.871153\tvalid_0's binary_logloss: 0.413888\n",
      "[291]\tvalid_0's auc: 0.871139\tvalid_0's binary_logloss: 0.413871\n",
      "[292]\tvalid_0's auc: 0.871203\tvalid_0's binary_logloss: 0.413754\n",
      "[293]\tvalid_0's auc: 0.871213\tvalid_0's binary_logloss: 0.413753\n",
      "[294]\tvalid_0's auc: 0.871249\tvalid_0's binary_logloss: 0.413667\n",
      "[295]\tvalid_0's auc: 0.8713\tvalid_0's binary_logloss: 0.413516\n",
      "[296]\tvalid_0's auc: 0.871299\tvalid_0's binary_logloss: 0.413325\n",
      "[297]\tvalid_0's auc: 0.87131\tvalid_0's binary_logloss: 0.413139\n",
      "[298]\tvalid_0's auc: 0.871283\tvalid_0's binary_logloss: 0.413022\n",
      "[299]\tvalid_0's auc: 0.87124\tvalid_0's binary_logloss: 0.412901\n",
      "[300]\tvalid_0's auc: 0.871225\tvalid_0's binary_logloss: 0.412807\n",
      "[301]\tvalid_0's auc: 0.871259\tvalid_0's binary_logloss: 0.412733\n",
      "[302]\tvalid_0's auc: 0.871334\tvalid_0's binary_logloss: 0.412567\n",
      "[303]\tvalid_0's auc: 0.871395\tvalid_0's binary_logloss: 0.412496\n",
      "[304]\tvalid_0's auc: 0.871422\tvalid_0's binary_logloss: 0.412387\n",
      "[305]\tvalid_0's auc: 0.871455\tvalid_0's binary_logloss: 0.41227\n",
      "[306]\tvalid_0's auc: 0.871396\tvalid_0's binary_logloss: 0.412168\n",
      "[307]\tvalid_0's auc: 0.871415\tvalid_0's binary_logloss: 0.412008\n",
      "[308]\tvalid_0's auc: 0.87144\tvalid_0's binary_logloss: 0.411872\n",
      "[309]\tvalid_0's auc: 0.871483\tvalid_0's binary_logloss: 0.41175\n",
      "[310]\tvalid_0's auc: 0.871389\tvalid_0's binary_logloss: 0.411714\n",
      "[311]\tvalid_0's auc: 0.87142\tvalid_0's binary_logloss: 0.411664\n",
      "[312]\tvalid_0's auc: 0.871416\tvalid_0's binary_logloss: 0.411655\n",
      "[313]\tvalid_0's auc: 0.871313\tvalid_0's binary_logloss: 0.411764\n",
      "[314]\tvalid_0's auc: 0.871323\tvalid_0's binary_logloss: 0.411693\n",
      "[315]\tvalid_0's auc: 0.871306\tvalid_0's binary_logloss: 0.41174\n",
      "[316]\tvalid_0's auc: 0.871263\tvalid_0's binary_logloss: 0.411806\n",
      "[317]\tvalid_0's auc: 0.871324\tvalid_0's binary_logloss: 0.411636\n",
      "[318]\tvalid_0's auc: 0.87132\tvalid_0's binary_logloss: 0.411641\n",
      "[319]\tvalid_0's auc: 0.87132\tvalid_0's binary_logloss: 0.411598\n",
      "[320]\tvalid_0's auc: 0.871357\tvalid_0's binary_logloss: 0.411564\n",
      "[321]\tvalid_0's auc: 0.871349\tvalid_0's binary_logloss: 0.411439\n",
      "[322]\tvalid_0's auc: 0.871344\tvalid_0's binary_logloss: 0.41137\n",
      "[323]\tvalid_0's auc: 0.871406\tvalid_0's binary_logloss: 0.41127\n",
      "[324]\tvalid_0's auc: 0.871406\tvalid_0's binary_logloss: 0.411215\n",
      "[325]\tvalid_0's auc: 0.871404\tvalid_0's binary_logloss: 0.411162\n",
      "[326]\tvalid_0's auc: 0.871427\tvalid_0's binary_logloss: 0.411048\n",
      "[327]\tvalid_0's auc: 0.871406\tvalid_0's binary_logloss: 0.410969\n",
      "[328]\tvalid_0's auc: 0.871423\tvalid_0's binary_logloss: 0.410932\n",
      "[329]\tvalid_0's auc: 0.871418\tvalid_0's binary_logloss: 0.410927\n",
      "[330]\tvalid_0's auc: 0.871382\tvalid_0's binary_logloss: 0.410939\n",
      "[331]\tvalid_0's auc: 0.871354\tvalid_0's binary_logloss: 0.410786\n",
      "[332]\tvalid_0's auc: 0.87135\tvalid_0's binary_logloss: 0.410676\n",
      "[333]\tvalid_0's auc: 0.871306\tvalid_0's binary_logloss: 0.410669\n",
      "[334]\tvalid_0's auc: 0.871348\tvalid_0's binary_logloss: 0.410537\n",
      "[335]\tvalid_0's auc: 0.871352\tvalid_0's binary_logloss: 0.410482\n",
      "[336]\tvalid_0's auc: 0.871309\tvalid_0's binary_logloss: 0.410541\n",
      "[337]\tvalid_0's auc: 0.871344\tvalid_0's binary_logloss: 0.410472\n",
      "[338]\tvalid_0's auc: 0.871323\tvalid_0's binary_logloss: 0.410478\n",
      "[339]\tvalid_0's auc: 0.871321\tvalid_0's binary_logloss: 0.410373\n",
      "[340]\tvalid_0's auc: 0.871261\tvalid_0's binary_logloss: 0.410304\n",
      "[341]\tvalid_0's auc: 0.871295\tvalid_0's binary_logloss: 0.410249\n",
      "[342]\tvalid_0's auc: 0.871282\tvalid_0's binary_logloss: 0.41014\n",
      "[343]\tvalid_0's auc: 0.871276\tvalid_0's binary_logloss: 0.410097\n",
      "[344]\tvalid_0's auc: 0.871308\tvalid_0's binary_logloss: 0.410025\n",
      "[345]\tvalid_0's auc: 0.871318\tvalid_0's binary_logloss: 0.410015\n",
      "[346]\tvalid_0's auc: 0.871445\tvalid_0's binary_logloss: 0.409915\n",
      "[347]\tvalid_0's auc: 0.87153\tvalid_0's binary_logloss: 0.409846\n",
      "[348]\tvalid_0's auc: 0.871519\tvalid_0's binary_logloss: 0.409914\n",
      "[349]\tvalid_0's auc: 0.871513\tvalid_0's binary_logloss: 0.409952\n",
      "[350]\tvalid_0's auc: 0.871567\tvalid_0's binary_logloss: 0.40986\n",
      "[351]\tvalid_0's auc: 0.871504\tvalid_0's binary_logloss: 0.4098\n",
      "[352]\tvalid_0's auc: 0.871476\tvalid_0's binary_logloss: 0.409759\n",
      "[353]\tvalid_0's auc: 0.871399\tvalid_0's binary_logloss: 0.409748\n",
      "[354]\tvalid_0's auc: 0.871355\tvalid_0's binary_logloss: 0.409731\n",
      "[355]\tvalid_0's auc: 0.871386\tvalid_0's binary_logloss: 0.409706\n",
      "[356]\tvalid_0's auc: 0.871315\tvalid_0's binary_logloss: 0.409567\n",
      "[357]\tvalid_0's auc: 0.871282\tvalid_0's binary_logloss: 0.409498\n",
      "[358]\tvalid_0's auc: 0.871341\tvalid_0's binary_logloss: 0.409372\n",
      "[359]\tvalid_0's auc: 0.871306\tvalid_0's binary_logloss: 0.409318\n",
      "[360]\tvalid_0's auc: 0.871308\tvalid_0's binary_logloss: 0.40922\n",
      "[361]\tvalid_0's auc: 0.871279\tvalid_0's binary_logloss: 0.409162\n",
      "[362]\tvalid_0's auc: 0.871207\tvalid_0's binary_logloss: 0.409183\n",
      "[363]\tvalid_0's auc: 0.871218\tvalid_0's binary_logloss: 0.409166\n",
      "[364]\tvalid_0's auc: 0.871223\tvalid_0's binary_logloss: 0.40903\n",
      "[365]\tvalid_0's auc: 0.871245\tvalid_0's binary_logloss: 0.409012\n",
      "[366]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.408881\n",
      "[367]\tvalid_0's auc: 0.871282\tvalid_0's binary_logloss: 0.408839\n",
      "[368]\tvalid_0's auc: 0.871282\tvalid_0's binary_logloss: 0.408697\n",
      "[369]\tvalid_0's auc: 0.87133\tvalid_0's binary_logloss: 0.40854\n",
      "[370]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.408446\n",
      "[371]\tvalid_0's auc: 0.871279\tvalid_0's binary_logloss: 0.408458\n",
      "[372]\tvalid_0's auc: 0.871245\tvalid_0's binary_logloss: 0.408491\n",
      "[373]\tvalid_0's auc: 0.871231\tvalid_0's binary_logloss: 0.408484\n",
      "[374]\tvalid_0's auc: 0.871188\tvalid_0's binary_logloss: 0.408441\n",
      "[375]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.408475\n",
      "[376]\tvalid_0's auc: 0.871147\tvalid_0's binary_logloss: 0.408414\n",
      "[377]\tvalid_0's auc: 0.871162\tvalid_0's binary_logloss: 0.408261\n",
      "[378]\tvalid_0's auc: 0.871097\tvalid_0's binary_logloss: 0.408208\n",
      "[379]\tvalid_0's auc: 0.871134\tvalid_0's binary_logloss: 0.408076\n",
      "[380]\tvalid_0's auc: 0.871115\tvalid_0's binary_logloss: 0.408077\n",
      "[381]\tvalid_0's auc: 0.871124\tvalid_0's binary_logloss: 0.408048\n",
      "[382]\tvalid_0's auc: 0.871073\tvalid_0's binary_logloss: 0.408176\n",
      "[383]\tvalid_0's auc: 0.871044\tvalid_0's binary_logloss: 0.40826\n",
      "[384]\tvalid_0's auc: 0.870978\tvalid_0's binary_logloss: 0.408364\n",
      "[385]\tvalid_0's auc: 0.870982\tvalid_0's binary_logloss: 0.4084\n",
      "[386]\tvalid_0's auc: 0.871\tvalid_0's binary_logloss: 0.408357\n",
      "[387]\tvalid_0's auc: 0.871045\tvalid_0's binary_logloss: 0.408239\n",
      "[388]\tvalid_0's auc: 0.871058\tvalid_0's binary_logloss: 0.408221\n",
      "[389]\tvalid_0's auc: 0.871079\tvalid_0's binary_logloss: 0.408196\n",
      "[390]\tvalid_0's auc: 0.871096\tvalid_0's binary_logloss: 0.408101\n",
      "[391]\tvalid_0's auc: 0.871163\tvalid_0's binary_logloss: 0.408037\n",
      "[392]\tvalid_0's auc: 0.871203\tvalid_0's binary_logloss: 0.407966\n",
      "[393]\tvalid_0's auc: 0.871194\tvalid_0's binary_logloss: 0.407971\n",
      "[394]\tvalid_0's auc: 0.871117\tvalid_0's binary_logloss: 0.407996\n",
      "[395]\tvalid_0's auc: 0.871138\tvalid_0's binary_logloss: 0.407923\n",
      "[396]\tvalid_0's auc: 0.871124\tvalid_0's binary_logloss: 0.407902\n",
      "[397]\tvalid_0's auc: 0.871061\tvalid_0's binary_logloss: 0.407904\n",
      "[398]\tvalid_0's auc: 0.87108\tvalid_0's binary_logloss: 0.407797\n",
      "[399]\tvalid_0's auc: 0.871111\tvalid_0's binary_logloss: 0.407688\n",
      "[400]\tvalid_0's auc: 0.871193\tvalid_0's binary_logloss: 0.407574\n",
      "[401]\tvalid_0's auc: 0.871125\tvalid_0's binary_logloss: 0.407627\n",
      "[402]\tvalid_0's auc: 0.871135\tvalid_0's binary_logloss: 0.407573\n",
      "[403]\tvalid_0's auc: 0.871088\tvalid_0's binary_logloss: 0.407606\n",
      "[404]\tvalid_0's auc: 0.871082\tvalid_0's binary_logloss: 0.407601\n",
      "[405]\tvalid_0's auc: 0.871061\tvalid_0's binary_logloss: 0.407614\n",
      "[406]\tvalid_0's auc: 0.871151\tvalid_0's binary_logloss: 0.407437\n",
      "[407]\tvalid_0's auc: 0.871166\tvalid_0's binary_logloss: 0.407369\n",
      "[408]\tvalid_0's auc: 0.871164\tvalid_0's binary_logloss: 0.407315\n",
      "[409]\tvalid_0's auc: 0.871145\tvalid_0's binary_logloss: 0.40731\n",
      "[410]\tvalid_0's auc: 0.871237\tvalid_0's binary_logloss: 0.40712\n",
      "[411]\tvalid_0's auc: 0.871332\tvalid_0's binary_logloss: 0.406937\n",
      "[412]\tvalid_0's auc: 0.871388\tvalid_0's binary_logloss: 0.406804\n",
      "[413]\tvalid_0's auc: 0.871414\tvalid_0's binary_logloss: 0.406693\n",
      "[414]\tvalid_0's auc: 0.8714\tvalid_0's binary_logloss: 0.406643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415]\tvalid_0's auc: 0.87141\tvalid_0's binary_logloss: 0.406573\n",
      "[416]\tvalid_0's auc: 0.871376\tvalid_0's binary_logloss: 0.4065\n",
      "[417]\tvalid_0's auc: 0.871417\tvalid_0's binary_logloss: 0.406392\n",
      "[418]\tvalid_0's auc: 0.871453\tvalid_0's binary_logloss: 0.406329\n",
      "[419]\tvalid_0's auc: 0.871454\tvalid_0's binary_logloss: 0.406231\n",
      "[420]\tvalid_0's auc: 0.871411\tvalid_0's binary_logloss: 0.406197\n",
      "[421]\tvalid_0's auc: 0.871417\tvalid_0's binary_logloss: 0.406058\n",
      "[422]\tvalid_0's auc: 0.871452\tvalid_0's binary_logloss: 0.405952\n",
      "[423]\tvalid_0's auc: 0.871457\tvalid_0's binary_logloss: 0.405854\n",
      "[424]\tvalid_0's auc: 0.871502\tvalid_0's binary_logloss: 0.405758\n",
      "[425]\tvalid_0's auc: 0.87152\tvalid_0's binary_logloss: 0.405607\n",
      "[426]\tvalid_0's auc: 0.871448\tvalid_0's binary_logloss: 0.405804\n",
      "[427]\tvalid_0's auc: 0.871445\tvalid_0's binary_logloss: 0.405895\n",
      "[428]\tvalid_0's auc: 0.871448\tvalid_0's binary_logloss: 0.405884\n",
      "[429]\tvalid_0's auc: 0.871413\tvalid_0's binary_logloss: 0.405948\n",
      "[430]\tvalid_0's auc: 0.871404\tvalid_0's binary_logloss: 0.406053\n",
      "[431]\tvalid_0's auc: 0.871407\tvalid_0's binary_logloss: 0.405952\n",
      "[432]\tvalid_0's auc: 0.871443\tvalid_0's binary_logloss: 0.405885\n",
      "[433]\tvalid_0's auc: 0.871597\tvalid_0's binary_logloss: 0.405652\n",
      "[434]\tvalid_0's auc: 0.871588\tvalid_0's binary_logloss: 0.405573\n",
      "[435]\tvalid_0's auc: 0.871594\tvalid_0's binary_logloss: 0.405508\n",
      "[436]\tvalid_0's auc: 0.871579\tvalid_0's binary_logloss: 0.405623\n",
      "[437]\tvalid_0's auc: 0.871593\tvalid_0's binary_logloss: 0.405603\n",
      "[438]\tvalid_0's auc: 0.871543\tvalid_0's binary_logloss: 0.405716\n",
      "[439]\tvalid_0's auc: 0.871553\tvalid_0's binary_logloss: 0.405752\n",
      "[440]\tvalid_0's auc: 0.871517\tvalid_0's binary_logloss: 0.40576\n",
      "[441]\tvalid_0's auc: 0.871454\tvalid_0's binary_logloss: 0.405867\n",
      "[442]\tvalid_0's auc: 0.871479\tvalid_0's binary_logloss: 0.405887\n",
      "[443]\tvalid_0's auc: 0.871463\tvalid_0's binary_logloss: 0.405901\n",
      "[444]\tvalid_0's auc: 0.871445\tvalid_0's binary_logloss: 0.405995\n",
      "[445]\tvalid_0's auc: 0.871469\tvalid_0's binary_logloss: 0.405995\n",
      "[446]\tvalid_0's auc: 0.871437\tvalid_0's binary_logloss: 0.405973\n",
      "[447]\tvalid_0's auc: 0.871465\tvalid_0's binary_logloss: 0.405927\n",
      "[448]\tvalid_0's auc: 0.871438\tvalid_0's binary_logloss: 0.405895\n",
      "[449]\tvalid_0's auc: 0.87141\tvalid_0's binary_logloss: 0.405905\n",
      "[450]\tvalid_0's auc: 0.871386\tvalid_0's binary_logloss: 0.405819\n",
      "[451]\tvalid_0's auc: 0.871374\tvalid_0's binary_logloss: 0.405688\n",
      "[452]\tvalid_0's auc: 0.871435\tvalid_0's binary_logloss: 0.405574\n",
      "[453]\tvalid_0's auc: 0.871372\tvalid_0's binary_logloss: 0.405565\n",
      "[454]\tvalid_0's auc: 0.871354\tvalid_0's binary_logloss: 0.405523\n",
      "[455]\tvalid_0's auc: 0.871375\tvalid_0's binary_logloss: 0.405455\n",
      "[456]\tvalid_0's auc: 0.871385\tvalid_0's binary_logloss: 0.405384\n",
      "[457]\tvalid_0's auc: 0.871407\tvalid_0's binary_logloss: 0.4053\n",
      "[458]\tvalid_0's auc: 0.871345\tvalid_0's binary_logloss: 0.40532\n",
      "[459]\tvalid_0's auc: 0.871353\tvalid_0's binary_logloss: 0.405289\n",
      "[460]\tvalid_0's auc: 0.871372\tvalid_0's binary_logloss: 0.405235\n",
      "[461]\tvalid_0's auc: 0.871266\tvalid_0's binary_logloss: 0.405108\n",
      "[462]\tvalid_0's auc: 0.871303\tvalid_0's binary_logloss: 0.404901\n",
      "[463]\tvalid_0's auc: 0.871346\tvalid_0's binary_logloss: 0.404708\n",
      "[464]\tvalid_0's auc: 0.871314\tvalid_0's binary_logloss: 0.404596\n",
      "[465]\tvalid_0's auc: 0.871299\tvalid_0's binary_logloss: 0.404483\n",
      "[466]\tvalid_0's auc: 0.871266\tvalid_0's binary_logloss: 0.404401\n",
      "[467]\tvalid_0's auc: 0.87126\tvalid_0's binary_logloss: 0.404269\n",
      "[468]\tvalid_0's auc: 0.871303\tvalid_0's binary_logloss: 0.404093\n",
      "[469]\tvalid_0's auc: 0.871368\tvalid_0's binary_logloss: 0.403918\n",
      "[470]\tvalid_0's auc: 0.871356\tvalid_0's binary_logloss: 0.403846\n",
      "[471]\tvalid_0's auc: 0.87141\tvalid_0's binary_logloss: 0.403683\n",
      "[472]\tvalid_0's auc: 0.871421\tvalid_0's binary_logloss: 0.403621\n",
      "[473]\tvalid_0's auc: 0.871355\tvalid_0's binary_logloss: 0.403689\n",
      "[474]\tvalid_0's auc: 0.871345\tvalid_0's binary_logloss: 0.403673\n",
      "[475]\tvalid_0's auc: 0.871248\tvalid_0's binary_logloss: 0.403715\n",
      "[476]\tvalid_0's auc: 0.871219\tvalid_0's binary_logloss: 0.4038\n",
      "[477]\tvalid_0's auc: 0.871087\tvalid_0's binary_logloss: 0.403939\n",
      "[478]\tvalid_0's auc: 0.871079\tvalid_0's binary_logloss: 0.403979\n",
      "[479]\tvalid_0's auc: 0.871063\tvalid_0's binary_logloss: 0.40399\n",
      "[480]\tvalid_0's auc: 0.871086\tvalid_0's binary_logloss: 0.404028\n",
      "[481]\tvalid_0's auc: 0.871112\tvalid_0's binary_logloss: 0.40387\n",
      "[482]\tvalid_0's auc: 0.87113\tvalid_0's binary_logloss: 0.403867\n",
      "[483]\tvalid_0's auc: 0.871104\tvalid_0's binary_logloss: 0.403835\n",
      "[484]\tvalid_0's auc: 0.87111\tvalid_0's binary_logloss: 0.403801\n",
      "[485]\tvalid_0's auc: 0.871143\tvalid_0's binary_logloss: 0.403747\n",
      "[486]\tvalid_0's auc: 0.871157\tvalid_0's binary_logloss: 0.403648\n",
      "[487]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.403602\n",
      "[488]\tvalid_0's auc: 0.871222\tvalid_0's binary_logloss: 0.403467\n",
      "[489]\tvalid_0's auc: 0.871242\tvalid_0's binary_logloss: 0.403347\n",
      "[490]\tvalid_0's auc: 0.871249\tvalid_0's binary_logloss: 0.403288\n",
      "[491]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.403192\n",
      "[492]\tvalid_0's auc: 0.871329\tvalid_0's binary_logloss: 0.403164\n",
      "[493]\tvalid_0's auc: 0.871279\tvalid_0's binary_logloss: 0.403082\n",
      "[494]\tvalid_0's auc: 0.871273\tvalid_0's binary_logloss: 0.403077\n",
      "[495]\tvalid_0's auc: 0.871246\tvalid_0's binary_logloss: 0.403045\n",
      "[496]\tvalid_0's auc: 0.871216\tvalid_0's binary_logloss: 0.40308\n",
      "[497]\tvalid_0's auc: 0.871264\tvalid_0's binary_logloss: 0.403053\n",
      "[498]\tvalid_0's auc: 0.871264\tvalid_0's binary_logloss: 0.403037\n",
      "[499]\tvalid_0's auc: 0.871265\tvalid_0's binary_logloss: 0.403043\n",
      "[500]\tvalid_0's auc: 0.871255\tvalid_0's binary_logloss: 0.403004\n",
      "[501]\tvalid_0's auc: 0.871294\tvalid_0's binary_logloss: 0.402932\n",
      "[502]\tvalid_0's auc: 0.871306\tvalid_0's binary_logloss: 0.402903\n",
      "[503]\tvalid_0's auc: 0.87127\tvalid_0's binary_logloss: 0.402904\n",
      "[504]\tvalid_0's auc: 0.871209\tvalid_0's binary_logloss: 0.402933\n",
      "[505]\tvalid_0's auc: 0.871206\tvalid_0's binary_logloss: 0.402922\n",
      "[506]\tvalid_0's auc: 0.871219\tvalid_0's binary_logloss: 0.402847\n",
      "[507]\tvalid_0's auc: 0.871253\tvalid_0's binary_logloss: 0.40274\n",
      "[508]\tvalid_0's auc: 0.871248\tvalid_0's binary_logloss: 0.402714\n",
      "[509]\tvalid_0's auc: 0.871267\tvalid_0's binary_logloss: 0.402632\n",
      "[510]\tvalid_0's auc: 0.871243\tvalid_0's binary_logloss: 0.402591\n",
      "[511]\tvalid_0's auc: 0.87126\tvalid_0's binary_logloss: 0.402638\n",
      "[512]\tvalid_0's auc: 0.871277\tvalid_0's binary_logloss: 0.402656\n",
      "[513]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.402656\n",
      "[514]\tvalid_0's auc: 0.871292\tvalid_0's binary_logloss: 0.402572\n",
      "[515]\tvalid_0's auc: 0.871298\tvalid_0's binary_logloss: 0.402605\n",
      "[516]\tvalid_0's auc: 0.871269\tvalid_0's binary_logloss: 0.402534\n",
      "[517]\tvalid_0's auc: 0.87122\tvalid_0's binary_logloss: 0.402548\n",
      "[518]\tvalid_0's auc: 0.871222\tvalid_0's binary_logloss: 0.402426\n",
      "[519]\tvalid_0's auc: 0.871204\tvalid_0's binary_logloss: 0.402364\n",
      "[520]\tvalid_0's auc: 0.871194\tvalid_0's binary_logloss: 0.402372\n",
      "[521]\tvalid_0's auc: 0.871182\tvalid_0's binary_logloss: 0.402279\n",
      "[522]\tvalid_0's auc: 0.871195\tvalid_0's binary_logloss: 0.402228\n",
      "[523]\tvalid_0's auc: 0.871247\tvalid_0's binary_logloss: 0.402117\n",
      "[524]\tvalid_0's auc: 0.87126\tvalid_0's binary_logloss: 0.402049\n",
      "[525]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.402062\n",
      "[526]\tvalid_0's auc: 0.871157\tvalid_0's binary_logloss: 0.401908\n",
      "[527]\tvalid_0's auc: 0.871137\tvalid_0's binary_logloss: 0.401855\n",
      "[528]\tvalid_0's auc: 0.871132\tvalid_0's binary_logloss: 0.401783\n",
      "[529]\tvalid_0's auc: 0.871125\tvalid_0's binary_logloss: 0.401676\n",
      "[530]\tvalid_0's auc: 0.871133\tvalid_0's binary_logloss: 0.401488\n",
      "[531]\tvalid_0's auc: 0.871123\tvalid_0's binary_logloss: 0.401482\n",
      "[532]\tvalid_0's auc: 0.871082\tvalid_0's binary_logloss: 0.401413\n",
      "[533]\tvalid_0's auc: 0.871092\tvalid_0's binary_logloss: 0.401433\n",
      "[534]\tvalid_0's auc: 0.871102\tvalid_0's binary_logloss: 0.40144\n",
      "[535]\tvalid_0's auc: 0.871088\tvalid_0's binary_logloss: 0.40138\n",
      "[536]\tvalid_0's auc: 0.87107\tvalid_0's binary_logloss: 0.401353\n",
      "[537]\tvalid_0's auc: 0.871018\tvalid_0's binary_logloss: 0.401369\n",
      "[538]\tvalid_0's auc: 0.871014\tvalid_0's binary_logloss: 0.401321\n",
      "[539]\tvalid_0's auc: 0.871036\tvalid_0's binary_logloss: 0.401334\n",
      "[540]\tvalid_0's auc: 0.871082\tvalid_0's binary_logloss: 0.401311\n",
      "[541]\tvalid_0's auc: 0.870985\tvalid_0's binary_logloss: 0.401349\n",
      "[542]\tvalid_0's auc: 0.870937\tvalid_0's binary_logloss: 0.40135\n",
      "[543]\tvalid_0's auc: 0.870978\tvalid_0's binary_logloss: 0.401298\n",
      "[544]\tvalid_0's auc: 0.870917\tvalid_0's binary_logloss: 0.401339\n",
      "[545]\tvalid_0's auc: 0.870848\tvalid_0's binary_logloss: 0.401408\n",
      "[546]\tvalid_0's auc: 0.870867\tvalid_0's binary_logloss: 0.401233\n",
      "[547]\tvalid_0's auc: 0.870847\tvalid_0's binary_logloss: 0.40118\n",
      "[548]\tvalid_0's auc: 0.870843\tvalid_0's binary_logloss: 0.401087\n",
      "[549]\tvalid_0's auc: 0.870849\tvalid_0's binary_logloss: 0.401017\n",
      "[550]\tvalid_0's auc: 0.870832\tvalid_0's binary_logloss: 0.401026\n",
      "[551]\tvalid_0's auc: 0.870772\tvalid_0's binary_logloss: 0.401072\n",
      "[552]\tvalid_0's auc: 0.870734\tvalid_0's binary_logloss: 0.40117\n",
      "[553]\tvalid_0's auc: 0.87077\tvalid_0's binary_logloss: 0.401169\n",
      "[554]\tvalid_0's auc: 0.870697\tvalid_0's binary_logloss: 0.401192\n",
      "[555]\tvalid_0's auc: 0.870649\tvalid_0's binary_logloss: 0.401253\n",
      "[556]\tvalid_0's auc: 0.870604\tvalid_0's binary_logloss: 0.401305\n",
      "[557]\tvalid_0's auc: 0.870572\tvalid_0's binary_logloss: 0.401197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[558]\tvalid_0's auc: 0.870559\tvalid_0's binary_logloss: 0.401147\n",
      "[559]\tvalid_0's auc: 0.870554\tvalid_0's binary_logloss: 0.401078\n",
      "[560]\tvalid_0's auc: 0.870556\tvalid_0's binary_logloss: 0.400997\n",
      "[561]\tvalid_0's auc: 0.870548\tvalid_0's binary_logloss: 0.400997\n",
      "[562]\tvalid_0's auc: 0.870615\tvalid_0's binary_logloss: 0.400904\n",
      "[563]\tvalid_0's auc: 0.87062\tvalid_0's binary_logloss: 0.400927\n",
      "[564]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.400889\n",
      "[565]\tvalid_0's auc: 0.870706\tvalid_0's binary_logloss: 0.400747\n",
      "[566]\tvalid_0's auc: 0.870698\tvalid_0's binary_logloss: 0.400688\n",
      "[567]\tvalid_0's auc: 0.870763\tvalid_0's binary_logloss: 0.400609\n",
      "[568]\tvalid_0's auc: 0.870713\tvalid_0's binary_logloss: 0.4006\n",
      "[569]\tvalid_0's auc: 0.870715\tvalid_0's binary_logloss: 0.400578\n",
      "[570]\tvalid_0's auc: 0.870736\tvalid_0's binary_logloss: 0.400578\n",
      "[571]\tvalid_0's auc: 0.870756\tvalid_0's binary_logloss: 0.400456\n",
      "[572]\tvalid_0's auc: 0.870687\tvalid_0's binary_logloss: 0.400401\n",
      "[573]\tvalid_0's auc: 0.870688\tvalid_0's binary_logloss: 0.400309\n",
      "[574]\tvalid_0's auc: 0.870659\tvalid_0's binary_logloss: 0.400221\n",
      "[575]\tvalid_0's auc: 0.870604\tvalid_0's binary_logloss: 0.400189\n",
      "[576]\tvalid_0's auc: 0.870606\tvalid_0's binary_logloss: 0.399997\n",
      "[577]\tvalid_0's auc: 0.870558\tvalid_0's binary_logloss: 0.399983\n",
      "[578]\tvalid_0's auc: 0.870523\tvalid_0's binary_logloss: 0.399893\n",
      "[579]\tvalid_0's auc: 0.870522\tvalid_0's binary_logloss: 0.399774\n",
      "[580]\tvalid_0's auc: 0.870476\tvalid_0's binary_logloss: 0.3997\n",
      "[581]\tvalid_0's auc: 0.870505\tvalid_0's binary_logloss: 0.399749\n",
      "[582]\tvalid_0's auc: 0.870483\tvalid_0's binary_logloss: 0.39987\n",
      "[583]\tvalid_0's auc: 0.870464\tvalid_0's binary_logloss: 0.39995\n",
      "[584]\tvalid_0's auc: 0.870421\tvalid_0's binary_logloss: 0.400089\n",
      "[585]\tvalid_0's auc: 0.870459\tvalid_0's binary_logloss: 0.400018\n",
      "[586]\tvalid_0's auc: 0.870442\tvalid_0's binary_logloss: 0.399887\n",
      "[587]\tvalid_0's auc: 0.870445\tvalid_0's binary_logloss: 0.399767\n",
      "[588]\tvalid_0's auc: 0.87045\tvalid_0's binary_logloss: 0.399683\n",
      "[589]\tvalid_0's auc: 0.870461\tvalid_0's binary_logloss: 0.399546\n",
      "[590]\tvalid_0's auc: 0.870485\tvalid_0's binary_logloss: 0.39946\n",
      "[591]\tvalid_0's auc: 0.870559\tvalid_0's binary_logloss: 0.399347\n",
      "[592]\tvalid_0's auc: 0.870522\tvalid_0's binary_logloss: 0.399433\n",
      "[593]\tvalid_0's auc: 0.870543\tvalid_0's binary_logloss: 0.399399\n",
      "[594]\tvalid_0's auc: 0.870551\tvalid_0's binary_logloss: 0.399372\n",
      "[595]\tvalid_0's auc: 0.870535\tvalid_0's binary_logloss: 0.39937\n",
      "[596]\tvalid_0's auc: 0.870495\tvalid_0's binary_logloss: 0.399281\n",
      "[597]\tvalid_0's auc: 0.870475\tvalid_0's binary_logloss: 0.39922\n",
      "[598]\tvalid_0's auc: 0.870506\tvalid_0's binary_logloss: 0.399061\n",
      "[599]\tvalid_0's auc: 0.870556\tvalid_0's binary_logloss: 0.398873\n",
      "[600]\tvalid_0's auc: 0.870564\tvalid_0's binary_logloss: 0.398768\n",
      "[601]\tvalid_0's auc: 0.870572\tvalid_0's binary_logloss: 0.398741\n",
      "[602]\tvalid_0's auc: 0.870523\tvalid_0's binary_logloss: 0.398752\n",
      "[603]\tvalid_0's auc: 0.870553\tvalid_0's binary_logloss: 0.398648\n",
      "[604]\tvalid_0's auc: 0.870527\tvalid_0's binary_logloss: 0.398684\n",
      "[605]\tvalid_0's auc: 0.870505\tvalid_0's binary_logloss: 0.398696\n",
      "[606]\tvalid_0's auc: 0.870523\tvalid_0's binary_logloss: 0.398663\n",
      "[607]\tvalid_0's auc: 0.870522\tvalid_0's binary_logloss: 0.3987\n",
      "[608]\tvalid_0's auc: 0.870492\tvalid_0's binary_logloss: 0.39875\n",
      "[609]\tvalid_0's auc: 0.870483\tvalid_0's binary_logloss: 0.398776\n",
      "[610]\tvalid_0's auc: 0.870534\tvalid_0's binary_logloss: 0.398728\n",
      "[611]\tvalid_0's auc: 0.870581\tvalid_0's binary_logloss: 0.398659\n",
      "[612]\tvalid_0's auc: 0.870623\tvalid_0's binary_logloss: 0.398565\n",
      "[613]\tvalid_0's auc: 0.870638\tvalid_0's binary_logloss: 0.398532\n",
      "[614]\tvalid_0's auc: 0.870685\tvalid_0's binary_logloss: 0.398394\n",
      "[615]\tvalid_0's auc: 0.870693\tvalid_0's binary_logloss: 0.398238\n",
      "[616]\tvalid_0's auc: 0.8707\tvalid_0's binary_logloss: 0.39825\n",
      "[617]\tvalid_0's auc: 0.870719\tvalid_0's binary_logloss: 0.398247\n",
      "[618]\tvalid_0's auc: 0.87074\tvalid_0's binary_logloss: 0.398219\n",
      "[619]\tvalid_0's auc: 0.870709\tvalid_0's binary_logloss: 0.398313\n",
      "[620]\tvalid_0's auc: 0.870689\tvalid_0's binary_logloss: 0.398324\n",
      "[621]\tvalid_0's auc: 0.870732\tvalid_0's binary_logloss: 0.398188\n",
      "[622]\tvalid_0's auc: 0.870778\tvalid_0's binary_logloss: 0.398122\n",
      "[623]\tvalid_0's auc: 0.870785\tvalid_0's binary_logloss: 0.398072\n",
      "[624]\tvalid_0's auc: 0.870705\tvalid_0's binary_logloss: 0.398096\n",
      "[625]\tvalid_0's auc: 0.870704\tvalid_0's binary_logloss: 0.398023\n",
      "[626]\tvalid_0's auc: 0.870606\tvalid_0's binary_logloss: 0.397961\n",
      "[627]\tvalid_0's auc: 0.870603\tvalid_0's binary_logloss: 0.397832\n",
      "[628]\tvalid_0's auc: 0.870623\tvalid_0's binary_logloss: 0.397708\n",
      "[629]\tvalid_0's auc: 0.870627\tvalid_0's binary_logloss: 0.397608\n",
      "[630]\tvalid_0's auc: 0.870684\tvalid_0's binary_logloss: 0.397378\n",
      "[631]\tvalid_0's auc: 0.870716\tvalid_0's binary_logloss: 0.397342\n",
      "[632]\tvalid_0's auc: 0.870726\tvalid_0's binary_logloss: 0.397337\n",
      "[633]\tvalid_0's auc: 0.870651\tvalid_0's binary_logloss: 0.397393\n",
      "[634]\tvalid_0's auc: 0.870631\tvalid_0's binary_logloss: 0.397437\n",
      "[635]\tvalid_0's auc: 0.870648\tvalid_0's binary_logloss: 0.39738\n",
      "[636]\tvalid_0's auc: 0.870605\tvalid_0's binary_logloss: 0.397316\n",
      "[637]\tvalid_0's auc: 0.870619\tvalid_0's binary_logloss: 0.397199\n",
      "[638]\tvalid_0's auc: 0.870574\tvalid_0's binary_logloss: 0.397194\n",
      "[639]\tvalid_0's auc: 0.870561\tvalid_0's binary_logloss: 0.397176\n",
      "[640]\tvalid_0's auc: 0.870564\tvalid_0's binary_logloss: 0.397108\n",
      "[641]\tvalid_0's auc: 0.870589\tvalid_0's binary_logloss: 0.397048\n",
      "[642]\tvalid_0's auc: 0.870639\tvalid_0's binary_logloss: 0.396944\n",
      "[643]\tvalid_0's auc: 0.870634\tvalid_0's binary_logloss: 0.39699\n",
      "[644]\tvalid_0's auc: 0.870671\tvalid_0's binary_logloss: 0.396959\n",
      "[645]\tvalid_0's auc: 0.870653\tvalid_0's binary_logloss: 0.396951\n",
      "[646]\tvalid_0's auc: 0.870679\tvalid_0's binary_logloss: 0.396901\n",
      "[647]\tvalid_0's auc: 0.870704\tvalid_0's binary_logloss: 0.396828\n",
      "[648]\tvalid_0's auc: 0.870712\tvalid_0's binary_logloss: 0.39683\n",
      "[649]\tvalid_0's auc: 0.870695\tvalid_0's binary_logloss: 0.396835\n",
      "[650]\tvalid_0's auc: 0.870648\tvalid_0's binary_logloss: 0.396836\n",
      "[651]\tvalid_0's auc: 0.870664\tvalid_0's binary_logloss: 0.396678\n",
      "[652]\tvalid_0's auc: 0.870639\tvalid_0's binary_logloss: 0.396637\n",
      "[653]\tvalid_0's auc: 0.870627\tvalid_0's binary_logloss: 0.396539\n",
      "[654]\tvalid_0's auc: 0.870617\tvalid_0's binary_logloss: 0.396464\n",
      "[655]\tvalid_0's auc: 0.870586\tvalid_0's binary_logloss: 0.396423\n",
      "[656]\tvalid_0's auc: 0.870576\tvalid_0's binary_logloss: 0.396451\n",
      "[657]\tvalid_0's auc: 0.870575\tvalid_0's binary_logloss: 0.396485\n",
      "[658]\tvalid_0's auc: 0.870573\tvalid_0's binary_logloss: 0.396579\n",
      "[659]\tvalid_0's auc: 0.870575\tvalid_0's binary_logloss: 0.396609\n",
      "[660]\tvalid_0's auc: 0.870574\tvalid_0's binary_logloss: 0.396672\n",
      "[661]\tvalid_0's auc: 0.870553\tvalid_0's binary_logloss: 0.396654\n",
      "[662]\tvalid_0's auc: 0.870573\tvalid_0's binary_logloss: 0.39664\n",
      "[663]\tvalid_0's auc: 0.870556\tvalid_0's binary_logloss: 0.396584\n",
      "[664]\tvalid_0's auc: 0.870574\tvalid_0's binary_logloss: 0.396598\n",
      "[665]\tvalid_0's auc: 0.870636\tvalid_0's binary_logloss: 0.396478\n",
      "[666]\tvalid_0's auc: 0.870667\tvalid_0's binary_logloss: 0.396368\n",
      "[667]\tvalid_0's auc: 0.870651\tvalid_0's binary_logloss: 0.396342\n",
      "[668]\tvalid_0's auc: 0.870693\tvalid_0's binary_logloss: 0.396258\n",
      "[669]\tvalid_0's auc: 0.870654\tvalid_0's binary_logloss: 0.396269\n",
      "[670]\tvalid_0's auc: 0.870617\tvalid_0's binary_logloss: 0.396269\n",
      "[671]\tvalid_0's auc: 0.870624\tvalid_0's binary_logloss: 0.396115\n",
      "[672]\tvalid_0's auc: 0.870623\tvalid_0's binary_logloss: 0.396019\n",
      "[673]\tvalid_0's auc: 0.870672\tvalid_0's binary_logloss: 0.395839\n",
      "[674]\tvalid_0's auc: 0.870677\tvalid_0's binary_logloss: 0.395714\n",
      "[675]\tvalid_0's auc: 0.870686\tvalid_0's binary_logloss: 0.395647\n",
      "[676]\tvalid_0's auc: 0.870663\tvalid_0's binary_logloss: 0.395741\n",
      "[677]\tvalid_0's auc: 0.870593\tvalid_0's binary_logloss: 0.39586\n",
      "[678]\tvalid_0's auc: 0.870627\tvalid_0's binary_logloss: 0.395846\n",
      "[679]\tvalid_0's auc: 0.870617\tvalid_0's binary_logloss: 0.395921\n",
      "[680]\tvalid_0's auc: 0.870633\tvalid_0's binary_logloss: 0.395977\n",
      "[681]\tvalid_0's auc: 0.870591\tvalid_0's binary_logloss: 0.39589\n",
      "[682]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.395759\n",
      "[683]\tvalid_0's auc: 0.870528\tvalid_0's binary_logloss: 0.395818\n",
      "[684]\tvalid_0's auc: 0.870506\tvalid_0's binary_logloss: 0.395799\n",
      "[685]\tvalid_0's auc: 0.870509\tvalid_0's binary_logloss: 0.395685\n",
      "[686]\tvalid_0's auc: 0.870508\tvalid_0's binary_logloss: 0.395746\n",
      "[687]\tvalid_0's auc: 0.870481\tvalid_0's binary_logloss: 0.395834\n",
      "[688]\tvalid_0's auc: 0.870481\tvalid_0's binary_logloss: 0.395856\n",
      "[689]\tvalid_0's auc: 0.870477\tvalid_0's binary_logloss: 0.395936\n",
      "[690]\tvalid_0's auc: 0.870479\tvalid_0's binary_logloss: 0.395943\n",
      "[691]\tvalid_0's auc: 0.870436\tvalid_0's binary_logloss: 0.395926\n",
      "[692]\tvalid_0's auc: 0.870432\tvalid_0's binary_logloss: 0.395901\n",
      "[693]\tvalid_0's auc: 0.87038\tvalid_0's binary_logloss: 0.395854\n",
      "[694]\tvalid_0's auc: 0.870369\tvalid_0's binary_logloss: 0.395807\n",
      "[695]\tvalid_0's auc: 0.8704\tvalid_0's binary_logloss: 0.395687\n",
      "[696]\tvalid_0's auc: 0.870391\tvalid_0's binary_logloss: 0.395667\n",
      "[697]\tvalid_0's auc: 0.870398\tvalid_0's binary_logloss: 0.395608\n",
      "[698]\tvalid_0's auc: 0.870389\tvalid_0's binary_logloss: 0.395594\n",
      "[699]\tvalid_0's auc: 0.870358\tvalid_0's binary_logloss: 0.395598\n",
      "[700]\tvalid_0's auc: 0.870436\tvalid_0's binary_logloss: 0.395466\n",
      "[701]\tvalid_0's auc: 0.870423\tvalid_0's binary_logloss: 0.395458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[702]\tvalid_0's auc: 0.870447\tvalid_0's binary_logloss: 0.395452\n",
      "[703]\tvalid_0's auc: 0.87048\tvalid_0's binary_logloss: 0.395404\n",
      "[704]\tvalid_0's auc: 0.870526\tvalid_0's binary_logloss: 0.395325\n",
      "[705]\tvalid_0's auc: 0.870524\tvalid_0's binary_logloss: 0.395343\n",
      "[706]\tvalid_0's auc: 0.870531\tvalid_0's binary_logloss: 0.395329\n",
      "[707]\tvalid_0's auc: 0.870509\tvalid_0's binary_logloss: 0.395332\n",
      "[708]\tvalid_0's auc: 0.870529\tvalid_0's binary_logloss: 0.395322\n",
      "[709]\tvalid_0's auc: 0.870529\tvalid_0's binary_logloss: 0.395297\n",
      "[710]\tvalid_0's auc: 0.870471\tvalid_0's binary_logloss: 0.395312\n",
      "[711]\tvalid_0's auc: 0.870489\tvalid_0's binary_logloss: 0.395183\n",
      "[712]\tvalid_0's auc: 0.870461\tvalid_0's binary_logloss: 0.395115\n",
      "[713]\tvalid_0's auc: 0.870483\tvalid_0's binary_logloss: 0.394968\n",
      "[714]\tvalid_0's auc: 0.87049\tvalid_0's binary_logloss: 0.394905\n",
      "[715]\tvalid_0's auc: 0.870476\tvalid_0's binary_logloss: 0.394869\n",
      "[716]\tvalid_0's auc: 0.870473\tvalid_0's binary_logloss: 0.394766\n",
      "[717]\tvalid_0's auc: 0.87049\tvalid_0's binary_logloss: 0.394606\n",
      "[718]\tvalid_0's auc: 0.870434\tvalid_0's binary_logloss: 0.394567\n",
      "[719]\tvalid_0's auc: 0.870412\tvalid_0's binary_logloss: 0.394522\n",
      "[720]\tvalid_0's auc: 0.870422\tvalid_0's binary_logloss: 0.394438\n",
      "[721]\tvalid_0's auc: 0.870393\tvalid_0's binary_logloss: 0.394466\n",
      "[722]\tvalid_0's auc: 0.870368\tvalid_0's binary_logloss: 0.394475\n",
      "[723]\tvalid_0's auc: 0.870372\tvalid_0's binary_logloss: 0.39446\n",
      "[724]\tvalid_0's auc: 0.870334\tvalid_0's binary_logloss: 0.394435\n",
      "[725]\tvalid_0's auc: 0.870309\tvalid_0's binary_logloss: 0.394503\n",
      "[726]\tvalid_0's auc: 0.870343\tvalid_0's binary_logloss: 0.394434\n",
      "[727]\tvalid_0's auc: 0.870345\tvalid_0's binary_logloss: 0.394392\n",
      "[728]\tvalid_0's auc: 0.87032\tvalid_0's binary_logloss: 0.394382\n",
      "[729]\tvalid_0's auc: 0.870294\tvalid_0's binary_logloss: 0.394331\n",
      "[730]\tvalid_0's auc: 0.870293\tvalid_0's binary_logloss: 0.394265\n",
      "[731]\tvalid_0's auc: 0.870297\tvalid_0's binary_logloss: 0.394325\n",
      "[732]\tvalid_0's auc: 0.870292\tvalid_0's binary_logloss: 0.39443\n",
      "[733]\tvalid_0's auc: 0.870234\tvalid_0's binary_logloss: 0.394552\n",
      "[734]\tvalid_0's auc: 0.870198\tvalid_0's binary_logloss: 0.394663\n",
      "[735]\tvalid_0's auc: 0.870171\tvalid_0's binary_logloss: 0.394747\n",
      "[736]\tvalid_0's auc: 0.870175\tvalid_0's binary_logloss: 0.394692\n",
      "[737]\tvalid_0's auc: 0.870162\tvalid_0's binary_logloss: 0.394686\n",
      "[738]\tvalid_0's auc: 0.870089\tvalid_0's binary_logloss: 0.394721\n",
      "[739]\tvalid_0's auc: 0.870076\tvalid_0's binary_logloss: 0.394754\n",
      "[740]\tvalid_0's auc: 0.870065\tvalid_0's binary_logloss: 0.394708\n",
      "[741]\tvalid_0's auc: 0.870064\tvalid_0's binary_logloss: 0.394766\n",
      "[742]\tvalid_0's auc: 0.870049\tvalid_0's binary_logloss: 0.394848\n",
      "[743]\tvalid_0's auc: 0.870009\tvalid_0's binary_logloss: 0.394951\n",
      "[744]\tvalid_0's auc: 0.870017\tvalid_0's binary_logloss: 0.394948\n",
      "[745]\tvalid_0's auc: 0.869982\tvalid_0's binary_logloss: 0.394985\n",
      "[746]\tvalid_0's auc: 0.869952\tvalid_0's binary_logloss: 0.394954\n",
      "[747]\tvalid_0's auc: 0.869918\tvalid_0's binary_logloss: 0.39492\n",
      "[748]\tvalid_0's auc: 0.869913\tvalid_0's binary_logloss: 0.394883\n",
      "[749]\tvalid_0's auc: 0.869923\tvalid_0's binary_logloss: 0.39484\n",
      "[750]\tvalid_0's auc: 0.869877\tvalid_0's binary_logloss: 0.394857\n",
      "[751]\tvalid_0's auc: 0.869936\tvalid_0's binary_logloss: 0.394853\n",
      "[752]\tvalid_0's auc: 0.86993\tvalid_0's binary_logloss: 0.394921\n",
      "[753]\tvalid_0's auc: 0.869961\tvalid_0's binary_logloss: 0.394955\n",
      "[754]\tvalid_0's auc: 0.869976\tvalid_0's binary_logloss: 0.39497\n",
      "[755]\tvalid_0's auc: 0.869994\tvalid_0's binary_logloss: 0.394932\n",
      "[756]\tvalid_0's auc: 0.869977\tvalid_0's binary_logloss: 0.394841\n",
      "[757]\tvalid_0's auc: 0.869996\tvalid_0's binary_logloss: 0.394755\n",
      "[758]\tvalid_0's auc: 0.869991\tvalid_0's binary_logloss: 0.394724\n",
      "[759]\tvalid_0's auc: 0.870052\tvalid_0's binary_logloss: 0.39455\n",
      "[760]\tvalid_0's auc: 0.870067\tvalid_0's binary_logloss: 0.394453\n",
      "[761]\tvalid_0's auc: 0.870051\tvalid_0's binary_logloss: 0.394452\n",
      "[762]\tvalid_0's auc: 0.869967\tvalid_0's binary_logloss: 0.394471\n",
      "[763]\tvalid_0's auc: 0.869974\tvalid_0's binary_logloss: 0.394442\n",
      "[764]\tvalid_0's auc: 0.870008\tvalid_0's binary_logloss: 0.394372\n",
      "[765]\tvalid_0's auc: 0.870016\tvalid_0's binary_logloss: 0.394361\n",
      "[766]\tvalid_0's auc: 0.87\tvalid_0's binary_logloss: 0.394368\n",
      "[767]\tvalid_0's auc: 0.869974\tvalid_0's binary_logloss: 0.39442\n",
      "[768]\tvalid_0's auc: 0.869991\tvalid_0's binary_logloss: 0.394445\n",
      "[769]\tvalid_0's auc: 0.869987\tvalid_0's binary_logloss: 0.394411\n",
      "[770]\tvalid_0's auc: 0.869981\tvalid_0's binary_logloss: 0.394379\n",
      "[771]\tvalid_0's auc: 0.870014\tvalid_0's binary_logloss: 0.394436\n",
      "[772]\tvalid_0's auc: 0.870041\tvalid_0's binary_logloss: 0.394495\n",
      "[773]\tvalid_0's auc: 0.870022\tvalid_0's binary_logloss: 0.394505\n",
      "[774]\tvalid_0's auc: 0.869993\tvalid_0's binary_logloss: 0.394569\n",
      "[775]\tvalid_0's auc: 0.869962\tvalid_0's binary_logloss: 0.394619\n",
      "[776]\tvalid_0's auc: 0.869947\tvalid_0's binary_logloss: 0.394524\n",
      "[777]\tvalid_0's auc: 0.869928\tvalid_0's binary_logloss: 0.394455\n",
      "[778]\tvalid_0's auc: 0.869914\tvalid_0's binary_logloss: 0.394336\n",
      "[779]\tvalid_0's auc: 0.869937\tvalid_0's binary_logloss: 0.394233\n",
      "[780]\tvalid_0's auc: 0.869895\tvalid_0's binary_logloss: 0.394223\n",
      "[781]\tvalid_0's auc: 0.869881\tvalid_0's binary_logloss: 0.394327\n",
      "[782]\tvalid_0's auc: 0.869888\tvalid_0's binary_logloss: 0.394404\n",
      "[783]\tvalid_0's auc: 0.869925\tvalid_0's binary_logloss: 0.394401\n",
      "[784]\tvalid_0's auc: 0.869973\tvalid_0's binary_logloss: 0.394383\n",
      "[785]\tvalid_0's auc: 0.86997\tvalid_0's binary_logloss: 0.394416\n",
      "[786]\tvalid_0's auc: 0.870004\tvalid_0's binary_logloss: 0.394252\n",
      "[787]\tvalid_0's auc: 0.869985\tvalid_0's binary_logloss: 0.394218\n",
      "[788]\tvalid_0's auc: 0.869995\tvalid_0's binary_logloss: 0.39413\n",
      "[789]\tvalid_0's auc: 0.869997\tvalid_0's binary_logloss: 0.39407\n",
      "[790]\tvalid_0's auc: 0.87\tvalid_0's binary_logloss: 0.393964\n",
      "[791]\tvalid_0's auc: 0.869967\tvalid_0's binary_logloss: 0.394021\n",
      "[792]\tvalid_0's auc: 0.869952\tvalid_0's binary_logloss: 0.394011\n",
      "[793]\tvalid_0's auc: 0.869923\tvalid_0's binary_logloss: 0.393987\n",
      "[794]\tvalid_0's auc: 0.869922\tvalid_0's binary_logloss: 0.394006\n",
      "[795]\tvalid_0's auc: 0.869865\tvalid_0's binary_logloss: 0.39408\n",
      "[796]\tvalid_0's auc: 0.869758\tvalid_0's binary_logloss: 0.394195\n",
      "[797]\tvalid_0's auc: 0.86979\tvalid_0's binary_logloss: 0.394187\n",
      "[798]\tvalid_0's auc: 0.869763\tvalid_0's binary_logloss: 0.394237\n",
      "[799]\tvalid_0's auc: 0.869769\tvalid_0's binary_logloss: 0.394277\n",
      "[800]\tvalid_0's auc: 0.869781\tvalid_0's binary_logloss: 0.394269\n",
      "[801]\tvalid_0's auc: 0.869787\tvalid_0's binary_logloss: 0.394272\n",
      "[802]\tvalid_0's auc: 0.869747\tvalid_0's binary_logloss: 0.394241\n",
      "[803]\tvalid_0's auc: 0.869791\tvalid_0's binary_logloss: 0.394179\n",
      "[804]\tvalid_0's auc: 0.869798\tvalid_0's binary_logloss: 0.39411\n",
      "[805]\tvalid_0's auc: 0.869741\tvalid_0's binary_logloss: 0.394142\n",
      "[806]\tvalid_0's auc: 0.869649\tvalid_0's binary_logloss: 0.394164\n",
      "[807]\tvalid_0's auc: 0.869562\tvalid_0's binary_logloss: 0.394216\n",
      "[808]\tvalid_0's auc: 0.869572\tvalid_0's binary_logloss: 0.394111\n",
      "[809]\tvalid_0's auc: 0.869604\tvalid_0's binary_logloss: 0.394054\n",
      "[810]\tvalid_0's auc: 0.869621\tvalid_0's binary_logloss: 0.394013\n",
      "[811]\tvalid_0's auc: 0.869624\tvalid_0's binary_logloss: 0.394015\n",
      "[812]\tvalid_0's auc: 0.869635\tvalid_0's binary_logloss: 0.393976\n",
      "[813]\tvalid_0's auc: 0.869643\tvalid_0's binary_logloss: 0.39393\n",
      "[814]\tvalid_0's auc: 0.869647\tvalid_0's binary_logloss: 0.393936\n",
      "[815]\tvalid_0's auc: 0.869636\tvalid_0's binary_logloss: 0.393922\n",
      "[816]\tvalid_0's auc: 0.869619\tvalid_0's binary_logloss: 0.393928\n",
      "[817]\tvalid_0's auc: 0.869619\tvalid_0's binary_logloss: 0.394003\n",
      "[818]\tvalid_0's auc: 0.869547\tvalid_0's binary_logloss: 0.39407\n",
      "[819]\tvalid_0's auc: 0.869575\tvalid_0's binary_logloss: 0.394071\n",
      "[820]\tvalid_0's auc: 0.869568\tvalid_0's binary_logloss: 0.394092\n",
      "[821]\tvalid_0's auc: 0.869572\tvalid_0's binary_logloss: 0.394111\n",
      "[822]\tvalid_0's auc: 0.869624\tvalid_0's binary_logloss: 0.394091\n",
      "[823]\tvalid_0's auc: 0.869529\tvalid_0's binary_logloss: 0.394195\n",
      "[824]\tvalid_0's auc: 0.869431\tvalid_0's binary_logloss: 0.394297\n",
      "[825]\tvalid_0's auc: 0.869465\tvalid_0's binary_logloss: 0.3943\n",
      "[826]\tvalid_0's auc: 0.869483\tvalid_0's binary_logloss: 0.394281\n",
      "[827]\tvalid_0's auc: 0.869496\tvalid_0's binary_logloss: 0.394287\n",
      "[828]\tvalid_0's auc: 0.869501\tvalid_0's binary_logloss: 0.394285\n",
      "[829]\tvalid_0's auc: 0.869479\tvalid_0's binary_logloss: 0.394301\n",
      "[830]\tvalid_0's auc: 0.86948\tvalid_0's binary_logloss: 0.394337\n",
      "[831]\tvalid_0's auc: 0.869483\tvalid_0's binary_logloss: 0.39422\n",
      "[832]\tvalid_0's auc: 0.869503\tvalid_0's binary_logloss: 0.39412\n",
      "[833]\tvalid_0's auc: 0.869515\tvalid_0's binary_logloss: 0.394024\n",
      "[834]\tvalid_0's auc: 0.869522\tvalid_0's binary_logloss: 0.393967\n",
      "[835]\tvalid_0's auc: 0.869475\tvalid_0's binary_logloss: 0.393955\n",
      "[836]\tvalid_0's auc: 0.869473\tvalid_0's binary_logloss: 0.393841\n",
      "[837]\tvalid_0's auc: 0.869536\tvalid_0's binary_logloss: 0.393647\n",
      "[838]\tvalid_0's auc: 0.869527\tvalid_0's binary_logloss: 0.393567\n",
      "[839]\tvalid_0's auc: 0.869558\tvalid_0's binary_logloss: 0.393441\n",
      "[840]\tvalid_0's auc: 0.869496\tvalid_0's binary_logloss: 0.393427\n",
      "[841]\tvalid_0's auc: 0.869543\tvalid_0's binary_logloss: 0.393343\n",
      "[842]\tvalid_0's auc: 0.869529\tvalid_0's binary_logloss: 0.393366\n",
      "[843]\tvalid_0's auc: 0.869502\tvalid_0's binary_logloss: 0.39338\n",
      "[844]\tvalid_0's auc: 0.86948\tvalid_0's binary_logloss: 0.393408\n",
      "[845]\tvalid_0's auc: 0.86949\tvalid_0's binary_logloss: 0.393337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[846]\tvalid_0's auc: 0.869493\tvalid_0's binary_logloss: 0.393363\n",
      "[847]\tvalid_0's auc: 0.86947\tvalid_0's binary_logloss: 0.393381\n",
      "[848]\tvalid_0's auc: 0.869482\tvalid_0's binary_logloss: 0.393415\n",
      "[849]\tvalid_0's auc: 0.869467\tvalid_0's binary_logloss: 0.393325\n",
      "[850]\tvalid_0's auc: 0.869446\tvalid_0's binary_logloss: 0.393358\n",
      "[851]\tvalid_0's auc: 0.869418\tvalid_0's binary_logloss: 0.393331\n",
      "[852]\tvalid_0's auc: 0.869388\tvalid_0's binary_logloss: 0.393333\n",
      "[853]\tvalid_0's auc: 0.869399\tvalid_0's binary_logloss: 0.393298\n",
      "[854]\tvalid_0's auc: 0.869297\tvalid_0's binary_logloss: 0.393371\n",
      "[855]\tvalid_0's auc: 0.869312\tvalid_0's binary_logloss: 0.393337\n",
      "[856]\tvalid_0's auc: 0.869322\tvalid_0's binary_logloss: 0.393264\n",
      "[857]\tvalid_0's auc: 0.869318\tvalid_0's binary_logloss: 0.393262\n",
      "[858]\tvalid_0's auc: 0.86934\tvalid_0's binary_logloss: 0.393206\n",
      "[859]\tvalid_0's auc: 0.869316\tvalid_0's binary_logloss: 0.393197\n",
      "[860]\tvalid_0's auc: 0.869332\tvalid_0's binary_logloss: 0.393139\n",
      "[861]\tvalid_0's auc: 0.869388\tvalid_0's binary_logloss: 0.393139\n",
      "[862]\tvalid_0's auc: 0.869378\tvalid_0's binary_logloss: 0.393169\n",
      "[863]\tvalid_0's auc: 0.869357\tvalid_0's binary_logloss: 0.393219\n",
      "[864]\tvalid_0's auc: 0.869375\tvalid_0's binary_logloss: 0.39327\n",
      "[865]\tvalid_0's auc: 0.869336\tvalid_0's binary_logloss: 0.393375\n",
      "[866]\tvalid_0's auc: 0.869371\tvalid_0's binary_logloss: 0.393274\n",
      "[867]\tvalid_0's auc: 0.869297\tvalid_0's binary_logloss: 0.393353\n",
      "[868]\tvalid_0's auc: 0.869298\tvalid_0's binary_logloss: 0.393322\n",
      "[869]\tvalid_0's auc: 0.869267\tvalid_0's binary_logloss: 0.393285\n",
      "[870]\tvalid_0's auc: 0.869235\tvalid_0's binary_logloss: 0.393317\n",
      "[871]\tvalid_0's auc: 0.869241\tvalid_0's binary_logloss: 0.393223\n",
      "[872]\tvalid_0's auc: 0.869239\tvalid_0's binary_logloss: 0.393184\n",
      "[873]\tvalid_0's auc: 0.869206\tvalid_0's binary_logloss: 0.393165\n",
      "[874]\tvalid_0's auc: 0.869219\tvalid_0's binary_logloss: 0.393084\n",
      "[875]\tvalid_0's auc: 0.869203\tvalid_0's binary_logloss: 0.393047\n",
      "[876]\tvalid_0's auc: 0.869205\tvalid_0's binary_logloss: 0.393068\n",
      "[877]\tvalid_0's auc: 0.869173\tvalid_0's binary_logloss: 0.393068\n",
      "[878]\tvalid_0's auc: 0.869172\tvalid_0's binary_logloss: 0.39312\n",
      "[879]\tvalid_0's auc: 0.869187\tvalid_0's binary_logloss: 0.39309\n",
      "[880]\tvalid_0's auc: 0.869182\tvalid_0's binary_logloss: 0.393108\n",
      "[881]\tvalid_0's auc: 0.869196\tvalid_0's binary_logloss: 0.39316\n",
      "[882]\tvalid_0's auc: 0.86922\tvalid_0's binary_logloss: 0.393187\n",
      "[883]\tvalid_0's auc: 0.869217\tvalid_0's binary_logloss: 0.39316\n",
      "[884]\tvalid_0's auc: 0.869207\tvalid_0's binary_logloss: 0.393167\n",
      "[885]\tvalid_0's auc: 0.869253\tvalid_0's binary_logloss: 0.393104\n",
      "[886]\tvalid_0's auc: 0.869295\tvalid_0's binary_logloss: 0.392988\n",
      "[887]\tvalid_0's auc: 0.869295\tvalid_0's binary_logloss: 0.392918\n",
      "[888]\tvalid_0's auc: 0.869257\tvalid_0's binary_logloss: 0.392881\n",
      "[889]\tvalid_0's auc: 0.869264\tvalid_0's binary_logloss: 0.392789\n",
      "[890]\tvalid_0's auc: 0.86922\tvalid_0's binary_logloss: 0.392736\n",
      "[891]\tvalid_0's auc: 0.869185\tvalid_0's binary_logloss: 0.392656\n",
      "[892]\tvalid_0's auc: 0.869162\tvalid_0's binary_logloss: 0.392594\n",
      "[893]\tvalid_0's auc: 0.869168\tvalid_0's binary_logloss: 0.392465\n",
      "[894]\tvalid_0's auc: 0.869178\tvalid_0's binary_logloss: 0.392364\n",
      "[895]\tvalid_0's auc: 0.869191\tvalid_0's binary_logloss: 0.392257\n",
      "[896]\tvalid_0's auc: 0.869214\tvalid_0's binary_logloss: 0.39227\n",
      "[897]\tvalid_0's auc: 0.869212\tvalid_0's binary_logloss: 0.392303\n",
      "[898]\tvalid_0's auc: 0.869234\tvalid_0's binary_logloss: 0.392321\n",
      "[899]\tvalid_0's auc: 0.869225\tvalid_0's binary_logloss: 0.392337\n",
      "[900]\tvalid_0's auc: 0.869221\tvalid_0's binary_logloss: 0.392374\n",
      "[901]\tvalid_0's auc: 0.869221\tvalid_0's binary_logloss: 0.392239\n",
      "[902]\tvalid_0's auc: 0.869164\tvalid_0's binary_logloss: 0.39226\n",
      "[903]\tvalid_0's auc: 0.869132\tvalid_0's binary_logloss: 0.392257\n",
      "[904]\tvalid_0's auc: 0.869055\tvalid_0's binary_logloss: 0.392226\n",
      "[905]\tvalid_0's auc: 0.869052\tvalid_0's binary_logloss: 0.392193\n",
      "[906]\tvalid_0's auc: 0.868996\tvalid_0's binary_logloss: 0.392224\n",
      "[907]\tvalid_0's auc: 0.868999\tvalid_0's binary_logloss: 0.39223\n",
      "[908]\tvalid_0's auc: 0.868978\tvalid_0's binary_logloss: 0.392235\n",
      "[909]\tvalid_0's auc: 0.868971\tvalid_0's binary_logloss: 0.392059\n",
      "[910]\tvalid_0's auc: 0.868916\tvalid_0's binary_logloss: 0.392068\n",
      "[911]\tvalid_0's auc: 0.868902\tvalid_0's binary_logloss: 0.392102\n",
      "[912]\tvalid_0's auc: 0.86885\tvalid_0's binary_logloss: 0.392235\n",
      "[913]\tvalid_0's auc: 0.868847\tvalid_0's binary_logloss: 0.392362\n",
      "[914]\tvalid_0's auc: 0.86885\tvalid_0's binary_logloss: 0.392378\n",
      "[915]\tvalid_0's auc: 0.868881\tvalid_0's binary_logloss: 0.392364\n",
      "[916]\tvalid_0's auc: 0.868853\tvalid_0's binary_logloss: 0.39239\n",
      "[917]\tvalid_0's auc: 0.868877\tvalid_0's binary_logloss: 0.392364\n",
      "[918]\tvalid_0's auc: 0.868876\tvalid_0's binary_logloss: 0.392386\n",
      "[919]\tvalid_0's auc: 0.868885\tvalid_0's binary_logloss: 0.392435\n",
      "[920]\tvalid_0's auc: 0.868832\tvalid_0's binary_logloss: 0.392507\n",
      "[921]\tvalid_0's auc: 0.868877\tvalid_0's binary_logloss: 0.39247\n",
      "[922]\tvalid_0's auc: 0.868877\tvalid_0's binary_logloss: 0.392439\n",
      "[923]\tvalid_0's auc: 0.868866\tvalid_0's binary_logloss: 0.392497\n",
      "[924]\tvalid_0's auc: 0.868863\tvalid_0's binary_logloss: 0.392468\n",
      "[925]\tvalid_0's auc: 0.868889\tvalid_0's binary_logloss: 0.392403\n",
      "[926]\tvalid_0's auc: 0.868881\tvalid_0's binary_logloss: 0.392416\n",
      "[927]\tvalid_0's auc: 0.868865\tvalid_0's binary_logloss: 0.392415\n",
      "[928]\tvalid_0's auc: 0.868854\tvalid_0's binary_logloss: 0.392385\n",
      "[929]\tvalid_0's auc: 0.868885\tvalid_0's binary_logloss: 0.392349\n",
      "[930]\tvalid_0's auc: 0.868819\tvalid_0's binary_logloss: 0.392378\n",
      "[931]\tvalid_0's auc: 0.868796\tvalid_0's binary_logloss: 0.392282\n",
      "[932]\tvalid_0's auc: 0.868819\tvalid_0's binary_logloss: 0.392077\n",
      "[933]\tvalid_0's auc: 0.868767\tvalid_0's binary_logloss: 0.39202\n",
      "Early stopping, best iteration is:\n",
      "[433]\tvalid_0's auc: 0.871597\tvalid_0's binary_logloss: 0.405652\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(params,  \n",
    "                lgb_train,  \n",
    "                num_boost_round=10000,  \n",
    "                valid_sets=lgb_eval,  \n",
    "                early_stopping_rounds=500)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train2=lgb.Dataset(pd.concat([train_x,df2],axis=1),train_y)\n",
    "gbm = lgb.train(params,  \n",
    "                lgb_train2,  \n",
    "                num_boost_round=500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters = {'max_depth': [15, 20, 25, 30, 35],\n",
    "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
    "              'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "              'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "              'bagging_freq': [2, 4, 5, 6, 8],\n",
    "              'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
    "              'lambda_l2': [0, 10, 15, 35, 40],\n",
    "              'cat_smooth': [1, 10, 15, 20, 35]\n",
    "}\n",
    "gbm = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         objective = 'binary',\n",
    "                         metric = 'auc',\n",
    "                         verbose = 0,\n",
    "                         learning_rate = 0.01,\n",
    "                         num_leaves = 35,\n",
    "                         feature_fraction=0.8,\n",
    "                         bagging_fraction= 0.9,\n",
    "                         bagging_freq= 8,\n",
    "                         lambda_l1= 0.6,\n",
    "                         lambda_l2= 0)\n",
    "gsearch = GridSearchCV(gbm, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "gsearch.fit(pd.concat([train_x,df2],axis=1), train_y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on the testing data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-12205817a2a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fit on the testing data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "#xgb_train = xgb.DMatrix(pd.concat([train_x,df2],axis=1), label=train_y)\n",
    "xgb_train = xgb.DMatrix(X_train, y_train)  \n",
    "xgb_eval = xgb.DMatrix(X_test, y_test)  \n",
    "'''\n",
    "clf = xgb.XGBClassifier(\n",
    "    missing=9999999999,\n",
    "    max_depth = 7, min_child_weight = 3,\n",
    "    gamma=0.8,\n",
    "    colsample_bytree=0.9,\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.01, \n",
    "    objective='binary:logistic',\n",
    "    subsample=1.0,\n",
    "    scale_pos_weight = 2,\n",
    "    seed=1301\n",
    ")\n",
    "\n",
    "\n",
    "print('Fit on the training data')\n",
    "clf.fit(X_train, y_train, eval_metric='error')#训练clf\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Fit on the testing data')\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'booster':'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth':7,\n",
    "    'lambda':3,\n",
    "    'subsample':0.75,\n",
    "    'colsample_bytree':0.75,\n",
    "    'min_child_weight':1,\n",
    "    'eta': 0.01,\n",
    "    'seed':0,\n",
    "    'nthread':8,\n",
    "     'silent':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82439\ttest-auc:0.81939\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 500 rounds.\n",
      "[1]\ttrain-auc:0.82682\ttest-auc:0.82141\n",
      "[2]\ttrain-auc:0.83773\ttest-auc:0.82841\n",
      "[3]\ttrain-auc:0.83751\ttest-auc:0.82733\n",
      "[4]\ttrain-auc:0.84156\ttest-auc:0.83021\n",
      "[5]\ttrain-auc:0.84202\ttest-auc:0.83069\n",
      "[6]\ttrain-auc:0.84142\ttest-auc:0.83083\n",
      "[7]\ttrain-auc:0.84122\ttest-auc:0.83077\n",
      "[8]\ttrain-auc:0.84148\ttest-auc:0.83058\n",
      "[9]\ttrain-auc:0.84179\ttest-auc:0.83090\n",
      "[10]\ttrain-auc:0.84194\ttest-auc:0.83113\n",
      "[11]\ttrain-auc:0.84176\ttest-auc:0.83091\n",
      "[12]\ttrain-auc:0.84219\ttest-auc:0.83123\n",
      "[13]\ttrain-auc:0.84268\ttest-auc:0.83180\n",
      "[14]\ttrain-auc:0.84414\ttest-auc:0.83292\n",
      "[15]\ttrain-auc:0.84373\ttest-auc:0.83280\n",
      "[16]\ttrain-auc:0.84375\ttest-auc:0.83269\n",
      "[17]\ttrain-auc:0.84440\ttest-auc:0.83334\n",
      "[18]\ttrain-auc:0.84482\ttest-auc:0.83443\n",
      "[19]\ttrain-auc:0.84456\ttest-auc:0.83430\n",
      "[20]\ttrain-auc:0.84446\ttest-auc:0.83422\n",
      "[21]\ttrain-auc:0.84473\ttest-auc:0.83388\n",
      "[22]\ttrain-auc:0.84478\ttest-auc:0.83364\n",
      "[23]\ttrain-auc:0.84455\ttest-auc:0.83366\n",
      "[24]\ttrain-auc:0.84436\ttest-auc:0.83353\n",
      "[25]\ttrain-auc:0.84466\ttest-auc:0.83359\n",
      "[26]\ttrain-auc:0.84462\ttest-auc:0.83338\n",
      "[27]\ttrain-auc:0.84526\ttest-auc:0.83398\n",
      "[28]\ttrain-auc:0.84573\ttest-auc:0.83452\n",
      "[29]\ttrain-auc:0.84582\ttest-auc:0.83448\n",
      "[30]\ttrain-auc:0.84727\ttest-auc:0.83560\n",
      "[31]\ttrain-auc:0.84731\ttest-auc:0.83551\n",
      "[32]\ttrain-auc:0.84728\ttest-auc:0.83545\n",
      "[33]\ttrain-auc:0.84730\ttest-auc:0.83549\n",
      "[34]\ttrain-auc:0.84767\ttest-auc:0.83586\n",
      "[35]\ttrain-auc:0.84780\ttest-auc:0.83583\n",
      "[36]\ttrain-auc:0.84781\ttest-auc:0.83578\n",
      "[37]\ttrain-auc:0.84779\ttest-auc:0.83586\n",
      "[38]\ttrain-auc:0.84767\ttest-auc:0.83573\n",
      "[39]\ttrain-auc:0.84773\ttest-auc:0.83569\n",
      "[40]\ttrain-auc:0.84804\ttest-auc:0.83594\n",
      "[41]\ttrain-auc:0.84803\ttest-auc:0.83584\n",
      "[42]\ttrain-auc:0.84800\ttest-auc:0.83581\n",
      "[43]\ttrain-auc:0.84799\ttest-auc:0.83583\n",
      "[44]\ttrain-auc:0.84803\ttest-auc:0.83585\n",
      "[45]\ttrain-auc:0.84797\ttest-auc:0.83583\n",
      "[46]\ttrain-auc:0.84797\ttest-auc:0.83562\n",
      "[47]\ttrain-auc:0.84799\ttest-auc:0.83553\n",
      "[48]\ttrain-auc:0.84801\ttest-auc:0.83557\n",
      "[49]\ttrain-auc:0.84813\ttest-auc:0.83557\n",
      "[50]\ttrain-auc:0.84813\ttest-auc:0.83555\n",
      "[51]\ttrain-auc:0.84835\ttest-auc:0.83572\n",
      "[52]\ttrain-auc:0.84839\ttest-auc:0.83580\n",
      "[53]\ttrain-auc:0.84836\ttest-auc:0.83577\n",
      "[54]\ttrain-auc:0.84838\ttest-auc:0.83586\n",
      "[55]\ttrain-auc:0.84838\ttest-auc:0.83593\n",
      "[56]\ttrain-auc:0.84837\ttest-auc:0.83597\n",
      "[57]\ttrain-auc:0.84862\ttest-auc:0.83620\n",
      "[58]\ttrain-auc:0.84870\ttest-auc:0.83620\n",
      "[59]\ttrain-auc:0.84919\ttest-auc:0.83663\n",
      "[60]\ttrain-auc:0.84945\ttest-auc:0.83686\n",
      "[61]\ttrain-auc:0.84973\ttest-auc:0.83715\n",
      "[62]\ttrain-auc:0.84984\ttest-auc:0.83723\n",
      "[63]\ttrain-auc:0.84985\ttest-auc:0.83713\n",
      "[64]\ttrain-auc:0.84999\ttest-auc:0.83710\n",
      "[65]\ttrain-auc:0.85049\ttest-auc:0.83743\n",
      "[66]\ttrain-auc:0.85052\ttest-auc:0.83747\n",
      "[67]\ttrain-auc:0.85081\ttest-auc:0.83770\n",
      "[68]\ttrain-auc:0.85113\ttest-auc:0.83801\n",
      "[69]\ttrain-auc:0.85119\ttest-auc:0.83811\n",
      "[70]\ttrain-auc:0.85161\ttest-auc:0.83857\n",
      "[71]\ttrain-auc:0.85201\ttest-auc:0.83900\n",
      "[72]\ttrain-auc:0.85240\ttest-auc:0.83929\n",
      "[73]\ttrain-auc:0.85245\ttest-auc:0.83931\n",
      "[74]\ttrain-auc:0.85262\ttest-auc:0.83949\n",
      "[75]\ttrain-auc:0.85282\ttest-auc:0.83971\n",
      "[76]\ttrain-auc:0.85320\ttest-auc:0.84013\n",
      "[77]\ttrain-auc:0.85343\ttest-auc:0.84021\n",
      "[78]\ttrain-auc:0.85369\ttest-auc:0.84052\n",
      "[79]\ttrain-auc:0.85397\ttest-auc:0.84073\n",
      "[80]\ttrain-auc:0.85410\ttest-auc:0.84088\n",
      "[81]\ttrain-auc:0.85422\ttest-auc:0.84102\n",
      "[82]\ttrain-auc:0.85440\ttest-auc:0.84113\n",
      "[83]\ttrain-auc:0.85481\ttest-auc:0.84143\n",
      "[84]\ttrain-auc:0.85499\ttest-auc:0.84157\n",
      "[85]\ttrain-auc:0.85510\ttest-auc:0.84163\n",
      "[86]\ttrain-auc:0.85537\ttest-auc:0.84184\n",
      "[87]\ttrain-auc:0.85562\ttest-auc:0.84191\n",
      "[88]\ttrain-auc:0.85573\ttest-auc:0.84196\n",
      "[89]\ttrain-auc:0.85572\ttest-auc:0.84197\n",
      "[90]\ttrain-auc:0.85603\ttest-auc:0.84218\n",
      "[91]\ttrain-auc:0.85636\ttest-auc:0.84245\n",
      "[92]\ttrain-auc:0.85643\ttest-auc:0.84244\n",
      "[93]\ttrain-auc:0.85658\ttest-auc:0.84254\n",
      "[94]\ttrain-auc:0.85669\ttest-auc:0.84263\n",
      "[95]\ttrain-auc:0.85676\ttest-auc:0.84266\n",
      "[96]\ttrain-auc:0.85676\ttest-auc:0.84264\n",
      "[97]\ttrain-auc:0.85685\ttest-auc:0.84275\n",
      "[98]\ttrain-auc:0.85700\ttest-auc:0.84288\n",
      "[99]\ttrain-auc:0.85716\ttest-auc:0.84299\n",
      "[100]\ttrain-auc:0.85725\ttest-auc:0.84308\n",
      "[101]\ttrain-auc:0.85744\ttest-auc:0.84314\n",
      "[102]\ttrain-auc:0.85775\ttest-auc:0.84348\n",
      "[103]\ttrain-auc:0.85781\ttest-auc:0.84351\n",
      "[104]\ttrain-auc:0.85809\ttest-auc:0.84373\n",
      "[105]\ttrain-auc:0.85813\ttest-auc:0.84375\n",
      "[106]\ttrain-auc:0.85820\ttest-auc:0.84375\n",
      "[107]\ttrain-auc:0.85840\ttest-auc:0.84385\n",
      "[108]\ttrain-auc:0.85852\ttest-auc:0.84397\n",
      "[109]\ttrain-auc:0.85861\ttest-auc:0.84400\n",
      "[110]\ttrain-auc:0.85874\ttest-auc:0.84409\n",
      "[111]\ttrain-auc:0.85894\ttest-auc:0.84422\n",
      "[112]\ttrain-auc:0.85908\ttest-auc:0.84434\n",
      "[113]\ttrain-auc:0.85930\ttest-auc:0.84450\n",
      "[114]\ttrain-auc:0.85944\ttest-auc:0.84457\n",
      "[115]\ttrain-auc:0.85956\ttest-auc:0.84457\n",
      "[116]\ttrain-auc:0.85986\ttest-auc:0.84486\n",
      "[117]\ttrain-auc:0.86015\ttest-auc:0.84508\n",
      "[118]\ttrain-auc:0.86037\ttest-auc:0.84527\n",
      "[119]\ttrain-auc:0.86055\ttest-auc:0.84542\n",
      "[120]\ttrain-auc:0.86065\ttest-auc:0.84542\n",
      "[121]\ttrain-auc:0.86086\ttest-auc:0.84558\n",
      "[122]\ttrain-auc:0.86107\ttest-auc:0.84570\n",
      "[123]\ttrain-auc:0.86118\ttest-auc:0.84573\n",
      "[124]\ttrain-auc:0.86129\ttest-auc:0.84577\n",
      "[125]\ttrain-auc:0.86135\ttest-auc:0.84579\n",
      "[126]\ttrain-auc:0.86157\ttest-auc:0.84596\n",
      "[127]\ttrain-auc:0.86169\ttest-auc:0.84605\n",
      "[128]\ttrain-auc:0.86176\ttest-auc:0.84609\n",
      "[129]\ttrain-auc:0.86179\ttest-auc:0.84608\n",
      "[130]\ttrain-auc:0.86185\ttest-auc:0.84612\n",
      "[131]\ttrain-auc:0.86190\ttest-auc:0.84613\n",
      "[132]\ttrain-auc:0.86193\ttest-auc:0.84615\n",
      "[133]\ttrain-auc:0.86204\ttest-auc:0.84622\n",
      "[134]\ttrain-auc:0.86213\ttest-auc:0.84619\n",
      "[135]\ttrain-auc:0.86218\ttest-auc:0.84622\n",
      "[136]\ttrain-auc:0.86228\ttest-auc:0.84621\n",
      "[137]\ttrain-auc:0.86249\ttest-auc:0.84636\n",
      "[138]\ttrain-auc:0.86266\ttest-auc:0.84653\n",
      "[139]\ttrain-auc:0.86272\ttest-auc:0.84651\n",
      "[140]\ttrain-auc:0.86279\ttest-auc:0.84651\n",
      "[141]\ttrain-auc:0.86296\ttest-auc:0.84664\n",
      "[142]\ttrain-auc:0.86314\ttest-auc:0.84685\n",
      "[143]\ttrain-auc:0.86334\ttest-auc:0.84696\n",
      "[144]\ttrain-auc:0.86354\ttest-auc:0.84713\n",
      "[145]\ttrain-auc:0.86369\ttest-auc:0.84723\n",
      "[146]\ttrain-auc:0.86386\ttest-auc:0.84736\n",
      "[147]\ttrain-auc:0.86403\ttest-auc:0.84752\n",
      "[148]\ttrain-auc:0.86415\ttest-auc:0.84758\n",
      "[149]\ttrain-auc:0.86428\ttest-auc:0.84764\n",
      "[150]\ttrain-auc:0.86438\ttest-auc:0.84772\n",
      "[151]\ttrain-auc:0.86455\ttest-auc:0.84779\n",
      "[152]\ttrain-auc:0.86469\ttest-auc:0.84787\n",
      "[153]\ttrain-auc:0.86475\ttest-auc:0.84794\n",
      "[154]\ttrain-auc:0.86494\ttest-auc:0.84803\n",
      "[155]\ttrain-auc:0.86510\ttest-auc:0.84814\n",
      "[156]\ttrain-auc:0.86521\ttest-auc:0.84821\n",
      "[157]\ttrain-auc:0.86531\ttest-auc:0.84831\n",
      "[158]\ttrain-auc:0.86542\ttest-auc:0.84837\n",
      "[159]\ttrain-auc:0.86549\ttest-auc:0.84843\n",
      "[160]\ttrain-auc:0.86554\ttest-auc:0.84845\n",
      "[161]\ttrain-auc:0.86563\ttest-auc:0.84847\n",
      "[162]\ttrain-auc:0.86582\ttest-auc:0.84857\n",
      "[163]\ttrain-auc:0.86605\ttest-auc:0.84869\n",
      "[164]\ttrain-auc:0.86613\ttest-auc:0.84874\n",
      "[165]\ttrain-auc:0.86623\ttest-auc:0.84876\n",
      "[166]\ttrain-auc:0.86639\ttest-auc:0.84889\n",
      "[167]\ttrain-auc:0.86650\ttest-auc:0.84902\n",
      "[168]\ttrain-auc:0.86659\ttest-auc:0.84910\n",
      "[169]\ttrain-auc:0.86674\ttest-auc:0.84917\n",
      "[170]\ttrain-auc:0.86684\ttest-auc:0.84925\n",
      "[171]\ttrain-auc:0.86704\ttest-auc:0.84942\n",
      "[172]\ttrain-auc:0.86713\ttest-auc:0.84948\n",
      "[173]\ttrain-auc:0.86731\ttest-auc:0.84959\n",
      "[174]\ttrain-auc:0.86741\ttest-auc:0.84967\n",
      "[175]\ttrain-auc:0.86746\ttest-auc:0.84970\n",
      "[176]\ttrain-auc:0.86756\ttest-auc:0.84975\n",
      "[177]\ttrain-auc:0.86773\ttest-auc:0.84992\n",
      "[178]\ttrain-auc:0.86785\ttest-auc:0.84997\n",
      "[179]\ttrain-auc:0.86800\ttest-auc:0.85010\n",
      "[180]\ttrain-auc:0.86808\ttest-auc:0.85015\n",
      "[181]\ttrain-auc:0.86821\ttest-auc:0.85021\n",
      "[182]\ttrain-auc:0.86825\ttest-auc:0.85022\n",
      "[183]\ttrain-auc:0.86845\ttest-auc:0.85040\n",
      "[184]\ttrain-auc:0.86864\ttest-auc:0.85052\n",
      "[185]\ttrain-auc:0.86878\ttest-auc:0.85065\n",
      "[186]\ttrain-auc:0.86889\ttest-auc:0.85067\n",
      "[187]\ttrain-auc:0.86901\ttest-auc:0.85074\n",
      "[188]\ttrain-auc:0.86906\ttest-auc:0.85078\n",
      "[189]\ttrain-auc:0.86923\ttest-auc:0.85088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190]\ttrain-auc:0.86935\ttest-auc:0.85100\n",
      "[191]\ttrain-auc:0.86946\ttest-auc:0.85109\n",
      "[192]\ttrain-auc:0.86957\ttest-auc:0.85115\n",
      "[193]\ttrain-auc:0.86970\ttest-auc:0.85120\n",
      "[194]\ttrain-auc:0.86988\ttest-auc:0.85128\n",
      "[195]\ttrain-auc:0.87000\ttest-auc:0.85135\n",
      "[196]\ttrain-auc:0.87018\ttest-auc:0.85145\n",
      "[197]\ttrain-auc:0.87033\ttest-auc:0.85152\n",
      "[198]\ttrain-auc:0.87035\ttest-auc:0.85154\n",
      "[199]\ttrain-auc:0.87048\ttest-auc:0.85165\n",
      "[200]\ttrain-auc:0.87058\ttest-auc:0.85175\n",
      "[201]\ttrain-auc:0.87066\ttest-auc:0.85179\n",
      "[202]\ttrain-auc:0.87080\ttest-auc:0.85194\n",
      "[203]\ttrain-auc:0.87095\ttest-auc:0.85202\n",
      "[204]\ttrain-auc:0.87101\ttest-auc:0.85204\n",
      "[205]\ttrain-auc:0.87114\ttest-auc:0.85217\n",
      "[206]\ttrain-auc:0.87131\ttest-auc:0.85223\n",
      "[207]\ttrain-auc:0.87144\ttest-auc:0.85235\n",
      "[208]\ttrain-auc:0.87156\ttest-auc:0.85244\n",
      "[209]\ttrain-auc:0.87161\ttest-auc:0.85246\n",
      "[210]\ttrain-auc:0.87191\ttest-auc:0.85270\n",
      "[211]\ttrain-auc:0.87202\ttest-auc:0.85279\n",
      "[212]\ttrain-auc:0.87208\ttest-auc:0.85280\n",
      "[213]\ttrain-auc:0.87222\ttest-auc:0.85288\n",
      "[214]\ttrain-auc:0.87236\ttest-auc:0.85295\n",
      "[215]\ttrain-auc:0.87244\ttest-auc:0.85301\n",
      "[216]\ttrain-auc:0.87258\ttest-auc:0.85308\n",
      "[217]\ttrain-auc:0.87269\ttest-auc:0.85313\n",
      "[218]\ttrain-auc:0.87274\ttest-auc:0.85318\n",
      "[219]\ttrain-auc:0.87289\ttest-auc:0.85326\n",
      "[220]\ttrain-auc:0.87307\ttest-auc:0.85342\n",
      "[221]\ttrain-auc:0.87317\ttest-auc:0.85349\n",
      "[222]\ttrain-auc:0.87332\ttest-auc:0.85362\n",
      "[223]\ttrain-auc:0.87347\ttest-auc:0.85367\n",
      "[224]\ttrain-auc:0.87354\ttest-auc:0.85374\n",
      "[225]\ttrain-auc:0.87368\ttest-auc:0.85385\n",
      "[226]\ttrain-auc:0.87388\ttest-auc:0.85400\n",
      "[227]\ttrain-auc:0.87402\ttest-auc:0.85414\n",
      "[228]\ttrain-auc:0.87416\ttest-auc:0.85425\n",
      "[229]\ttrain-auc:0.87431\ttest-auc:0.85435\n",
      "[230]\ttrain-auc:0.87443\ttest-auc:0.85448\n",
      "[231]\ttrain-auc:0.87455\ttest-auc:0.85458\n",
      "[232]\ttrain-auc:0.87467\ttest-auc:0.85469\n",
      "[233]\ttrain-auc:0.87481\ttest-auc:0.85481\n",
      "[234]\ttrain-auc:0.87489\ttest-auc:0.85486\n",
      "[235]\ttrain-auc:0.87501\ttest-auc:0.85493\n",
      "[236]\ttrain-auc:0.87507\ttest-auc:0.85499\n",
      "[237]\ttrain-auc:0.87513\ttest-auc:0.85504\n",
      "[238]\ttrain-auc:0.87524\ttest-auc:0.85510\n",
      "[239]\ttrain-auc:0.87530\ttest-auc:0.85511\n",
      "[240]\ttrain-auc:0.87536\ttest-auc:0.85515\n",
      "[241]\ttrain-auc:0.87545\ttest-auc:0.85516\n",
      "[242]\ttrain-auc:0.87555\ttest-auc:0.85519\n",
      "[243]\ttrain-auc:0.87565\ttest-auc:0.85522\n",
      "[244]\ttrain-auc:0.87577\ttest-auc:0.85528\n",
      "[245]\ttrain-auc:0.87594\ttest-auc:0.85537\n",
      "[246]\ttrain-auc:0.87601\ttest-auc:0.85537\n",
      "[247]\ttrain-auc:0.87612\ttest-auc:0.85545\n",
      "[248]\ttrain-auc:0.87627\ttest-auc:0.85558\n",
      "[249]\ttrain-auc:0.87634\ttest-auc:0.85564\n",
      "[250]\ttrain-auc:0.87643\ttest-auc:0.85568\n",
      "[251]\ttrain-auc:0.87654\ttest-auc:0.85577\n",
      "[252]\ttrain-auc:0.87667\ttest-auc:0.85588\n",
      "[253]\ttrain-auc:0.87677\ttest-auc:0.85590\n",
      "[254]\ttrain-auc:0.87686\ttest-auc:0.85598\n",
      "[255]\ttrain-auc:0.87697\ttest-auc:0.85605\n",
      "[256]\ttrain-auc:0.87709\ttest-auc:0.85610\n",
      "[257]\ttrain-auc:0.87723\ttest-auc:0.85625\n",
      "[258]\ttrain-auc:0.87738\ttest-auc:0.85634\n",
      "[259]\ttrain-auc:0.87746\ttest-auc:0.85636\n",
      "[260]\ttrain-auc:0.87753\ttest-auc:0.85640\n",
      "[261]\ttrain-auc:0.87762\ttest-auc:0.85644\n",
      "[262]\ttrain-auc:0.87766\ttest-auc:0.85648\n",
      "[263]\ttrain-auc:0.87777\ttest-auc:0.85652\n",
      "[264]\ttrain-auc:0.87790\ttest-auc:0.85659\n",
      "[265]\ttrain-auc:0.87801\ttest-auc:0.85664\n",
      "[266]\ttrain-auc:0.87813\ttest-auc:0.85669\n",
      "[267]\ttrain-auc:0.87825\ttest-auc:0.85676\n",
      "[268]\ttrain-auc:0.87831\ttest-auc:0.85680\n",
      "[269]\ttrain-auc:0.87837\ttest-auc:0.85686\n",
      "[270]\ttrain-auc:0.87845\ttest-auc:0.85686\n",
      "[271]\ttrain-auc:0.87854\ttest-auc:0.85691\n",
      "[272]\ttrain-auc:0.87868\ttest-auc:0.85701\n",
      "[273]\ttrain-auc:0.87877\ttest-auc:0.85703\n",
      "[274]\ttrain-auc:0.87884\ttest-auc:0.85707\n",
      "[275]\ttrain-auc:0.87892\ttest-auc:0.85708\n",
      "[276]\ttrain-auc:0.87903\ttest-auc:0.85715\n",
      "[277]\ttrain-auc:0.87916\ttest-auc:0.85721\n",
      "[278]\ttrain-auc:0.87925\ttest-auc:0.85729\n",
      "[279]\ttrain-auc:0.87934\ttest-auc:0.85737\n",
      "[280]\ttrain-auc:0.87947\ttest-auc:0.85743\n",
      "[281]\ttrain-auc:0.87957\ttest-auc:0.85745\n",
      "[282]\ttrain-auc:0.87964\ttest-auc:0.85750\n",
      "[283]\ttrain-auc:0.87976\ttest-auc:0.85756\n",
      "[284]\ttrain-auc:0.87985\ttest-auc:0.85761\n",
      "[285]\ttrain-auc:0.87992\ttest-auc:0.85764\n",
      "[286]\ttrain-auc:0.87996\ttest-auc:0.85768\n",
      "[287]\ttrain-auc:0.88004\ttest-auc:0.85775\n",
      "[288]\ttrain-auc:0.88011\ttest-auc:0.85779\n",
      "[289]\ttrain-auc:0.88019\ttest-auc:0.85785\n",
      "[290]\ttrain-auc:0.88026\ttest-auc:0.85789\n",
      "[291]\ttrain-auc:0.88031\ttest-auc:0.85791\n",
      "[292]\ttrain-auc:0.88036\ttest-auc:0.85796\n",
      "[293]\ttrain-auc:0.88048\ttest-auc:0.85798\n",
      "[294]\ttrain-auc:0.88057\ttest-auc:0.85804\n",
      "[295]\ttrain-auc:0.88063\ttest-auc:0.85805\n",
      "[296]\ttrain-auc:0.88075\ttest-auc:0.85813\n",
      "[297]\ttrain-auc:0.88084\ttest-auc:0.85816\n",
      "[298]\ttrain-auc:0.88092\ttest-auc:0.85820\n",
      "[299]\ttrain-auc:0.88100\ttest-auc:0.85828\n",
      "[300]\ttrain-auc:0.88111\ttest-auc:0.85832\n",
      "[301]\ttrain-auc:0.88114\ttest-auc:0.85832\n",
      "[302]\ttrain-auc:0.88131\ttest-auc:0.85842\n",
      "[303]\ttrain-auc:0.88138\ttest-auc:0.85845\n",
      "[304]\ttrain-auc:0.88145\ttest-auc:0.85851\n",
      "[305]\ttrain-auc:0.88159\ttest-auc:0.85861\n",
      "[306]\ttrain-auc:0.88165\ttest-auc:0.85862\n",
      "[307]\ttrain-auc:0.88180\ttest-auc:0.85870\n",
      "[308]\ttrain-auc:0.88192\ttest-auc:0.85874\n",
      "[309]\ttrain-auc:0.88199\ttest-auc:0.85878\n",
      "[310]\ttrain-auc:0.88206\ttest-auc:0.85880\n",
      "[311]\ttrain-auc:0.88216\ttest-auc:0.85886\n",
      "[312]\ttrain-auc:0.88225\ttest-auc:0.85889\n",
      "[313]\ttrain-auc:0.88237\ttest-auc:0.85897\n",
      "[314]\ttrain-auc:0.88247\ttest-auc:0.85904\n",
      "[315]\ttrain-auc:0.88253\ttest-auc:0.85909\n",
      "[316]\ttrain-auc:0.88263\ttest-auc:0.85916\n",
      "[317]\ttrain-auc:0.88271\ttest-auc:0.85919\n",
      "[318]\ttrain-auc:0.88276\ttest-auc:0.85919\n",
      "[319]\ttrain-auc:0.88285\ttest-auc:0.85925\n",
      "[320]\ttrain-auc:0.88291\ttest-auc:0.85928\n",
      "[321]\ttrain-auc:0.88301\ttest-auc:0.85933\n",
      "[322]\ttrain-auc:0.88307\ttest-auc:0.85934\n",
      "[323]\ttrain-auc:0.88316\ttest-auc:0.85936\n",
      "[324]\ttrain-auc:0.88322\ttest-auc:0.85939\n",
      "[325]\ttrain-auc:0.88333\ttest-auc:0.85946\n",
      "[326]\ttrain-auc:0.88346\ttest-auc:0.85953\n",
      "[327]\ttrain-auc:0.88354\ttest-auc:0.85959\n",
      "[328]\ttrain-auc:0.88359\ttest-auc:0.85959\n",
      "[329]\ttrain-auc:0.88369\ttest-auc:0.85966\n",
      "[330]\ttrain-auc:0.88377\ttest-auc:0.85970\n",
      "[331]\ttrain-auc:0.88385\ttest-auc:0.85976\n",
      "[332]\ttrain-auc:0.88398\ttest-auc:0.85981\n",
      "[333]\ttrain-auc:0.88407\ttest-auc:0.85984\n",
      "[334]\ttrain-auc:0.88411\ttest-auc:0.85988\n",
      "[335]\ttrain-auc:0.88419\ttest-auc:0.85987\n",
      "[336]\ttrain-auc:0.88428\ttest-auc:0.85992\n",
      "[337]\ttrain-auc:0.88437\ttest-auc:0.85995\n",
      "[338]\ttrain-auc:0.88445\ttest-auc:0.86002\n",
      "[339]\ttrain-auc:0.88454\ttest-auc:0.86005\n",
      "[340]\ttrain-auc:0.88461\ttest-auc:0.86008\n",
      "[341]\ttrain-auc:0.88466\ttest-auc:0.86010\n",
      "[342]\ttrain-auc:0.88478\ttest-auc:0.86014\n",
      "[343]\ttrain-auc:0.88486\ttest-auc:0.86018\n",
      "[344]\ttrain-auc:0.88497\ttest-auc:0.86025\n",
      "[345]\ttrain-auc:0.88505\ttest-auc:0.86033\n",
      "[346]\ttrain-auc:0.88512\ttest-auc:0.86038\n",
      "[347]\ttrain-auc:0.88522\ttest-auc:0.86042\n",
      "[348]\ttrain-auc:0.88530\ttest-auc:0.86043\n",
      "[349]\ttrain-auc:0.88543\ttest-auc:0.86049\n",
      "[350]\ttrain-auc:0.88551\ttest-auc:0.86053\n",
      "[351]\ttrain-auc:0.88561\ttest-auc:0.86062\n",
      "[352]\ttrain-auc:0.88570\ttest-auc:0.86066\n",
      "[353]\ttrain-auc:0.88576\ttest-auc:0.86066\n",
      "[354]\ttrain-auc:0.88581\ttest-auc:0.86070\n",
      "[355]\ttrain-auc:0.88587\ttest-auc:0.86075\n",
      "[356]\ttrain-auc:0.88601\ttest-auc:0.86082\n",
      "[357]\ttrain-auc:0.88602\ttest-auc:0.86082\n",
      "[358]\ttrain-auc:0.88608\ttest-auc:0.86085\n",
      "[359]\ttrain-auc:0.88614\ttest-auc:0.86087\n",
      "[360]\ttrain-auc:0.88618\ttest-auc:0.86089\n",
      "[361]\ttrain-auc:0.88624\ttest-auc:0.86092\n",
      "[362]\ttrain-auc:0.88633\ttest-auc:0.86097\n",
      "[363]\ttrain-auc:0.88639\ttest-auc:0.86101\n",
      "[364]\ttrain-auc:0.88650\ttest-auc:0.86102\n",
      "[365]\ttrain-auc:0.88655\ttest-auc:0.86107\n",
      "[366]\ttrain-auc:0.88664\ttest-auc:0.86110\n",
      "[367]\ttrain-auc:0.88677\ttest-auc:0.86118\n",
      "[368]\ttrain-auc:0.88688\ttest-auc:0.86122\n",
      "[369]\ttrain-auc:0.88694\ttest-auc:0.86126\n",
      "[370]\ttrain-auc:0.88703\ttest-auc:0.86129\n",
      "[371]\ttrain-auc:0.88716\ttest-auc:0.86133\n",
      "[372]\ttrain-auc:0.88719\ttest-auc:0.86135\n",
      "[373]\ttrain-auc:0.88721\ttest-auc:0.86135\n",
      "[374]\ttrain-auc:0.88727\ttest-auc:0.86135\n",
      "[375]\ttrain-auc:0.88739\ttest-auc:0.86141\n",
      "[376]\ttrain-auc:0.88750\ttest-auc:0.86143\n",
      "[377]\ttrain-auc:0.88758\ttest-auc:0.86147\n",
      "[378]\ttrain-auc:0.88765\ttest-auc:0.86150\n",
      "[379]\ttrain-auc:0.88773\ttest-auc:0.86152\n",
      "[380]\ttrain-auc:0.88778\ttest-auc:0.86153\n",
      "[381]\ttrain-auc:0.88790\ttest-auc:0.86161\n",
      "[382]\ttrain-auc:0.88800\ttest-auc:0.86165\n",
      "[383]\ttrain-auc:0.88807\ttest-auc:0.86168\n",
      "[384]\ttrain-auc:0.88814\ttest-auc:0.86172\n",
      "[385]\ttrain-auc:0.88819\ttest-auc:0.86174\n",
      "[386]\ttrain-auc:0.88830\ttest-auc:0.86180\n",
      "[387]\ttrain-auc:0.88842\ttest-auc:0.86184\n",
      "[388]\ttrain-auc:0.88847\ttest-auc:0.86187\n",
      "[389]\ttrain-auc:0.88855\ttest-auc:0.86190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390]\ttrain-auc:0.88861\ttest-auc:0.86194\n",
      "[391]\ttrain-auc:0.88869\ttest-auc:0.86197\n",
      "[392]\ttrain-auc:0.88874\ttest-auc:0.86199\n",
      "[393]\ttrain-auc:0.88878\ttest-auc:0.86200\n",
      "[394]\ttrain-auc:0.88886\ttest-auc:0.86203\n",
      "[395]\ttrain-auc:0.88894\ttest-auc:0.86205\n",
      "[396]\ttrain-auc:0.88905\ttest-auc:0.86210\n",
      "[397]\ttrain-auc:0.88911\ttest-auc:0.86213\n",
      "[398]\ttrain-auc:0.88918\ttest-auc:0.86216\n",
      "[399]\ttrain-auc:0.88926\ttest-auc:0.86220\n",
      "[400]\ttrain-auc:0.88936\ttest-auc:0.86225\n",
      "[401]\ttrain-auc:0.88950\ttest-auc:0.86234\n",
      "[402]\ttrain-auc:0.88955\ttest-auc:0.86235\n",
      "[403]\ttrain-auc:0.88960\ttest-auc:0.86237\n",
      "[404]\ttrain-auc:0.88968\ttest-auc:0.86241\n",
      "[405]\ttrain-auc:0.88974\ttest-auc:0.86243\n",
      "[406]\ttrain-auc:0.88980\ttest-auc:0.86246\n",
      "[407]\ttrain-auc:0.88986\ttest-auc:0.86249\n",
      "[408]\ttrain-auc:0.88991\ttest-auc:0.86250\n",
      "[409]\ttrain-auc:0.88995\ttest-auc:0.86253\n",
      "[410]\ttrain-auc:0.89002\ttest-auc:0.86256\n",
      "[411]\ttrain-auc:0.89013\ttest-auc:0.86261\n",
      "[412]\ttrain-auc:0.89019\ttest-auc:0.86264\n",
      "[413]\ttrain-auc:0.89025\ttest-auc:0.86270\n",
      "[414]\ttrain-auc:0.89033\ttest-auc:0.86273\n",
      "[415]\ttrain-auc:0.89042\ttest-auc:0.86281\n",
      "[416]\ttrain-auc:0.89052\ttest-auc:0.86284\n",
      "[417]\ttrain-auc:0.89066\ttest-auc:0.86289\n",
      "[418]\ttrain-auc:0.89074\ttest-auc:0.86289\n",
      "[419]\ttrain-auc:0.89084\ttest-auc:0.86294\n",
      "[420]\ttrain-auc:0.89090\ttest-auc:0.86296\n",
      "[421]\ttrain-auc:0.89102\ttest-auc:0.86302\n",
      "[422]\ttrain-auc:0.89107\ttest-auc:0.86303\n",
      "[423]\ttrain-auc:0.89114\ttest-auc:0.86306\n",
      "[424]\ttrain-auc:0.89120\ttest-auc:0.86310\n",
      "[425]\ttrain-auc:0.89128\ttest-auc:0.86312\n",
      "[426]\ttrain-auc:0.89137\ttest-auc:0.86316\n",
      "[427]\ttrain-auc:0.89145\ttest-auc:0.86318\n",
      "[428]\ttrain-auc:0.89148\ttest-auc:0.86319\n",
      "[429]\ttrain-auc:0.89155\ttest-auc:0.86325\n",
      "[430]\ttrain-auc:0.89164\ttest-auc:0.86325\n",
      "[431]\ttrain-auc:0.89168\ttest-auc:0.86328\n",
      "[432]\ttrain-auc:0.89182\ttest-auc:0.86334\n",
      "[433]\ttrain-auc:0.89187\ttest-auc:0.86335\n",
      "[434]\ttrain-auc:0.89195\ttest-auc:0.86337\n",
      "[435]\ttrain-auc:0.89202\ttest-auc:0.86339\n",
      "[436]\ttrain-auc:0.89215\ttest-auc:0.86343\n",
      "[437]\ttrain-auc:0.89218\ttest-auc:0.86346\n",
      "[438]\ttrain-auc:0.89223\ttest-auc:0.86349\n",
      "[439]\ttrain-auc:0.89232\ttest-auc:0.86351\n",
      "[440]\ttrain-auc:0.89243\ttest-auc:0.86355\n",
      "[441]\ttrain-auc:0.89248\ttest-auc:0.86358\n",
      "[442]\ttrain-auc:0.89258\ttest-auc:0.86363\n",
      "[443]\ttrain-auc:0.89263\ttest-auc:0.86364\n",
      "[444]\ttrain-auc:0.89270\ttest-auc:0.86369\n",
      "[445]\ttrain-auc:0.89277\ttest-auc:0.86371\n",
      "[446]\ttrain-auc:0.89287\ttest-auc:0.86377\n",
      "[447]\ttrain-auc:0.89294\ttest-auc:0.86379\n",
      "[448]\ttrain-auc:0.89299\ttest-auc:0.86379\n",
      "[449]\ttrain-auc:0.89308\ttest-auc:0.86381\n",
      "[450]\ttrain-auc:0.89318\ttest-auc:0.86386\n",
      "[451]\ttrain-auc:0.89328\ttest-auc:0.86391\n",
      "[452]\ttrain-auc:0.89333\ttest-auc:0.86393\n",
      "[453]\ttrain-auc:0.89343\ttest-auc:0.86400\n",
      "[454]\ttrain-auc:0.89348\ttest-auc:0.86401\n",
      "[455]\ttrain-auc:0.89362\ttest-auc:0.86410\n",
      "[456]\ttrain-auc:0.89365\ttest-auc:0.86410\n",
      "[457]\ttrain-auc:0.89377\ttest-auc:0.86416\n",
      "[458]\ttrain-auc:0.89382\ttest-auc:0.86416\n",
      "[459]\ttrain-auc:0.89390\ttest-auc:0.86418\n",
      "[460]\ttrain-auc:0.89397\ttest-auc:0.86420\n",
      "[461]\ttrain-auc:0.89403\ttest-auc:0.86422\n",
      "[462]\ttrain-auc:0.89411\ttest-auc:0.86425\n",
      "[463]\ttrain-auc:0.89419\ttest-auc:0.86430\n",
      "[464]\ttrain-auc:0.89423\ttest-auc:0.86432\n",
      "[465]\ttrain-auc:0.89432\ttest-auc:0.86437\n",
      "[466]\ttrain-auc:0.89437\ttest-auc:0.86437\n",
      "[467]\ttrain-auc:0.89448\ttest-auc:0.86441\n",
      "[468]\ttrain-auc:0.89456\ttest-auc:0.86443\n",
      "[469]\ttrain-auc:0.89461\ttest-auc:0.86446\n",
      "[470]\ttrain-auc:0.89466\ttest-auc:0.86449\n",
      "[471]\ttrain-auc:0.89473\ttest-auc:0.86452\n",
      "[472]\ttrain-auc:0.89485\ttest-auc:0.86457\n",
      "[473]\ttrain-auc:0.89490\ttest-auc:0.86459\n",
      "[474]\ttrain-auc:0.89493\ttest-auc:0.86462\n",
      "[475]\ttrain-auc:0.89499\ttest-auc:0.86464\n",
      "[476]\ttrain-auc:0.89510\ttest-auc:0.86467\n",
      "[477]\ttrain-auc:0.89516\ttest-auc:0.86469\n",
      "[478]\ttrain-auc:0.89526\ttest-auc:0.86473\n",
      "[479]\ttrain-auc:0.89530\ttest-auc:0.86474\n",
      "[480]\ttrain-auc:0.89536\ttest-auc:0.86477\n",
      "[481]\ttrain-auc:0.89540\ttest-auc:0.86478\n",
      "[482]\ttrain-auc:0.89546\ttest-auc:0.86484\n",
      "[483]\ttrain-auc:0.89555\ttest-auc:0.86489\n",
      "[484]\ttrain-auc:0.89563\ttest-auc:0.86489\n",
      "[485]\ttrain-auc:0.89568\ttest-auc:0.86489\n",
      "[486]\ttrain-auc:0.89577\ttest-auc:0.86492\n",
      "[487]\ttrain-auc:0.89584\ttest-auc:0.86493\n",
      "[488]\ttrain-auc:0.89589\ttest-auc:0.86494\n",
      "[489]\ttrain-auc:0.89594\ttest-auc:0.86495\n",
      "[490]\ttrain-auc:0.89601\ttest-auc:0.86498\n",
      "[491]\ttrain-auc:0.89610\ttest-auc:0.86500\n",
      "[492]\ttrain-auc:0.89618\ttest-auc:0.86505\n",
      "[493]\ttrain-auc:0.89624\ttest-auc:0.86506\n",
      "[494]\ttrain-auc:0.89631\ttest-auc:0.86508\n",
      "[495]\ttrain-auc:0.89637\ttest-auc:0.86511\n",
      "[496]\ttrain-auc:0.89650\ttest-auc:0.86512\n",
      "[497]\ttrain-auc:0.89656\ttest-auc:0.86512\n",
      "[498]\ttrain-auc:0.89664\ttest-auc:0.86517\n",
      "[499]\ttrain-auc:0.89668\ttest-auc:0.86518\n",
      "[500]\ttrain-auc:0.89676\ttest-auc:0.86519\n",
      "[501]\ttrain-auc:0.89685\ttest-auc:0.86522\n",
      "[502]\ttrain-auc:0.89695\ttest-auc:0.86525\n",
      "[503]\ttrain-auc:0.89702\ttest-auc:0.86528\n",
      "[504]\ttrain-auc:0.89710\ttest-auc:0.86529\n",
      "[505]\ttrain-auc:0.89717\ttest-auc:0.86530\n",
      "[506]\ttrain-auc:0.89725\ttest-auc:0.86532\n",
      "[507]\ttrain-auc:0.89737\ttest-auc:0.86537\n",
      "[508]\ttrain-auc:0.89742\ttest-auc:0.86538\n",
      "[509]\ttrain-auc:0.89752\ttest-auc:0.86546\n",
      "[510]\ttrain-auc:0.89759\ttest-auc:0.86550\n",
      "[511]\ttrain-auc:0.89769\ttest-auc:0.86553\n",
      "[512]\ttrain-auc:0.89777\ttest-auc:0.86556\n",
      "[513]\ttrain-auc:0.89785\ttest-auc:0.86559\n",
      "[514]\ttrain-auc:0.89791\ttest-auc:0.86559\n",
      "[515]\ttrain-auc:0.89802\ttest-auc:0.86560\n",
      "[516]\ttrain-auc:0.89807\ttest-auc:0.86564\n",
      "[517]\ttrain-auc:0.89810\ttest-auc:0.86564\n",
      "[518]\ttrain-auc:0.89814\ttest-auc:0.86566\n",
      "[519]\ttrain-auc:0.89818\ttest-auc:0.86567\n",
      "[520]\ttrain-auc:0.89822\ttest-auc:0.86568\n",
      "[521]\ttrain-auc:0.89832\ttest-auc:0.86571\n",
      "[522]\ttrain-auc:0.89839\ttest-auc:0.86572\n",
      "[523]\ttrain-auc:0.89846\ttest-auc:0.86576\n",
      "[524]\ttrain-auc:0.89851\ttest-auc:0.86579\n",
      "[525]\ttrain-auc:0.89865\ttest-auc:0.86582\n",
      "[526]\ttrain-auc:0.89876\ttest-auc:0.86584\n",
      "[527]\ttrain-auc:0.89884\ttest-auc:0.86587\n",
      "[528]\ttrain-auc:0.89892\ttest-auc:0.86588\n",
      "[529]\ttrain-auc:0.89898\ttest-auc:0.86591\n",
      "[530]\ttrain-auc:0.89907\ttest-auc:0.86596\n",
      "[531]\ttrain-auc:0.89917\ttest-auc:0.86598\n",
      "[532]\ttrain-auc:0.89922\ttest-auc:0.86601\n",
      "[533]\ttrain-auc:0.89926\ttest-auc:0.86602\n",
      "[534]\ttrain-auc:0.89934\ttest-auc:0.86607\n",
      "[535]\ttrain-auc:0.89942\ttest-auc:0.86610\n",
      "[536]\ttrain-auc:0.89948\ttest-auc:0.86613\n",
      "[537]\ttrain-auc:0.89953\ttest-auc:0.86614\n",
      "[538]\ttrain-auc:0.89966\ttest-auc:0.86618\n",
      "[539]\ttrain-auc:0.89969\ttest-auc:0.86620\n",
      "[540]\ttrain-auc:0.89975\ttest-auc:0.86621\n",
      "[541]\ttrain-auc:0.89978\ttest-auc:0.86622\n",
      "[542]\ttrain-auc:0.89987\ttest-auc:0.86625\n",
      "[543]\ttrain-auc:0.89992\ttest-auc:0.86627\n",
      "[544]\ttrain-auc:0.89999\ttest-auc:0.86628\n",
      "[545]\ttrain-auc:0.90010\ttest-auc:0.86634\n",
      "[546]\ttrain-auc:0.90018\ttest-auc:0.86637\n",
      "[547]\ttrain-auc:0.90023\ttest-auc:0.86639\n",
      "[548]\ttrain-auc:0.90031\ttest-auc:0.86641\n",
      "[549]\ttrain-auc:0.90043\ttest-auc:0.86647\n",
      "[550]\ttrain-auc:0.90050\ttest-auc:0.86647\n",
      "[551]\ttrain-auc:0.90062\ttest-auc:0.86648\n",
      "[552]\ttrain-auc:0.90070\ttest-auc:0.86652\n",
      "[553]\ttrain-auc:0.90076\ttest-auc:0.86654\n",
      "[554]\ttrain-auc:0.90084\ttest-auc:0.86656\n",
      "[555]\ttrain-auc:0.90091\ttest-auc:0.86658\n",
      "[556]\ttrain-auc:0.90097\ttest-auc:0.86662\n",
      "[557]\ttrain-auc:0.90104\ttest-auc:0.86666\n",
      "[558]\ttrain-auc:0.90111\ttest-auc:0.86671\n",
      "[559]\ttrain-auc:0.90116\ttest-auc:0.86672\n",
      "[560]\ttrain-auc:0.90127\ttest-auc:0.86673\n",
      "[561]\ttrain-auc:0.90134\ttest-auc:0.86674\n",
      "[562]\ttrain-auc:0.90143\ttest-auc:0.86677\n",
      "[563]\ttrain-auc:0.90148\ttest-auc:0.86678\n",
      "[564]\ttrain-auc:0.90154\ttest-auc:0.86681\n",
      "[565]\ttrain-auc:0.90161\ttest-auc:0.86681\n",
      "[566]\ttrain-auc:0.90171\ttest-auc:0.86683\n",
      "[567]\ttrain-auc:0.90178\ttest-auc:0.86684\n",
      "[568]\ttrain-auc:0.90186\ttest-auc:0.86686\n",
      "[569]\ttrain-auc:0.90193\ttest-auc:0.86688\n",
      "[570]\ttrain-auc:0.90198\ttest-auc:0.86688\n",
      "[571]\ttrain-auc:0.90202\ttest-auc:0.86689\n",
      "[572]\ttrain-auc:0.90209\ttest-auc:0.86691\n",
      "[573]\ttrain-auc:0.90213\ttest-auc:0.86693\n",
      "[574]\ttrain-auc:0.90220\ttest-auc:0.86692\n",
      "[575]\ttrain-auc:0.90228\ttest-auc:0.86696\n",
      "[576]\ttrain-auc:0.90234\ttest-auc:0.86699\n",
      "[577]\ttrain-auc:0.90244\ttest-auc:0.86701\n",
      "[578]\ttrain-auc:0.90253\ttest-auc:0.86706\n",
      "[579]\ttrain-auc:0.90257\ttest-auc:0.86707\n",
      "[580]\ttrain-auc:0.90265\ttest-auc:0.86710\n",
      "[581]\ttrain-auc:0.90272\ttest-auc:0.86711\n",
      "[582]\ttrain-auc:0.90278\ttest-auc:0.86715\n",
      "[583]\ttrain-auc:0.90284\ttest-auc:0.86715\n",
      "[584]\ttrain-auc:0.90288\ttest-auc:0.86718\n",
      "[585]\ttrain-auc:0.90298\ttest-auc:0.86720\n",
      "[586]\ttrain-auc:0.90302\ttest-auc:0.86720\n",
      "[587]\ttrain-auc:0.90306\ttest-auc:0.86721\n",
      "[588]\ttrain-auc:0.90309\ttest-auc:0.86722\n",
      "[589]\ttrain-auc:0.90321\ttest-auc:0.86728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[590]\ttrain-auc:0.90327\ttest-auc:0.86730\n",
      "[591]\ttrain-auc:0.90335\ttest-auc:0.86731\n",
      "[592]\ttrain-auc:0.90343\ttest-auc:0.86733\n",
      "[593]\ttrain-auc:0.90353\ttest-auc:0.86733\n",
      "[594]\ttrain-auc:0.90361\ttest-auc:0.86734\n",
      "[595]\ttrain-auc:0.90371\ttest-auc:0.86736\n",
      "[596]\ttrain-auc:0.90379\ttest-auc:0.86737\n",
      "[597]\ttrain-auc:0.90384\ttest-auc:0.86738\n",
      "[598]\ttrain-auc:0.90392\ttest-auc:0.86741\n",
      "[599]\ttrain-auc:0.90402\ttest-auc:0.86745\n",
      "[600]\ttrain-auc:0.90416\ttest-auc:0.86747\n",
      "[601]\ttrain-auc:0.90425\ttest-auc:0.86749\n",
      "[602]\ttrain-auc:0.90436\ttest-auc:0.86755\n",
      "[603]\ttrain-auc:0.90450\ttest-auc:0.86757\n",
      "[604]\ttrain-auc:0.90456\ttest-auc:0.86761\n",
      "[605]\ttrain-auc:0.90459\ttest-auc:0.86760\n",
      "[606]\ttrain-auc:0.90468\ttest-auc:0.86762\n",
      "[607]\ttrain-auc:0.90477\ttest-auc:0.86766\n",
      "[608]\ttrain-auc:0.90486\ttest-auc:0.86767\n",
      "[609]\ttrain-auc:0.90497\ttest-auc:0.86771\n",
      "[610]\ttrain-auc:0.90503\ttest-auc:0.86773\n",
      "[611]\ttrain-auc:0.90509\ttest-auc:0.86774\n",
      "[612]\ttrain-auc:0.90515\ttest-auc:0.86774\n",
      "[613]\ttrain-auc:0.90524\ttest-auc:0.86777\n",
      "[614]\ttrain-auc:0.90529\ttest-auc:0.86778\n",
      "[615]\ttrain-auc:0.90535\ttest-auc:0.86782\n",
      "[616]\ttrain-auc:0.90542\ttest-auc:0.86782\n",
      "[617]\ttrain-auc:0.90553\ttest-auc:0.86783\n",
      "[618]\ttrain-auc:0.90560\ttest-auc:0.86783\n",
      "[619]\ttrain-auc:0.90564\ttest-auc:0.86785\n",
      "[620]\ttrain-auc:0.90569\ttest-auc:0.86784\n",
      "[621]\ttrain-auc:0.90577\ttest-auc:0.86787\n",
      "[622]\ttrain-auc:0.90584\ttest-auc:0.86788\n",
      "[623]\ttrain-auc:0.90587\ttest-auc:0.86789\n",
      "[624]\ttrain-auc:0.90595\ttest-auc:0.86792\n",
      "[625]\ttrain-auc:0.90600\ttest-auc:0.86794\n",
      "[626]\ttrain-auc:0.90608\ttest-auc:0.86795\n",
      "[627]\ttrain-auc:0.90620\ttest-auc:0.86796\n",
      "[628]\ttrain-auc:0.90625\ttest-auc:0.86797\n",
      "[629]\ttrain-auc:0.90630\ttest-auc:0.86798\n",
      "[630]\ttrain-auc:0.90637\ttest-auc:0.86799\n",
      "[631]\ttrain-auc:0.90642\ttest-auc:0.86800\n",
      "[632]\ttrain-auc:0.90647\ttest-auc:0.86802\n",
      "[633]\ttrain-auc:0.90654\ttest-auc:0.86804\n",
      "[634]\ttrain-auc:0.90657\ttest-auc:0.86805\n",
      "[635]\ttrain-auc:0.90668\ttest-auc:0.86806\n",
      "[636]\ttrain-auc:0.90676\ttest-auc:0.86807\n",
      "[637]\ttrain-auc:0.90688\ttest-auc:0.86809\n",
      "[638]\ttrain-auc:0.90696\ttest-auc:0.86815\n",
      "[639]\ttrain-auc:0.90704\ttest-auc:0.86817\n",
      "[640]\ttrain-auc:0.90710\ttest-auc:0.86820\n",
      "[641]\ttrain-auc:0.90714\ttest-auc:0.86820\n",
      "[642]\ttrain-auc:0.90724\ttest-auc:0.86825\n",
      "[643]\ttrain-auc:0.90735\ttest-auc:0.86826\n",
      "[644]\ttrain-auc:0.90742\ttest-auc:0.86827\n",
      "[645]\ttrain-auc:0.90746\ttest-auc:0.86830\n",
      "[646]\ttrain-auc:0.90755\ttest-auc:0.86832\n",
      "[647]\ttrain-auc:0.90767\ttest-auc:0.86837\n",
      "[648]\ttrain-auc:0.90771\ttest-auc:0.86839\n",
      "[649]\ttrain-auc:0.90780\ttest-auc:0.86842\n",
      "[650]\ttrain-auc:0.90789\ttest-auc:0.86846\n",
      "[651]\ttrain-auc:0.90793\ttest-auc:0.86847\n",
      "[652]\ttrain-auc:0.90797\ttest-auc:0.86848\n",
      "[653]\ttrain-auc:0.90803\ttest-auc:0.86851\n",
      "[654]\ttrain-auc:0.90813\ttest-auc:0.86853\n",
      "[655]\ttrain-auc:0.90822\ttest-auc:0.86855\n",
      "[656]\ttrain-auc:0.90829\ttest-auc:0.86855\n",
      "[657]\ttrain-auc:0.90833\ttest-auc:0.86855\n",
      "[658]\ttrain-auc:0.90842\ttest-auc:0.86860\n",
      "[659]\ttrain-auc:0.90851\ttest-auc:0.86861\n",
      "[660]\ttrain-auc:0.90857\ttest-auc:0.86862\n",
      "[661]\ttrain-auc:0.90863\ttest-auc:0.86862\n",
      "[662]\ttrain-auc:0.90872\ttest-auc:0.86865\n",
      "[663]\ttrain-auc:0.90877\ttest-auc:0.86865\n",
      "[664]\ttrain-auc:0.90883\ttest-auc:0.86865\n",
      "[665]\ttrain-auc:0.90894\ttest-auc:0.86867\n",
      "[666]\ttrain-auc:0.90901\ttest-auc:0.86869\n",
      "[667]\ttrain-auc:0.90911\ttest-auc:0.86870\n",
      "[668]\ttrain-auc:0.90917\ttest-auc:0.86872\n",
      "[669]\ttrain-auc:0.90922\ttest-auc:0.86873\n",
      "[670]\ttrain-auc:0.90928\ttest-auc:0.86874\n",
      "[671]\ttrain-auc:0.90938\ttest-auc:0.86874\n",
      "[672]\ttrain-auc:0.90942\ttest-auc:0.86874\n",
      "[673]\ttrain-auc:0.90949\ttest-auc:0.86876\n",
      "[674]\ttrain-auc:0.90955\ttest-auc:0.86878\n",
      "[675]\ttrain-auc:0.90961\ttest-auc:0.86880\n",
      "[676]\ttrain-auc:0.90967\ttest-auc:0.86881\n",
      "[677]\ttrain-auc:0.90974\ttest-auc:0.86884\n",
      "[678]\ttrain-auc:0.90982\ttest-auc:0.86884\n",
      "[679]\ttrain-auc:0.90987\ttest-auc:0.86884\n",
      "[680]\ttrain-auc:0.90997\ttest-auc:0.86885\n",
      "[681]\ttrain-auc:0.91004\ttest-auc:0.86887\n",
      "[682]\ttrain-auc:0.91009\ttest-auc:0.86889\n",
      "[683]\ttrain-auc:0.91015\ttest-auc:0.86889\n",
      "[684]\ttrain-auc:0.91021\ttest-auc:0.86891\n",
      "[685]\ttrain-auc:0.91031\ttest-auc:0.86891\n",
      "[686]\ttrain-auc:0.91038\ttest-auc:0.86892\n",
      "[687]\ttrain-auc:0.91045\ttest-auc:0.86891\n",
      "[688]\ttrain-auc:0.91050\ttest-auc:0.86891\n",
      "[689]\ttrain-auc:0.91056\ttest-auc:0.86892\n",
      "[690]\ttrain-auc:0.91063\ttest-auc:0.86893\n",
      "[691]\ttrain-auc:0.91072\ttest-auc:0.86895\n",
      "[692]\ttrain-auc:0.91078\ttest-auc:0.86897\n",
      "[693]\ttrain-auc:0.91093\ttest-auc:0.86900\n",
      "[694]\ttrain-auc:0.91099\ttest-auc:0.86897\n",
      "[695]\ttrain-auc:0.91107\ttest-auc:0.86900\n",
      "[696]\ttrain-auc:0.91113\ttest-auc:0.86899\n",
      "[697]\ttrain-auc:0.91115\ttest-auc:0.86900\n",
      "[698]\ttrain-auc:0.91123\ttest-auc:0.86900\n",
      "[699]\ttrain-auc:0.91132\ttest-auc:0.86902\n",
      "[700]\ttrain-auc:0.91137\ttest-auc:0.86902\n",
      "[701]\ttrain-auc:0.91143\ttest-auc:0.86902\n",
      "[702]\ttrain-auc:0.91148\ttest-auc:0.86903\n",
      "[703]\ttrain-auc:0.91153\ttest-auc:0.86905\n",
      "[704]\ttrain-auc:0.91160\ttest-auc:0.86906\n",
      "[705]\ttrain-auc:0.91164\ttest-auc:0.86907\n",
      "[706]\ttrain-auc:0.91172\ttest-auc:0.86909\n",
      "[707]\ttrain-auc:0.91178\ttest-auc:0.86912\n",
      "[708]\ttrain-auc:0.91181\ttest-auc:0.86913\n",
      "[709]\ttrain-auc:0.91183\ttest-auc:0.86914\n",
      "[710]\ttrain-auc:0.91188\ttest-auc:0.86913\n",
      "[711]\ttrain-auc:0.91196\ttest-auc:0.86913\n",
      "[712]\ttrain-auc:0.91203\ttest-auc:0.86915\n",
      "[713]\ttrain-auc:0.91209\ttest-auc:0.86916\n",
      "[714]\ttrain-auc:0.91216\ttest-auc:0.86917\n",
      "[715]\ttrain-auc:0.91223\ttest-auc:0.86919\n",
      "[716]\ttrain-auc:0.91227\ttest-auc:0.86920\n",
      "[717]\ttrain-auc:0.91232\ttest-auc:0.86921\n",
      "[718]\ttrain-auc:0.91241\ttest-auc:0.86923\n",
      "[719]\ttrain-auc:0.91247\ttest-auc:0.86924\n",
      "[720]\ttrain-auc:0.91257\ttest-auc:0.86926\n",
      "[721]\ttrain-auc:0.91263\ttest-auc:0.86927\n",
      "[722]\ttrain-auc:0.91274\ttest-auc:0.86929\n",
      "[723]\ttrain-auc:0.91282\ttest-auc:0.86931\n",
      "[724]\ttrain-auc:0.91286\ttest-auc:0.86932\n",
      "[725]\ttrain-auc:0.91294\ttest-auc:0.86933\n",
      "[726]\ttrain-auc:0.91303\ttest-auc:0.86934\n",
      "[727]\ttrain-auc:0.91312\ttest-auc:0.86936\n",
      "[728]\ttrain-auc:0.91322\ttest-auc:0.86940\n",
      "[729]\ttrain-auc:0.91330\ttest-auc:0.86940\n",
      "[730]\ttrain-auc:0.91339\ttest-auc:0.86943\n",
      "[731]\ttrain-auc:0.91348\ttest-auc:0.86944\n",
      "[732]\ttrain-auc:0.91354\ttest-auc:0.86947\n",
      "[733]\ttrain-auc:0.91360\ttest-auc:0.86948\n",
      "[734]\ttrain-auc:0.91365\ttest-auc:0.86950\n",
      "[735]\ttrain-auc:0.91371\ttest-auc:0.86951\n",
      "[736]\ttrain-auc:0.91379\ttest-auc:0.86950\n",
      "[737]\ttrain-auc:0.91387\ttest-auc:0.86954\n",
      "[738]\ttrain-auc:0.91396\ttest-auc:0.86956\n",
      "[739]\ttrain-auc:0.91400\ttest-auc:0.86958\n",
      "[740]\ttrain-auc:0.91407\ttest-auc:0.86960\n",
      "[741]\ttrain-auc:0.91412\ttest-auc:0.86963\n",
      "[742]\ttrain-auc:0.91421\ttest-auc:0.86966\n",
      "[743]\ttrain-auc:0.91431\ttest-auc:0.86967\n",
      "[744]\ttrain-auc:0.91433\ttest-auc:0.86967\n",
      "[745]\ttrain-auc:0.91442\ttest-auc:0.86966\n",
      "[746]\ttrain-auc:0.91446\ttest-auc:0.86968\n",
      "[747]\ttrain-auc:0.91450\ttest-auc:0.86970\n",
      "[748]\ttrain-auc:0.91455\ttest-auc:0.86970\n",
      "[749]\ttrain-auc:0.91462\ttest-auc:0.86972\n",
      "[750]\ttrain-auc:0.91471\ttest-auc:0.86972\n",
      "[751]\ttrain-auc:0.91478\ttest-auc:0.86974\n",
      "[752]\ttrain-auc:0.91488\ttest-auc:0.86977\n",
      "[753]\ttrain-auc:0.91497\ttest-auc:0.86979\n",
      "[754]\ttrain-auc:0.91500\ttest-auc:0.86981\n",
      "[755]\ttrain-auc:0.91508\ttest-auc:0.86982\n",
      "[756]\ttrain-auc:0.91516\ttest-auc:0.86984\n",
      "[757]\ttrain-auc:0.91521\ttest-auc:0.86986\n",
      "[758]\ttrain-auc:0.91528\ttest-auc:0.86985\n",
      "[759]\ttrain-auc:0.91533\ttest-auc:0.86985\n",
      "[760]\ttrain-auc:0.91535\ttest-auc:0.86986\n",
      "[761]\ttrain-auc:0.91540\ttest-auc:0.86988\n",
      "[762]\ttrain-auc:0.91542\ttest-auc:0.86988\n",
      "[763]\ttrain-auc:0.91546\ttest-auc:0.86988\n",
      "[764]\ttrain-auc:0.91549\ttest-auc:0.86990\n",
      "[765]\ttrain-auc:0.91551\ttest-auc:0.86989\n",
      "[766]\ttrain-auc:0.91561\ttest-auc:0.86992\n",
      "[767]\ttrain-auc:0.91566\ttest-auc:0.86993\n",
      "[768]\ttrain-auc:0.91573\ttest-auc:0.86997\n",
      "[769]\ttrain-auc:0.91576\ttest-auc:0.86997\n",
      "[770]\ttrain-auc:0.91584\ttest-auc:0.86999\n",
      "[771]\ttrain-auc:0.91589\ttest-auc:0.86998\n",
      "[772]\ttrain-auc:0.91596\ttest-auc:0.87000\n",
      "[773]\ttrain-auc:0.91604\ttest-auc:0.87001\n",
      "[774]\ttrain-auc:0.91609\ttest-auc:0.87002\n",
      "[775]\ttrain-auc:0.91615\ttest-auc:0.87002\n",
      "[776]\ttrain-auc:0.91620\ttest-auc:0.87002\n",
      "[777]\ttrain-auc:0.91626\ttest-auc:0.87003\n",
      "[778]\ttrain-auc:0.91630\ttest-auc:0.87005\n",
      "[779]\ttrain-auc:0.91639\ttest-auc:0.87004\n",
      "[780]\ttrain-auc:0.91646\ttest-auc:0.87006\n",
      "[781]\ttrain-auc:0.91649\ttest-auc:0.87006\n",
      "[782]\ttrain-auc:0.91654\ttest-auc:0.87008\n",
      "[783]\ttrain-auc:0.91661\ttest-auc:0.87009\n",
      "[784]\ttrain-auc:0.91670\ttest-auc:0.87009\n",
      "[785]\ttrain-auc:0.91678\ttest-auc:0.87012\n",
      "[786]\ttrain-auc:0.91682\ttest-auc:0.87014\n",
      "[787]\ttrain-auc:0.91683\ttest-auc:0.87014\n",
      "[788]\ttrain-auc:0.91690\ttest-auc:0.87015\n",
      "[789]\ttrain-auc:0.91696\ttest-auc:0.87015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[790]\ttrain-auc:0.91705\ttest-auc:0.87016\n",
      "[791]\ttrain-auc:0.91716\ttest-auc:0.87020\n",
      "[792]\ttrain-auc:0.91723\ttest-auc:0.87021\n",
      "[793]\ttrain-auc:0.91726\ttest-auc:0.87022\n",
      "[794]\ttrain-auc:0.91731\ttest-auc:0.87025\n",
      "[795]\ttrain-auc:0.91735\ttest-auc:0.87025\n",
      "[796]\ttrain-auc:0.91743\ttest-auc:0.87027\n",
      "[797]\ttrain-auc:0.91747\ttest-auc:0.87028\n",
      "[798]\ttrain-auc:0.91751\ttest-auc:0.87029\n",
      "[799]\ttrain-auc:0.91764\ttest-auc:0.87032\n",
      "[800]\ttrain-auc:0.91771\ttest-auc:0.87033\n",
      "[801]\ttrain-auc:0.91777\ttest-auc:0.87034\n",
      "[802]\ttrain-auc:0.91781\ttest-auc:0.87033\n",
      "[803]\ttrain-auc:0.91786\ttest-auc:0.87035\n",
      "[804]\ttrain-auc:0.91796\ttest-auc:0.87037\n",
      "[805]\ttrain-auc:0.91802\ttest-auc:0.87038\n",
      "[806]\ttrain-auc:0.91805\ttest-auc:0.87037\n",
      "[807]\ttrain-auc:0.91810\ttest-auc:0.87039\n",
      "[808]\ttrain-auc:0.91820\ttest-auc:0.87041\n",
      "[809]\ttrain-auc:0.91825\ttest-auc:0.87043\n",
      "[810]\ttrain-auc:0.91835\ttest-auc:0.87046\n",
      "[811]\ttrain-auc:0.91837\ttest-auc:0.87046\n",
      "[812]\ttrain-auc:0.91849\ttest-auc:0.87045\n",
      "[813]\ttrain-auc:0.91854\ttest-auc:0.87046\n",
      "[814]\ttrain-auc:0.91858\ttest-auc:0.87047\n",
      "[815]\ttrain-auc:0.91865\ttest-auc:0.87048\n",
      "[816]\ttrain-auc:0.91868\ttest-auc:0.87048\n",
      "[817]\ttrain-auc:0.91873\ttest-auc:0.87048\n",
      "[818]\ttrain-auc:0.91874\ttest-auc:0.87048\n",
      "[819]\ttrain-auc:0.91882\ttest-auc:0.87050\n",
      "[820]\ttrain-auc:0.91886\ttest-auc:0.87051\n",
      "[821]\ttrain-auc:0.91891\ttest-auc:0.87052\n",
      "[822]\ttrain-auc:0.91895\ttest-auc:0.87054\n",
      "[823]\ttrain-auc:0.91897\ttest-auc:0.87055\n",
      "[824]\ttrain-auc:0.91903\ttest-auc:0.87056\n",
      "[825]\ttrain-auc:0.91908\ttest-auc:0.87055\n",
      "[826]\ttrain-auc:0.91914\ttest-auc:0.87054\n",
      "[827]\ttrain-auc:0.91919\ttest-auc:0.87054\n",
      "[828]\ttrain-auc:0.91928\ttest-auc:0.87057\n",
      "[829]\ttrain-auc:0.91935\ttest-auc:0.87059\n",
      "[830]\ttrain-auc:0.91945\ttest-auc:0.87058\n",
      "[831]\ttrain-auc:0.91950\ttest-auc:0.87060\n",
      "[832]\ttrain-auc:0.91953\ttest-auc:0.87060\n",
      "[833]\ttrain-auc:0.91954\ttest-auc:0.87061\n",
      "[834]\ttrain-auc:0.91961\ttest-auc:0.87061\n",
      "[835]\ttrain-auc:0.91966\ttest-auc:0.87062\n",
      "[836]\ttrain-auc:0.91970\ttest-auc:0.87063\n",
      "[837]\ttrain-auc:0.91974\ttest-auc:0.87067\n",
      "[838]\ttrain-auc:0.91981\ttest-auc:0.87068\n",
      "[839]\ttrain-auc:0.91984\ttest-auc:0.87070\n",
      "[840]\ttrain-auc:0.91988\ttest-auc:0.87069\n",
      "[841]\ttrain-auc:0.91992\ttest-auc:0.87069\n",
      "[842]\ttrain-auc:0.91999\ttest-auc:0.87067\n",
      "[843]\ttrain-auc:0.92001\ttest-auc:0.87069\n",
      "[844]\ttrain-auc:0.92006\ttest-auc:0.87071\n",
      "[845]\ttrain-auc:0.92010\ttest-auc:0.87071\n",
      "[846]\ttrain-auc:0.92017\ttest-auc:0.87072\n",
      "[847]\ttrain-auc:0.92024\ttest-auc:0.87074\n",
      "[848]\ttrain-auc:0.92029\ttest-auc:0.87075\n",
      "[849]\ttrain-auc:0.92033\ttest-auc:0.87076\n",
      "[850]\ttrain-auc:0.92035\ttest-auc:0.87077\n",
      "[851]\ttrain-auc:0.92038\ttest-auc:0.87077\n",
      "[852]\ttrain-auc:0.92043\ttest-auc:0.87078\n",
      "[853]\ttrain-auc:0.92046\ttest-auc:0.87079\n",
      "[854]\ttrain-auc:0.92051\ttest-auc:0.87079\n",
      "[855]\ttrain-auc:0.92055\ttest-auc:0.87080\n",
      "[856]\ttrain-auc:0.92059\ttest-auc:0.87081\n",
      "[857]\ttrain-auc:0.92069\ttest-auc:0.87084\n",
      "[858]\ttrain-auc:0.92074\ttest-auc:0.87086\n",
      "[859]\ttrain-auc:0.92078\ttest-auc:0.87085\n",
      "[860]\ttrain-auc:0.92085\ttest-auc:0.87086\n",
      "[861]\ttrain-auc:0.92089\ttest-auc:0.87085\n",
      "[862]\ttrain-auc:0.92095\ttest-auc:0.87088\n",
      "[863]\ttrain-auc:0.92099\ttest-auc:0.87089\n",
      "[864]\ttrain-auc:0.92102\ttest-auc:0.87089\n",
      "[865]\ttrain-auc:0.92107\ttest-auc:0.87091\n",
      "[866]\ttrain-auc:0.92115\ttest-auc:0.87092\n",
      "[867]\ttrain-auc:0.92119\ttest-auc:0.87092\n",
      "[868]\ttrain-auc:0.92126\ttest-auc:0.87094\n",
      "[869]\ttrain-auc:0.92132\ttest-auc:0.87096\n",
      "[870]\ttrain-auc:0.92135\ttest-auc:0.87096\n",
      "[871]\ttrain-auc:0.92139\ttest-auc:0.87096\n",
      "[872]\ttrain-auc:0.92144\ttest-auc:0.87098\n",
      "[873]\ttrain-auc:0.92148\ttest-auc:0.87099\n",
      "[874]\ttrain-auc:0.92156\ttest-auc:0.87100\n",
      "[875]\ttrain-auc:0.92165\ttest-auc:0.87099\n",
      "[876]\ttrain-auc:0.92171\ttest-auc:0.87101\n",
      "[877]\ttrain-auc:0.92179\ttest-auc:0.87102\n",
      "[878]\ttrain-auc:0.92185\ttest-auc:0.87102\n",
      "[879]\ttrain-auc:0.92187\ttest-auc:0.87102\n",
      "[880]\ttrain-auc:0.92192\ttest-auc:0.87102\n",
      "[881]\ttrain-auc:0.92196\ttest-auc:0.87103\n",
      "[882]\ttrain-auc:0.92201\ttest-auc:0.87104\n",
      "[883]\ttrain-auc:0.92205\ttest-auc:0.87106\n",
      "[884]\ttrain-auc:0.92207\ttest-auc:0.87106\n",
      "[885]\ttrain-auc:0.92214\ttest-auc:0.87107\n",
      "[886]\ttrain-auc:0.92220\ttest-auc:0.87109\n",
      "[887]\ttrain-auc:0.92230\ttest-auc:0.87110\n",
      "[888]\ttrain-auc:0.92234\ttest-auc:0.87112\n",
      "[889]\ttrain-auc:0.92239\ttest-auc:0.87113\n",
      "[890]\ttrain-auc:0.92241\ttest-auc:0.87113\n",
      "[891]\ttrain-auc:0.92245\ttest-auc:0.87113\n",
      "[892]\ttrain-auc:0.92253\ttest-auc:0.87114\n",
      "[893]\ttrain-auc:0.92258\ttest-auc:0.87114\n",
      "[894]\ttrain-auc:0.92263\ttest-auc:0.87114\n",
      "[895]\ttrain-auc:0.92273\ttest-auc:0.87118\n",
      "[896]\ttrain-auc:0.92275\ttest-auc:0.87119\n",
      "[897]\ttrain-auc:0.92276\ttest-auc:0.87119\n",
      "[898]\ttrain-auc:0.92283\ttest-auc:0.87122\n",
      "[899]\ttrain-auc:0.92286\ttest-auc:0.87122\n",
      "[900]\ttrain-auc:0.92293\ttest-auc:0.87124\n",
      "[901]\ttrain-auc:0.92301\ttest-auc:0.87125\n",
      "[902]\ttrain-auc:0.92307\ttest-auc:0.87125\n",
      "[903]\ttrain-auc:0.92312\ttest-auc:0.87126\n",
      "[904]\ttrain-auc:0.92315\ttest-auc:0.87126\n",
      "[905]\ttrain-auc:0.92321\ttest-auc:0.87127\n",
      "[906]\ttrain-auc:0.92324\ttest-auc:0.87127\n",
      "[907]\ttrain-auc:0.92331\ttest-auc:0.87127\n",
      "[908]\ttrain-auc:0.92336\ttest-auc:0.87129\n",
      "[909]\ttrain-auc:0.92345\ttest-auc:0.87129\n",
      "[910]\ttrain-auc:0.92353\ttest-auc:0.87130\n",
      "[911]\ttrain-auc:0.92356\ttest-auc:0.87131\n",
      "[912]\ttrain-auc:0.92361\ttest-auc:0.87134\n",
      "[913]\ttrain-auc:0.92366\ttest-auc:0.87133\n",
      "[914]\ttrain-auc:0.92370\ttest-auc:0.87134\n",
      "[915]\ttrain-auc:0.92375\ttest-auc:0.87135\n",
      "[916]\ttrain-auc:0.92382\ttest-auc:0.87137\n",
      "[917]\ttrain-auc:0.92388\ttest-auc:0.87138\n",
      "[918]\ttrain-auc:0.92389\ttest-auc:0.87139\n",
      "[919]\ttrain-auc:0.92393\ttest-auc:0.87139\n",
      "[920]\ttrain-auc:0.92396\ttest-auc:0.87139\n",
      "[921]\ttrain-auc:0.92400\ttest-auc:0.87140\n",
      "[922]\ttrain-auc:0.92405\ttest-auc:0.87141\n",
      "[923]\ttrain-auc:0.92409\ttest-auc:0.87142\n",
      "[924]\ttrain-auc:0.92415\ttest-auc:0.87142\n",
      "[925]\ttrain-auc:0.92420\ttest-auc:0.87142\n",
      "[926]\ttrain-auc:0.92427\ttest-auc:0.87144\n",
      "[927]\ttrain-auc:0.92431\ttest-auc:0.87143\n",
      "[928]\ttrain-auc:0.92434\ttest-auc:0.87143\n",
      "[929]\ttrain-auc:0.92441\ttest-auc:0.87143\n",
      "[930]\ttrain-auc:0.92446\ttest-auc:0.87144\n",
      "[931]\ttrain-auc:0.92453\ttest-auc:0.87144\n",
      "[932]\ttrain-auc:0.92460\ttest-auc:0.87144\n",
      "[933]\ttrain-auc:0.92465\ttest-auc:0.87144\n",
      "[934]\ttrain-auc:0.92469\ttest-auc:0.87144\n",
      "[935]\ttrain-auc:0.92472\ttest-auc:0.87144\n",
      "[936]\ttrain-auc:0.92476\ttest-auc:0.87146\n",
      "[937]\ttrain-auc:0.92480\ttest-auc:0.87147\n",
      "[938]\ttrain-auc:0.92486\ttest-auc:0.87149\n",
      "[939]\ttrain-auc:0.92492\ttest-auc:0.87151\n",
      "[940]\ttrain-auc:0.92499\ttest-auc:0.87153\n",
      "[941]\ttrain-auc:0.92503\ttest-auc:0.87153\n",
      "[942]\ttrain-auc:0.92512\ttest-auc:0.87153\n",
      "[943]\ttrain-auc:0.92517\ttest-auc:0.87152\n",
      "[944]\ttrain-auc:0.92523\ttest-auc:0.87153\n",
      "[945]\ttrain-auc:0.92529\ttest-auc:0.87153\n",
      "[946]\ttrain-auc:0.92532\ttest-auc:0.87154\n",
      "[947]\ttrain-auc:0.92537\ttest-auc:0.87153\n",
      "[948]\ttrain-auc:0.92546\ttest-auc:0.87153\n",
      "[949]\ttrain-auc:0.92551\ttest-auc:0.87155\n",
      "[950]\ttrain-auc:0.92557\ttest-auc:0.87155\n",
      "[951]\ttrain-auc:0.92564\ttest-auc:0.87157\n",
      "[952]\ttrain-auc:0.92572\ttest-auc:0.87157\n",
      "[953]\ttrain-auc:0.92578\ttest-auc:0.87160\n",
      "[954]\ttrain-auc:0.92585\ttest-auc:0.87161\n",
      "[955]\ttrain-auc:0.92588\ttest-auc:0.87162\n",
      "[956]\ttrain-auc:0.92593\ttest-auc:0.87163\n",
      "[957]\ttrain-auc:0.92601\ttest-auc:0.87163\n",
      "[958]\ttrain-auc:0.92605\ttest-auc:0.87163\n",
      "[959]\ttrain-auc:0.92608\ttest-auc:0.87164\n",
      "[960]\ttrain-auc:0.92612\ttest-auc:0.87166\n",
      "[961]\ttrain-auc:0.92614\ttest-auc:0.87166\n",
      "[962]\ttrain-auc:0.92619\ttest-auc:0.87168\n",
      "[963]\ttrain-auc:0.92625\ttest-auc:0.87168\n",
      "[964]\ttrain-auc:0.92631\ttest-auc:0.87169\n",
      "[965]\ttrain-auc:0.92636\ttest-auc:0.87173\n",
      "[966]\ttrain-auc:0.92639\ttest-auc:0.87174\n",
      "[967]\ttrain-auc:0.92643\ttest-auc:0.87174\n",
      "[968]\ttrain-auc:0.92649\ttest-auc:0.87175\n",
      "[969]\ttrain-auc:0.92652\ttest-auc:0.87174\n",
      "[970]\ttrain-auc:0.92655\ttest-auc:0.87175\n",
      "[971]\ttrain-auc:0.92660\ttest-auc:0.87176\n",
      "[972]\ttrain-auc:0.92664\ttest-auc:0.87177\n",
      "[973]\ttrain-auc:0.92671\ttest-auc:0.87178\n",
      "[974]\ttrain-auc:0.92676\ttest-auc:0.87178\n",
      "[975]\ttrain-auc:0.92686\ttest-auc:0.87182\n",
      "[976]\ttrain-auc:0.92690\ttest-auc:0.87182\n",
      "[977]\ttrain-auc:0.92697\ttest-auc:0.87185\n",
      "[978]\ttrain-auc:0.92697\ttest-auc:0.87185\n",
      "[979]\ttrain-auc:0.92703\ttest-auc:0.87186\n",
      "[980]\ttrain-auc:0.92709\ttest-auc:0.87188\n",
      "[981]\ttrain-auc:0.92714\ttest-auc:0.87189\n",
      "[982]\ttrain-auc:0.92718\ttest-auc:0.87189\n",
      "[983]\ttrain-auc:0.92727\ttest-auc:0.87193\n",
      "[984]\ttrain-auc:0.92736\ttest-auc:0.87193\n",
      "[985]\ttrain-auc:0.92741\ttest-auc:0.87195\n",
      "[986]\ttrain-auc:0.92746\ttest-auc:0.87196\n",
      "[987]\ttrain-auc:0.92749\ttest-auc:0.87197\n",
      "[988]\ttrain-auc:0.92754\ttest-auc:0.87198\n",
      "[989]\ttrain-auc:0.92756\ttest-auc:0.87199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[990]\ttrain-auc:0.92765\ttest-auc:0.87201\n",
      "[991]\ttrain-auc:0.92771\ttest-auc:0.87200\n",
      "[992]\ttrain-auc:0.92776\ttest-auc:0.87202\n",
      "[993]\ttrain-auc:0.92785\ttest-auc:0.87202\n",
      "[994]\ttrain-auc:0.92791\ttest-auc:0.87204\n",
      "[995]\ttrain-auc:0.92798\ttest-auc:0.87205\n",
      "[996]\ttrain-auc:0.92805\ttest-auc:0.87209\n",
      "[997]\ttrain-auc:0.92813\ttest-auc:0.87210\n",
      "[998]\ttrain-auc:0.92817\ttest-auc:0.87209\n",
      "[999]\ttrain-auc:0.92820\ttest-auc:0.87210\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xgb_train,'train'),(xgb_eval,'test')]\n",
    "bst=xgb.train(params,xgb_train,num_boost_round=1000,early_stopping_rounds=500,evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82185\n",
      "[1]\ttrain-auc:0.82317\n",
      "[2]\ttrain-auc:0.82550\n",
      "[3]\ttrain-auc:0.83488\n",
      "[4]\ttrain-auc:0.83543\n",
      "[5]\ttrain-auc:0.83663\n",
      "[6]\ttrain-auc:0.83663\n",
      "[7]\ttrain-auc:0.83642\n",
      "[8]\ttrain-auc:0.83616\n",
      "[9]\ttrain-auc:0.83674\n",
      "[10]\ttrain-auc:0.83649\n",
      "[11]\ttrain-auc:0.83672\n",
      "[12]\ttrain-auc:0.83708\n",
      "[13]\ttrain-auc:0.84026\n",
      "[14]\ttrain-auc:0.84044\n",
      "[15]\ttrain-auc:0.84034\n",
      "[16]\ttrain-auc:0.84025\n",
      "[17]\ttrain-auc:0.84030\n",
      "[18]\ttrain-auc:0.84143\n",
      "[19]\ttrain-auc:0.84263\n",
      "[20]\ttrain-auc:0.84279\n",
      "[21]\ttrain-auc:0.84353\n",
      "[22]\ttrain-auc:0.84340\n",
      "[23]\ttrain-auc:0.84336\n",
      "[24]\ttrain-auc:0.84347\n",
      "[25]\ttrain-auc:0.84366\n",
      "[26]\ttrain-auc:0.84461\n",
      "[27]\ttrain-auc:0.84445\n",
      "[28]\ttrain-auc:0.84515\n",
      "[29]\ttrain-auc:0.84557\n",
      "[30]\ttrain-auc:0.84546\n",
      "[31]\ttrain-auc:0.84603\n",
      "[32]\ttrain-auc:0.84588\n",
      "[33]\ttrain-auc:0.84585\n",
      "[34]\ttrain-auc:0.84627\n",
      "[35]\ttrain-auc:0.84625\n",
      "[36]\ttrain-auc:0.84625\n",
      "[37]\ttrain-auc:0.84607\n",
      "[38]\ttrain-auc:0.84654\n",
      "[39]\ttrain-auc:0.84713\n",
      "[40]\ttrain-auc:0.84705\n",
      "[41]\ttrain-auc:0.84711\n",
      "[42]\ttrain-auc:0.84747\n",
      "[43]\ttrain-auc:0.84750\n",
      "[44]\ttrain-auc:0.84756\n",
      "[45]\ttrain-auc:0.84747\n",
      "[46]\ttrain-auc:0.84744\n",
      "[47]\ttrain-auc:0.84737\n",
      "[48]\ttrain-auc:0.84732\n",
      "[49]\ttrain-auc:0.84744\n",
      "[50]\ttrain-auc:0.84749\n",
      "[51]\ttrain-auc:0.84755\n",
      "[52]\ttrain-auc:0.84757\n",
      "[53]\ttrain-auc:0.84760\n",
      "[54]\ttrain-auc:0.84759\n",
      "[55]\ttrain-auc:0.84761\n",
      "[56]\ttrain-auc:0.84766\n",
      "[57]\ttrain-auc:0.84783\n",
      "[58]\ttrain-auc:0.84810\n",
      "[59]\ttrain-auc:0.84824\n",
      "[60]\ttrain-auc:0.84818\n",
      "[61]\ttrain-auc:0.84822\n",
      "[62]\ttrain-auc:0.84823\n",
      "[63]\ttrain-auc:0.84828\n",
      "[64]\ttrain-auc:0.84858\n",
      "[65]\ttrain-auc:0.84875\n",
      "[66]\ttrain-auc:0.84881\n",
      "[67]\ttrain-auc:0.84905\n",
      "[68]\ttrain-auc:0.84919\n",
      "[69]\ttrain-auc:0.84925\n",
      "[70]\ttrain-auc:0.84937\n",
      "[71]\ttrain-auc:0.84966\n",
      "[72]\ttrain-auc:0.85013\n",
      "[73]\ttrain-auc:0.85017\n",
      "[74]\ttrain-auc:0.85017\n",
      "[75]\ttrain-auc:0.85057\n",
      "[76]\ttrain-auc:0.85060\n",
      "[77]\ttrain-auc:0.85071\n",
      "[78]\ttrain-auc:0.85077\n",
      "[79]\ttrain-auc:0.85118\n",
      "[80]\ttrain-auc:0.85178\n",
      "[81]\ttrain-auc:0.85181\n",
      "[82]\ttrain-auc:0.85193\n",
      "[83]\ttrain-auc:0.85222\n",
      "[84]\ttrain-auc:0.85250\n",
      "[85]\ttrain-auc:0.85260\n",
      "[86]\ttrain-auc:0.85272\n",
      "[87]\ttrain-auc:0.85317\n",
      "[88]\ttrain-auc:0.85335\n",
      "[89]\ttrain-auc:0.85343\n",
      "[90]\ttrain-auc:0.85368\n",
      "[91]\ttrain-auc:0.85398\n",
      "[92]\ttrain-auc:0.85408\n",
      "[93]\ttrain-auc:0.85410\n",
      "[94]\ttrain-auc:0.85411\n",
      "[95]\ttrain-auc:0.85428\n",
      "[96]\ttrain-auc:0.85452\n",
      "[97]\ttrain-auc:0.85464\n",
      "[98]\ttrain-auc:0.85473\n",
      "[99]\ttrain-auc:0.85497\n",
      "[100]\ttrain-auc:0.85523\n",
      "[101]\ttrain-auc:0.85543\n",
      "[102]\ttrain-auc:0.85582\n",
      "[103]\ttrain-auc:0.85603\n",
      "[104]\ttrain-auc:0.85630\n",
      "[105]\ttrain-auc:0.85654\n",
      "[106]\ttrain-auc:0.85666\n",
      "[107]\ttrain-auc:0.85691\n",
      "[108]\ttrain-auc:0.85699\n",
      "[109]\ttrain-auc:0.85714\n",
      "[110]\ttrain-auc:0.85721\n",
      "[111]\ttrain-auc:0.85733\n",
      "[112]\ttrain-auc:0.85751\n",
      "[113]\ttrain-auc:0.85768\n",
      "[114]\ttrain-auc:0.85784\n",
      "[115]\ttrain-auc:0.85799\n",
      "[116]\ttrain-auc:0.85801\n",
      "[117]\ttrain-auc:0.85817\n",
      "[118]\ttrain-auc:0.85851\n",
      "[119]\ttrain-auc:0.85850\n",
      "[120]\ttrain-auc:0.85860\n",
      "[121]\ttrain-auc:0.85875\n",
      "[122]\ttrain-auc:0.85892\n",
      "[123]\ttrain-auc:0.85917\n",
      "[124]\ttrain-auc:0.85936\n",
      "[125]\ttrain-auc:0.85951\n",
      "[126]\ttrain-auc:0.85967\n",
      "[127]\ttrain-auc:0.85973\n",
      "[128]\ttrain-auc:0.85974\n",
      "[129]\ttrain-auc:0.85987\n",
      "[130]\ttrain-auc:0.86003\n",
      "[131]\ttrain-auc:0.86019\n",
      "[132]\ttrain-auc:0.86033\n",
      "[133]\ttrain-auc:0.86045\n",
      "[134]\ttrain-auc:0.86053\n",
      "[135]\ttrain-auc:0.86066\n",
      "[136]\ttrain-auc:0.86073\n",
      "[137]\ttrain-auc:0.86089\n",
      "[138]\ttrain-auc:0.86099\n",
      "[139]\ttrain-auc:0.86118\n",
      "[140]\ttrain-auc:0.86147\n",
      "[141]\ttrain-auc:0.86145\n",
      "[142]\ttrain-auc:0.86148\n",
      "[143]\ttrain-auc:0.86156\n",
      "[144]\ttrain-auc:0.86163\n",
      "[145]\ttrain-auc:0.86176\n",
      "[146]\ttrain-auc:0.86186\n",
      "[147]\ttrain-auc:0.86193\n",
      "[148]\ttrain-auc:0.86199\n",
      "[149]\ttrain-auc:0.86216\n",
      "[150]\ttrain-auc:0.86230\n",
      "[151]\ttrain-auc:0.86235\n",
      "[152]\ttrain-auc:0.86246\n",
      "[153]\ttrain-auc:0.86257\n",
      "[154]\ttrain-auc:0.86271\n",
      "[155]\ttrain-auc:0.86284\n",
      "[156]\ttrain-auc:0.86304\n",
      "[157]\ttrain-auc:0.86311\n",
      "[158]\ttrain-auc:0.86335\n",
      "[159]\ttrain-auc:0.86341\n",
      "[160]\ttrain-auc:0.86348\n",
      "[161]\ttrain-auc:0.86356\n",
      "[162]\ttrain-auc:0.86363\n",
      "[163]\ttrain-auc:0.86379\n",
      "[164]\ttrain-auc:0.86386\n",
      "[165]\ttrain-auc:0.86402\n",
      "[166]\ttrain-auc:0.86415\n",
      "[167]\ttrain-auc:0.86424\n",
      "[168]\ttrain-auc:0.86438\n",
      "[169]\ttrain-auc:0.86444\n",
      "[170]\ttrain-auc:0.86463\n",
      "[171]\ttrain-auc:0.86482\n",
      "[172]\ttrain-auc:0.86490\n",
      "[173]\ttrain-auc:0.86496\n",
      "[174]\ttrain-auc:0.86505\n",
      "[175]\ttrain-auc:0.86524\n",
      "[176]\ttrain-auc:0.86545\n",
      "[177]\ttrain-auc:0.86555\n",
      "[178]\ttrain-auc:0.86561\n",
      "[179]\ttrain-auc:0.86570\n",
      "[180]\ttrain-auc:0.86587\n",
      "[181]\ttrain-auc:0.86596\n",
      "[182]\ttrain-auc:0.86602\n",
      "[183]\ttrain-auc:0.86609\n",
      "[184]\ttrain-auc:0.86619\n",
      "[185]\ttrain-auc:0.86637\n",
      "[186]\ttrain-auc:0.86648\n",
      "[187]\ttrain-auc:0.86658\n",
      "[188]\ttrain-auc:0.86673\n",
      "[189]\ttrain-auc:0.86689\n",
      "[190]\ttrain-auc:0.86703\n",
      "[191]\ttrain-auc:0.86709\n",
      "[192]\ttrain-auc:0.86722\n",
      "[193]\ttrain-auc:0.86738\n",
      "[194]\ttrain-auc:0.86754\n",
      "[195]\ttrain-auc:0.86768\n",
      "[196]\ttrain-auc:0.86771\n",
      "[197]\ttrain-auc:0.86781\n",
      "[198]\ttrain-auc:0.86792\n",
      "[199]\ttrain-auc:0.86803\n",
      "[200]\ttrain-auc:0.86819\n",
      "[201]\ttrain-auc:0.86833\n",
      "[202]\ttrain-auc:0.86839\n",
      "[203]\ttrain-auc:0.86851\n",
      "[204]\ttrain-auc:0.86859\n",
      "[205]\ttrain-auc:0.86872\n",
      "[206]\ttrain-auc:0.86883\n",
      "[207]\ttrain-auc:0.86893\n",
      "[208]\ttrain-auc:0.86909\n",
      "[209]\ttrain-auc:0.86917\n",
      "[210]\ttrain-auc:0.86924\n",
      "[211]\ttrain-auc:0.86933\n",
      "[212]\ttrain-auc:0.86946\n",
      "[213]\ttrain-auc:0.86955\n",
      "[214]\ttrain-auc:0.86966\n",
      "[215]\ttrain-auc:0.86981\n",
      "[216]\ttrain-auc:0.86989\n",
      "[217]\ttrain-auc:0.86999\n",
      "[218]\ttrain-auc:0.87006\n",
      "[219]\ttrain-auc:0.87024\n",
      "[220]\ttrain-auc:0.87037\n",
      "[221]\ttrain-auc:0.87045\n",
      "[222]\ttrain-auc:0.87059\n",
      "[223]\ttrain-auc:0.87074\n",
      "[224]\ttrain-auc:0.87083\n",
      "[225]\ttrain-auc:0.87092\n",
      "[226]\ttrain-auc:0.87105\n",
      "[227]\ttrain-auc:0.87113\n",
      "[228]\ttrain-auc:0.87120\n",
      "[229]\ttrain-auc:0.87130\n",
      "[230]\ttrain-auc:0.87141\n",
      "[231]\ttrain-auc:0.87152\n",
      "[232]\ttrain-auc:0.87157\n",
      "[233]\ttrain-auc:0.87169\n",
      "[234]\ttrain-auc:0.87183\n",
      "[235]\ttrain-auc:0.87193\n",
      "[236]\ttrain-auc:0.87207\n",
      "[237]\ttrain-auc:0.87216\n",
      "[238]\ttrain-auc:0.87232\n",
      "[239]\ttrain-auc:0.87239\n",
      "[240]\ttrain-auc:0.87252\n",
      "[241]\ttrain-auc:0.87268\n",
      "[242]\ttrain-auc:0.87271\n",
      "[243]\ttrain-auc:0.87281\n",
      "[244]\ttrain-auc:0.87294\n",
      "[245]\ttrain-auc:0.87303\n",
      "[246]\ttrain-auc:0.87312\n",
      "[247]\ttrain-auc:0.87319\n",
      "[248]\ttrain-auc:0.87331\n",
      "[249]\ttrain-auc:0.87348\n",
      "[250]\ttrain-auc:0.87351\n",
      "[251]\ttrain-auc:0.87368\n",
      "[252]\ttrain-auc:0.87377\n",
      "[253]\ttrain-auc:0.87388\n",
      "[254]\ttrain-auc:0.87397\n",
      "[255]\ttrain-auc:0.87403\n",
      "[256]\ttrain-auc:0.87414\n",
      "[257]\ttrain-auc:0.87427\n",
      "[258]\ttrain-auc:0.87440\n",
      "[259]\ttrain-auc:0.87451\n",
      "[260]\ttrain-auc:0.87459\n",
      "[261]\ttrain-auc:0.87468\n",
      "[262]\ttrain-auc:0.87472\n",
      "[263]\ttrain-auc:0.87477\n",
      "[264]\ttrain-auc:0.87489\n",
      "[265]\ttrain-auc:0.87501\n",
      "[266]\ttrain-auc:0.87514\n",
      "[267]\ttrain-auc:0.87524\n",
      "[268]\ttrain-auc:0.87533\n",
      "[269]\ttrain-auc:0.87541\n",
      "[270]\ttrain-auc:0.87554\n",
      "[271]\ttrain-auc:0.87564\n",
      "[272]\ttrain-auc:0.87569\n",
      "[273]\ttrain-auc:0.87576\n",
      "[274]\ttrain-auc:0.87591\n",
      "[275]\ttrain-auc:0.87602\n",
      "[276]\ttrain-auc:0.87611\n",
      "[277]\ttrain-auc:0.87623\n",
      "[278]\ttrain-auc:0.87634\n",
      "[279]\ttrain-auc:0.87642\n",
      "[280]\ttrain-auc:0.87652\n",
      "[281]\ttrain-auc:0.87665\n",
      "[282]\ttrain-auc:0.87670\n",
      "[283]\ttrain-auc:0.87679\n",
      "[284]\ttrain-auc:0.87686\n",
      "[285]\ttrain-auc:0.87695\n",
      "[286]\ttrain-auc:0.87708\n",
      "[287]\ttrain-auc:0.87717\n",
      "[288]\ttrain-auc:0.87729\n",
      "[289]\ttrain-auc:0.87744\n",
      "[290]\ttrain-auc:0.87752\n",
      "[291]\ttrain-auc:0.87761\n",
      "[292]\ttrain-auc:0.87777\n",
      "[293]\ttrain-auc:0.87784\n",
      "[294]\ttrain-auc:0.87797\n",
      "[295]\ttrain-auc:0.87803\n",
      "[296]\ttrain-auc:0.87814\n",
      "[297]\ttrain-auc:0.87823\n",
      "[298]\ttrain-auc:0.87828\n",
      "[299]\ttrain-auc:0.87832\n",
      "[300]\ttrain-auc:0.87845\n",
      "[301]\ttrain-auc:0.87848\n",
      "[302]\ttrain-auc:0.87855\n",
      "[303]\ttrain-auc:0.87861\n",
      "[304]\ttrain-auc:0.87868\n",
      "[305]\ttrain-auc:0.87877\n",
      "[306]\ttrain-auc:0.87882\n",
      "[307]\ttrain-auc:0.87889\n",
      "[308]\ttrain-auc:0.87899\n",
      "[309]\ttrain-auc:0.87904\n",
      "[310]\ttrain-auc:0.87911\n",
      "[311]\ttrain-auc:0.87917\n",
      "[312]\ttrain-auc:0.87923\n",
      "[313]\ttrain-auc:0.87931\n",
      "[314]\ttrain-auc:0.87938\n",
      "[315]\ttrain-auc:0.87948\n",
      "[316]\ttrain-auc:0.87958\n",
      "[317]\ttrain-auc:0.87971\n",
      "[318]\ttrain-auc:0.87979\n",
      "[319]\ttrain-auc:0.87988\n",
      "[320]\ttrain-auc:0.87994\n",
      "[321]\ttrain-auc:0.88003\n",
      "[322]\ttrain-auc:0.88010\n",
      "[323]\ttrain-auc:0.88020\n",
      "[324]\ttrain-auc:0.88029\n",
      "[325]\ttrain-auc:0.88035\n",
      "[326]\ttrain-auc:0.88049\n",
      "[327]\ttrain-auc:0.88062\n",
      "[328]\ttrain-auc:0.88069\n",
      "[329]\ttrain-auc:0.88076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330]\ttrain-auc:0.88083\n",
      "[331]\ttrain-auc:0.88092\n",
      "[332]\ttrain-auc:0.88101\n",
      "[333]\ttrain-auc:0.88110\n",
      "[334]\ttrain-auc:0.88121\n",
      "[335]\ttrain-auc:0.88128\n",
      "[336]\ttrain-auc:0.88133\n",
      "[337]\ttrain-auc:0.88142\n",
      "[338]\ttrain-auc:0.88146\n",
      "[339]\ttrain-auc:0.88159\n",
      "[340]\ttrain-auc:0.88165\n",
      "[341]\ttrain-auc:0.88176\n",
      "[342]\ttrain-auc:0.88179\n",
      "[343]\ttrain-auc:0.88186\n",
      "[344]\ttrain-auc:0.88193\n",
      "[345]\ttrain-auc:0.88201\n",
      "[346]\ttrain-auc:0.88212\n",
      "[347]\ttrain-auc:0.88219\n",
      "[348]\ttrain-auc:0.88226\n",
      "[349]\ttrain-auc:0.88233\n",
      "[350]\ttrain-auc:0.88245\n",
      "[351]\ttrain-auc:0.88250\n",
      "[352]\ttrain-auc:0.88259\n",
      "[353]\ttrain-auc:0.88272\n",
      "[354]\ttrain-auc:0.88278\n",
      "[355]\ttrain-auc:0.88289\n",
      "[356]\ttrain-auc:0.88301\n",
      "[357]\ttrain-auc:0.88307\n",
      "[358]\ttrain-auc:0.88311\n",
      "[359]\ttrain-auc:0.88316\n",
      "[360]\ttrain-auc:0.88323\n",
      "[361]\ttrain-auc:0.88331\n",
      "[362]\ttrain-auc:0.88337\n",
      "[363]\ttrain-auc:0.88344\n",
      "[364]\ttrain-auc:0.88355\n",
      "[365]\ttrain-auc:0.88364\n",
      "[366]\ttrain-auc:0.88372\n",
      "[367]\ttrain-auc:0.88379\n",
      "[368]\ttrain-auc:0.88387\n",
      "[369]\ttrain-auc:0.88394\n",
      "[370]\ttrain-auc:0.88397\n",
      "[371]\ttrain-auc:0.88405\n",
      "[372]\ttrain-auc:0.88412\n",
      "[373]\ttrain-auc:0.88420\n",
      "[374]\ttrain-auc:0.88428\n",
      "[375]\ttrain-auc:0.88433\n",
      "[376]\ttrain-auc:0.88439\n",
      "[377]\ttrain-auc:0.88446\n",
      "[378]\ttrain-auc:0.88452\n",
      "[379]\ttrain-auc:0.88462\n",
      "[380]\ttrain-auc:0.88467\n",
      "[381]\ttrain-auc:0.88473\n",
      "[382]\ttrain-auc:0.88479\n",
      "[383]\ttrain-auc:0.88488\n",
      "[384]\ttrain-auc:0.88497\n",
      "[385]\ttrain-auc:0.88504\n",
      "[386]\ttrain-auc:0.88511\n",
      "[387]\ttrain-auc:0.88525\n",
      "[388]\ttrain-auc:0.88539\n",
      "[389]\ttrain-auc:0.88545\n",
      "[390]\ttrain-auc:0.88551\n",
      "[391]\ttrain-auc:0.88558\n",
      "[392]\ttrain-auc:0.88566\n",
      "[393]\ttrain-auc:0.88574\n",
      "[394]\ttrain-auc:0.88582\n",
      "[395]\ttrain-auc:0.88586\n",
      "[396]\ttrain-auc:0.88595\n",
      "[397]\ttrain-auc:0.88608\n",
      "[398]\ttrain-auc:0.88616\n",
      "[399]\ttrain-auc:0.88619\n",
      "[400]\ttrain-auc:0.88625\n",
      "[401]\ttrain-auc:0.88634\n",
      "[402]\ttrain-auc:0.88640\n",
      "[403]\ttrain-auc:0.88644\n",
      "[404]\ttrain-auc:0.88653\n",
      "[405]\ttrain-auc:0.88657\n",
      "[406]\ttrain-auc:0.88662\n",
      "[407]\ttrain-auc:0.88668\n",
      "[408]\ttrain-auc:0.88673\n",
      "[409]\ttrain-auc:0.88677\n",
      "[410]\ttrain-auc:0.88681\n",
      "[411]\ttrain-auc:0.88687\n",
      "[412]\ttrain-auc:0.88693\n",
      "[413]\ttrain-auc:0.88699\n",
      "[414]\ttrain-auc:0.88704\n",
      "[415]\ttrain-auc:0.88709\n",
      "[416]\ttrain-auc:0.88717\n",
      "[417]\ttrain-auc:0.88721\n",
      "[418]\ttrain-auc:0.88727\n",
      "[419]\ttrain-auc:0.88734\n",
      "[420]\ttrain-auc:0.88738\n",
      "[421]\ttrain-auc:0.88744\n",
      "[422]\ttrain-auc:0.88748\n",
      "[423]\ttrain-auc:0.88758\n",
      "[424]\ttrain-auc:0.88762\n",
      "[425]\ttrain-auc:0.88769\n",
      "[426]\ttrain-auc:0.88775\n",
      "[427]\ttrain-auc:0.88782\n",
      "[428]\ttrain-auc:0.88787\n",
      "[429]\ttrain-auc:0.88795\n",
      "[430]\ttrain-auc:0.88802\n",
      "[431]\ttrain-auc:0.88810\n",
      "[432]\ttrain-auc:0.88815\n",
      "[433]\ttrain-auc:0.88821\n",
      "[434]\ttrain-auc:0.88826\n",
      "[435]\ttrain-auc:0.88830\n",
      "[436]\ttrain-auc:0.88837\n",
      "[437]\ttrain-auc:0.88843\n",
      "[438]\ttrain-auc:0.88849\n",
      "[439]\ttrain-auc:0.88860\n",
      "[440]\ttrain-auc:0.88868\n",
      "[441]\ttrain-auc:0.88876\n",
      "[442]\ttrain-auc:0.88884\n",
      "[443]\ttrain-auc:0.88889\n",
      "[444]\ttrain-auc:0.88895\n",
      "[445]\ttrain-auc:0.88901\n",
      "[446]\ttrain-auc:0.88905\n",
      "[447]\ttrain-auc:0.88911\n",
      "[448]\ttrain-auc:0.88923\n",
      "[449]\ttrain-auc:0.88929\n",
      "[450]\ttrain-auc:0.88935\n",
      "[451]\ttrain-auc:0.88940\n",
      "[452]\ttrain-auc:0.88946\n",
      "[453]\ttrain-auc:0.88951\n",
      "[454]\ttrain-auc:0.88957\n",
      "[455]\ttrain-auc:0.88960\n",
      "[456]\ttrain-auc:0.88968\n",
      "[457]\ttrain-auc:0.88977\n",
      "[458]\ttrain-auc:0.88986\n",
      "[459]\ttrain-auc:0.88996\n",
      "[460]\ttrain-auc:0.89004\n",
      "[461]\ttrain-auc:0.89011\n",
      "[462]\ttrain-auc:0.89021\n",
      "[463]\ttrain-auc:0.89030\n",
      "[464]\ttrain-auc:0.89034\n",
      "[465]\ttrain-auc:0.89043\n",
      "[466]\ttrain-auc:0.89049\n",
      "[467]\ttrain-auc:0.89054\n",
      "[468]\ttrain-auc:0.89061\n",
      "[469]\ttrain-auc:0.89066\n",
      "[470]\ttrain-auc:0.89072\n",
      "[471]\ttrain-auc:0.89083\n",
      "[472]\ttrain-auc:0.89088\n",
      "[473]\ttrain-auc:0.89092\n",
      "[474]\ttrain-auc:0.89096\n",
      "[475]\ttrain-auc:0.89104\n",
      "[476]\ttrain-auc:0.89109\n",
      "[477]\ttrain-auc:0.89116\n",
      "[478]\ttrain-auc:0.89123\n",
      "[479]\ttrain-auc:0.89128\n",
      "[480]\ttrain-auc:0.89134\n",
      "[481]\ttrain-auc:0.89138\n",
      "[482]\ttrain-auc:0.89142\n",
      "[483]\ttrain-auc:0.89149\n",
      "[484]\ttrain-auc:0.89155\n",
      "[485]\ttrain-auc:0.89162\n",
      "[486]\ttrain-auc:0.89167\n",
      "[487]\ttrain-auc:0.89176\n",
      "[488]\ttrain-auc:0.89191\n",
      "[489]\ttrain-auc:0.89194\n",
      "[490]\ttrain-auc:0.89198\n",
      "[491]\ttrain-auc:0.89205\n",
      "[492]\ttrain-auc:0.89219\n",
      "[493]\ttrain-auc:0.89226\n",
      "[494]\ttrain-auc:0.89230\n",
      "[495]\ttrain-auc:0.89238\n",
      "[496]\ttrain-auc:0.89242\n",
      "[497]\ttrain-auc:0.89250\n",
      "[498]\ttrain-auc:0.89259\n",
      "[499]\ttrain-auc:0.89267\n",
      "[500]\ttrain-auc:0.89273\n",
      "[501]\ttrain-auc:0.89281\n",
      "[502]\ttrain-auc:0.89289\n",
      "[503]\ttrain-auc:0.89294\n",
      "[504]\ttrain-auc:0.89301\n",
      "[505]\ttrain-auc:0.89312\n",
      "[506]\ttrain-auc:0.89319\n",
      "[507]\ttrain-auc:0.89324\n",
      "[508]\ttrain-auc:0.89329\n",
      "[509]\ttrain-auc:0.89337\n",
      "[510]\ttrain-auc:0.89345\n",
      "[511]\ttrain-auc:0.89353\n",
      "[512]\ttrain-auc:0.89357\n",
      "[513]\ttrain-auc:0.89365\n",
      "[514]\ttrain-auc:0.89373\n",
      "[515]\ttrain-auc:0.89380\n",
      "[516]\ttrain-auc:0.89389\n",
      "[517]\ttrain-auc:0.89397\n",
      "[518]\ttrain-auc:0.89402\n",
      "[519]\ttrain-auc:0.89411\n",
      "[520]\ttrain-auc:0.89419\n",
      "[521]\ttrain-auc:0.89426\n",
      "[522]\ttrain-auc:0.89433\n",
      "[523]\ttrain-auc:0.89441\n",
      "[524]\ttrain-auc:0.89446\n",
      "[525]\ttrain-auc:0.89451\n",
      "[526]\ttrain-auc:0.89458\n",
      "[527]\ttrain-auc:0.89466\n",
      "[528]\ttrain-auc:0.89474\n",
      "[529]\ttrain-auc:0.89480\n",
      "[530]\ttrain-auc:0.89487\n",
      "[531]\ttrain-auc:0.89495\n",
      "[532]\ttrain-auc:0.89502\n",
      "[533]\ttrain-auc:0.89507\n",
      "[534]\ttrain-auc:0.89514\n",
      "[535]\ttrain-auc:0.89518\n",
      "[536]\ttrain-auc:0.89526\n",
      "[537]\ttrain-auc:0.89531\n",
      "[538]\ttrain-auc:0.89536\n",
      "[539]\ttrain-auc:0.89540\n",
      "[540]\ttrain-auc:0.89545\n",
      "[541]\ttrain-auc:0.89550\n",
      "[542]\ttrain-auc:0.89560\n",
      "[543]\ttrain-auc:0.89565\n",
      "[544]\ttrain-auc:0.89570\n",
      "[545]\ttrain-auc:0.89575\n",
      "[546]\ttrain-auc:0.89583\n",
      "[547]\ttrain-auc:0.89589\n",
      "[548]\ttrain-auc:0.89594\n",
      "[549]\ttrain-auc:0.89600\n",
      "[550]\ttrain-auc:0.89605\n",
      "[551]\ttrain-auc:0.89616\n",
      "[552]\ttrain-auc:0.89621\n",
      "[553]\ttrain-auc:0.89632\n",
      "[554]\ttrain-auc:0.89635\n",
      "[555]\ttrain-auc:0.89640\n",
      "[556]\ttrain-auc:0.89647\n",
      "[557]\ttrain-auc:0.89659\n",
      "[558]\ttrain-auc:0.89665\n",
      "[559]\ttrain-auc:0.89675\n",
      "[560]\ttrain-auc:0.89680\n",
      "[561]\ttrain-auc:0.89683\n",
      "[562]\ttrain-auc:0.89693\n",
      "[563]\ttrain-auc:0.89706\n",
      "[564]\ttrain-auc:0.89709\n",
      "[565]\ttrain-auc:0.89713\n",
      "[566]\ttrain-auc:0.89720\n",
      "[567]\ttrain-auc:0.89727\n",
      "[568]\ttrain-auc:0.89732\n",
      "[569]\ttrain-auc:0.89736\n",
      "[570]\ttrain-auc:0.89741\n",
      "[571]\ttrain-auc:0.89745\n",
      "[572]\ttrain-auc:0.89756\n",
      "[573]\ttrain-auc:0.89766\n",
      "[574]\ttrain-auc:0.89772\n",
      "[575]\ttrain-auc:0.89782\n",
      "[576]\ttrain-auc:0.89790\n",
      "[577]\ttrain-auc:0.89795\n",
      "[578]\ttrain-auc:0.89804\n",
      "[579]\ttrain-auc:0.89810\n",
      "[580]\ttrain-auc:0.89819\n",
      "[581]\ttrain-auc:0.89823\n",
      "[582]\ttrain-auc:0.89829\n",
      "[583]\ttrain-auc:0.89841\n",
      "[584]\ttrain-auc:0.89845\n",
      "[585]\ttrain-auc:0.89850\n",
      "[586]\ttrain-auc:0.89858\n",
      "[587]\ttrain-auc:0.89864\n",
      "[588]\ttrain-auc:0.89868\n",
      "[589]\ttrain-auc:0.89879\n",
      "[590]\ttrain-auc:0.89885\n",
      "[591]\ttrain-auc:0.89891\n",
      "[592]\ttrain-auc:0.89901\n",
      "[593]\ttrain-auc:0.89908\n",
      "[594]\ttrain-auc:0.89914\n",
      "[595]\ttrain-auc:0.89919\n",
      "[596]\ttrain-auc:0.89928\n",
      "[597]\ttrain-auc:0.89934\n",
      "[598]\ttrain-auc:0.89940\n",
      "[599]\ttrain-auc:0.89949\n",
      "[600]\ttrain-auc:0.89957\n",
      "[601]\ttrain-auc:0.89963\n",
      "[602]\ttrain-auc:0.89969\n",
      "[603]\ttrain-auc:0.89976\n",
      "[604]\ttrain-auc:0.89982\n",
      "[605]\ttrain-auc:0.89988\n",
      "[606]\ttrain-auc:0.89995\n",
      "[607]\ttrain-auc:0.90000\n",
      "[608]\ttrain-auc:0.90007\n",
      "[609]\ttrain-auc:0.90012\n",
      "[610]\ttrain-auc:0.90018\n",
      "[611]\ttrain-auc:0.90024\n",
      "[612]\ttrain-auc:0.90030\n",
      "[613]\ttrain-auc:0.90037\n",
      "[614]\ttrain-auc:0.90044\n",
      "[615]\ttrain-auc:0.90051\n",
      "[616]\ttrain-auc:0.90062\n",
      "[617]\ttrain-auc:0.90069\n",
      "[618]\ttrain-auc:0.90078\n",
      "[619]\ttrain-auc:0.90087\n",
      "[620]\ttrain-auc:0.90097\n",
      "[621]\ttrain-auc:0.90105\n",
      "[622]\ttrain-auc:0.90114\n",
      "[623]\ttrain-auc:0.90121\n",
      "[624]\ttrain-auc:0.90131\n",
      "[625]\ttrain-auc:0.90137\n",
      "[626]\ttrain-auc:0.90147\n",
      "[627]\ttrain-auc:0.90153\n",
      "[628]\ttrain-auc:0.90163\n",
      "[629]\ttrain-auc:0.90173\n",
      "[630]\ttrain-auc:0.90180\n",
      "[631]\ttrain-auc:0.90186\n",
      "[632]\ttrain-auc:0.90191\n",
      "[633]\ttrain-auc:0.90202\n",
      "[634]\ttrain-auc:0.90210\n",
      "[635]\ttrain-auc:0.90216\n",
      "[636]\ttrain-auc:0.90223\n",
      "[637]\ttrain-auc:0.90229\n",
      "[638]\ttrain-auc:0.90233\n",
      "[639]\ttrain-auc:0.90238\n",
      "[640]\ttrain-auc:0.90243\n",
      "[641]\ttrain-auc:0.90249\n",
      "[642]\ttrain-auc:0.90256\n",
      "[643]\ttrain-auc:0.90262\n",
      "[644]\ttrain-auc:0.90269\n",
      "[645]\ttrain-auc:0.90274\n",
      "[646]\ttrain-auc:0.90283\n",
      "[647]\ttrain-auc:0.90293\n",
      "[648]\ttrain-auc:0.90297\n",
      "[649]\ttrain-auc:0.90300\n",
      "[650]\ttrain-auc:0.90305\n",
      "[651]\ttrain-auc:0.90311\n",
      "[652]\ttrain-auc:0.90314\n",
      "[653]\ttrain-auc:0.90318\n",
      "[654]\ttrain-auc:0.90328\n",
      "[655]\ttrain-auc:0.90337\n",
      "[656]\ttrain-auc:0.90349\n",
      "[657]\ttrain-auc:0.90357\n",
      "[658]\ttrain-auc:0.90364\n",
      "[659]\ttrain-auc:0.90373\n",
      "[660]\ttrain-auc:0.90378\n",
      "[661]\ttrain-auc:0.90382\n",
      "[662]\ttrain-auc:0.90387\n",
      "[663]\ttrain-auc:0.90390\n",
      "[664]\ttrain-auc:0.90396\n",
      "[665]\ttrain-auc:0.90405\n",
      "[666]\ttrain-auc:0.90411\n",
      "[667]\ttrain-auc:0.90419\n",
      "[668]\ttrain-auc:0.90425\n",
      "[669]\ttrain-auc:0.90432\n",
      "[670]\ttrain-auc:0.90436\n",
      "[671]\ttrain-auc:0.90446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[672]\ttrain-auc:0.90457\n",
      "[673]\ttrain-auc:0.90465\n",
      "[674]\ttrain-auc:0.90469\n",
      "[675]\ttrain-auc:0.90474\n",
      "[676]\ttrain-auc:0.90485\n",
      "[677]\ttrain-auc:0.90492\n",
      "[678]\ttrain-auc:0.90498\n",
      "[679]\ttrain-auc:0.90503\n",
      "[680]\ttrain-auc:0.90509\n",
      "[681]\ttrain-auc:0.90516\n",
      "[682]\ttrain-auc:0.90520\n",
      "[683]\ttrain-auc:0.90526\n",
      "[684]\ttrain-auc:0.90529\n",
      "[685]\ttrain-auc:0.90536\n",
      "[686]\ttrain-auc:0.90538\n",
      "[687]\ttrain-auc:0.90541\n",
      "[688]\ttrain-auc:0.90548\n",
      "[689]\ttrain-auc:0.90553\n",
      "[690]\ttrain-auc:0.90564\n",
      "[691]\ttrain-auc:0.90571\n",
      "[692]\ttrain-auc:0.90578\n",
      "[693]\ttrain-auc:0.90581\n",
      "[694]\ttrain-auc:0.90586\n",
      "[695]\ttrain-auc:0.90590\n",
      "[696]\ttrain-auc:0.90593\n",
      "[697]\ttrain-auc:0.90601\n",
      "[698]\ttrain-auc:0.90612\n",
      "[699]\ttrain-auc:0.90619\n",
      "[700]\ttrain-auc:0.90624\n",
      "[701]\ttrain-auc:0.90632\n",
      "[702]\ttrain-auc:0.90637\n",
      "[703]\ttrain-auc:0.90642\n",
      "[704]\ttrain-auc:0.90647\n",
      "[705]\ttrain-auc:0.90651\n",
      "[706]\ttrain-auc:0.90660\n",
      "[707]\ttrain-auc:0.90666\n",
      "[708]\ttrain-auc:0.90673\n",
      "[709]\ttrain-auc:0.90677\n",
      "[710]\ttrain-auc:0.90682\n",
      "[711]\ttrain-auc:0.90691\n",
      "[712]\ttrain-auc:0.90700\n",
      "[713]\ttrain-auc:0.90708\n",
      "[714]\ttrain-auc:0.90712\n",
      "[715]\ttrain-auc:0.90719\n",
      "[716]\ttrain-auc:0.90724\n",
      "[717]\ttrain-auc:0.90733\n",
      "[718]\ttrain-auc:0.90741\n",
      "[719]\ttrain-auc:0.90748\n",
      "[720]\ttrain-auc:0.90756\n",
      "[721]\ttrain-auc:0.90762\n",
      "[722]\ttrain-auc:0.90769\n",
      "[723]\ttrain-auc:0.90778\n",
      "[724]\ttrain-auc:0.90783\n",
      "[725]\ttrain-auc:0.90788\n",
      "[726]\ttrain-auc:0.90792\n",
      "[727]\ttrain-auc:0.90797\n",
      "[728]\ttrain-auc:0.90802\n",
      "[729]\ttrain-auc:0.90805\n",
      "[730]\ttrain-auc:0.90812\n",
      "[731]\ttrain-auc:0.90814\n",
      "[732]\ttrain-auc:0.90818\n",
      "[733]\ttrain-auc:0.90825\n",
      "[734]\ttrain-auc:0.90831\n",
      "[735]\ttrain-auc:0.90836\n",
      "[736]\ttrain-auc:0.90844\n",
      "[737]\ttrain-auc:0.90849\n",
      "[738]\ttrain-auc:0.90854\n",
      "[739]\ttrain-auc:0.90861\n",
      "[740]\ttrain-auc:0.90867\n",
      "[741]\ttrain-auc:0.90873\n",
      "[742]\ttrain-auc:0.90878\n",
      "[743]\ttrain-auc:0.90889\n",
      "[744]\ttrain-auc:0.90896\n",
      "[745]\ttrain-auc:0.90904\n",
      "[746]\ttrain-auc:0.90909\n",
      "[747]\ttrain-auc:0.90915\n",
      "[748]\ttrain-auc:0.90919\n",
      "[749]\ttrain-auc:0.90922\n",
      "[750]\ttrain-auc:0.90927\n",
      "[751]\ttrain-auc:0.90930\n",
      "[752]\ttrain-auc:0.90936\n",
      "[753]\ttrain-auc:0.90944\n",
      "[754]\ttrain-auc:0.90953\n",
      "[755]\ttrain-auc:0.90958\n",
      "[756]\ttrain-auc:0.90966\n",
      "[757]\ttrain-auc:0.90972\n",
      "[758]\ttrain-auc:0.90982\n",
      "[759]\ttrain-auc:0.90984\n",
      "[760]\ttrain-auc:0.90988\n",
      "[761]\ttrain-auc:0.90996\n",
      "[762]\ttrain-auc:0.91000\n",
      "[763]\ttrain-auc:0.91005\n",
      "[764]\ttrain-auc:0.91015\n",
      "[765]\ttrain-auc:0.91024\n",
      "[766]\ttrain-auc:0.91028\n",
      "[767]\ttrain-auc:0.91032\n",
      "[768]\ttrain-auc:0.91039\n",
      "[769]\ttrain-auc:0.91044\n",
      "[770]\ttrain-auc:0.91054\n",
      "[771]\ttrain-auc:0.91058\n",
      "[772]\ttrain-auc:0.91062\n",
      "[773]\ttrain-auc:0.91065\n",
      "[774]\ttrain-auc:0.91068\n",
      "[775]\ttrain-auc:0.91071\n",
      "[776]\ttrain-auc:0.91078\n",
      "[777]\ttrain-auc:0.91082\n",
      "[778]\ttrain-auc:0.91085\n",
      "[779]\ttrain-auc:0.91087\n",
      "[780]\ttrain-auc:0.91095\n",
      "[781]\ttrain-auc:0.91098\n",
      "[782]\ttrain-auc:0.91102\n",
      "[783]\ttrain-auc:0.91109\n",
      "[784]\ttrain-auc:0.91117\n",
      "[785]\ttrain-auc:0.91119\n",
      "[786]\ttrain-auc:0.91126\n",
      "[787]\ttrain-auc:0.91128\n",
      "[788]\ttrain-auc:0.91135\n",
      "[789]\ttrain-auc:0.91143\n",
      "[790]\ttrain-auc:0.91150\n",
      "[791]\ttrain-auc:0.91153\n",
      "[792]\ttrain-auc:0.91162\n",
      "[793]\ttrain-auc:0.91166\n",
      "[794]\ttrain-auc:0.91172\n",
      "[795]\ttrain-auc:0.91180\n",
      "[796]\ttrain-auc:0.91186\n",
      "[797]\ttrain-auc:0.91190\n",
      "[798]\ttrain-auc:0.91194\n",
      "[799]\ttrain-auc:0.91197\n",
      "[800]\ttrain-auc:0.91202\n",
      "[801]\ttrain-auc:0.91208\n",
      "[802]\ttrain-auc:0.91220\n",
      "[803]\ttrain-auc:0.91225\n",
      "[804]\ttrain-auc:0.91229\n",
      "[805]\ttrain-auc:0.91233\n",
      "[806]\ttrain-auc:0.91239\n",
      "[807]\ttrain-auc:0.91245\n",
      "[808]\ttrain-auc:0.91251\n",
      "[809]\ttrain-auc:0.91257\n",
      "[810]\ttrain-auc:0.91265\n",
      "[811]\ttrain-auc:0.91274\n",
      "[812]\ttrain-auc:0.91277\n",
      "[813]\ttrain-auc:0.91281\n",
      "[814]\ttrain-auc:0.91285\n",
      "[815]\ttrain-auc:0.91290\n",
      "[816]\ttrain-auc:0.91298\n",
      "[817]\ttrain-auc:0.91302\n",
      "[818]\ttrain-auc:0.91308\n",
      "[819]\ttrain-auc:0.91318\n",
      "[820]\ttrain-auc:0.91324\n",
      "[821]\ttrain-auc:0.91329\n",
      "[822]\ttrain-auc:0.91342\n",
      "[823]\ttrain-auc:0.91344\n",
      "[824]\ttrain-auc:0.91347\n",
      "[825]\ttrain-auc:0.91354\n",
      "[826]\ttrain-auc:0.91359\n",
      "[827]\ttrain-auc:0.91365\n",
      "[828]\ttrain-auc:0.91368\n",
      "[829]\ttrain-auc:0.91372\n",
      "[830]\ttrain-auc:0.91375\n",
      "[831]\ttrain-auc:0.91384\n",
      "[832]\ttrain-auc:0.91387\n",
      "[833]\ttrain-auc:0.91391\n",
      "[834]\ttrain-auc:0.91398\n",
      "[835]\ttrain-auc:0.91402\n",
      "[836]\ttrain-auc:0.91408\n",
      "[837]\ttrain-auc:0.91411\n",
      "[838]\ttrain-auc:0.91416\n",
      "[839]\ttrain-auc:0.91421\n",
      "[840]\ttrain-auc:0.91428\n",
      "[841]\ttrain-auc:0.91432\n",
      "[842]\ttrain-auc:0.91435\n",
      "[843]\ttrain-auc:0.91440\n",
      "[844]\ttrain-auc:0.91444\n",
      "[845]\ttrain-auc:0.91448\n",
      "[846]\ttrain-auc:0.91452\n",
      "[847]\ttrain-auc:0.91457\n",
      "[848]\ttrain-auc:0.91463\n",
      "[849]\ttrain-auc:0.91465\n",
      "[850]\ttrain-auc:0.91468\n",
      "[851]\ttrain-auc:0.91471\n",
      "[852]\ttrain-auc:0.91477\n",
      "[853]\ttrain-auc:0.91482\n",
      "[854]\ttrain-auc:0.91485\n",
      "[855]\ttrain-auc:0.91488\n",
      "[856]\ttrain-auc:0.91494\n",
      "[857]\ttrain-auc:0.91500\n",
      "[858]\ttrain-auc:0.91510\n",
      "[859]\ttrain-auc:0.91516\n",
      "[860]\ttrain-auc:0.91520\n",
      "[861]\ttrain-auc:0.91528\n",
      "[862]\ttrain-auc:0.91534\n",
      "[863]\ttrain-auc:0.91540\n",
      "[864]\ttrain-auc:0.91547\n",
      "[865]\ttrain-auc:0.91556\n",
      "[866]\ttrain-auc:0.91560\n",
      "[867]\ttrain-auc:0.91564\n",
      "[868]\ttrain-auc:0.91571\n",
      "[869]\ttrain-auc:0.91576\n",
      "[870]\ttrain-auc:0.91580\n",
      "[871]\ttrain-auc:0.91584\n",
      "[872]\ttrain-auc:0.91587\n",
      "[873]\ttrain-auc:0.91594\n",
      "[874]\ttrain-auc:0.91598\n",
      "[875]\ttrain-auc:0.91601\n",
      "[876]\ttrain-auc:0.91603\n",
      "[877]\ttrain-auc:0.91608\n",
      "[878]\ttrain-auc:0.91615\n",
      "[879]\ttrain-auc:0.91625\n",
      "[880]\ttrain-auc:0.91629\n",
      "[881]\ttrain-auc:0.91634\n",
      "[882]\ttrain-auc:0.91638\n",
      "[883]\ttrain-auc:0.91645\n",
      "[884]\ttrain-auc:0.91650\n",
      "[885]\ttrain-auc:0.91654\n",
      "[886]\ttrain-auc:0.91658\n",
      "[887]\ttrain-auc:0.91661\n",
      "[888]\ttrain-auc:0.91667\n",
      "[889]\ttrain-auc:0.91670\n",
      "[890]\ttrain-auc:0.91674\n",
      "[891]\ttrain-auc:0.91681\n",
      "[892]\ttrain-auc:0.91686\n",
      "[893]\ttrain-auc:0.91695\n",
      "[894]\ttrain-auc:0.91697\n",
      "[895]\ttrain-auc:0.91705\n",
      "[896]\ttrain-auc:0.91710\n",
      "[897]\ttrain-auc:0.91714\n",
      "[898]\ttrain-auc:0.91719\n",
      "[899]\ttrain-auc:0.91727\n",
      "[900]\ttrain-auc:0.91734\n",
      "[901]\ttrain-auc:0.91741\n",
      "[902]\ttrain-auc:0.91743\n",
      "[903]\ttrain-auc:0.91745\n",
      "[904]\ttrain-auc:0.91750\n",
      "[905]\ttrain-auc:0.91756\n",
      "[906]\ttrain-auc:0.91761\n",
      "[907]\ttrain-auc:0.91764\n",
      "[908]\ttrain-auc:0.91767\n",
      "[909]\ttrain-auc:0.91773\n",
      "[910]\ttrain-auc:0.91777\n",
      "[911]\ttrain-auc:0.91783\n",
      "[912]\ttrain-auc:0.91789\n",
      "[913]\ttrain-auc:0.91792\n",
      "[914]\ttrain-auc:0.91799\n",
      "[915]\ttrain-auc:0.91803\n",
      "[916]\ttrain-auc:0.91810\n",
      "[917]\ttrain-auc:0.91816\n",
      "[918]\ttrain-auc:0.91819\n",
      "[919]\ttrain-auc:0.91822\n",
      "[920]\ttrain-auc:0.91829\n",
      "[921]\ttrain-auc:0.91832\n",
      "[922]\ttrain-auc:0.91837\n",
      "[923]\ttrain-auc:0.91839\n",
      "[924]\ttrain-auc:0.91843\n",
      "[925]\ttrain-auc:0.91848\n",
      "[926]\ttrain-auc:0.91852\n",
      "[927]\ttrain-auc:0.91856\n",
      "[928]\ttrain-auc:0.91867\n",
      "[929]\ttrain-auc:0.91871\n",
      "[930]\ttrain-auc:0.91871\n",
      "[931]\ttrain-auc:0.91874\n",
      "[932]\ttrain-auc:0.91879\n",
      "[933]\ttrain-auc:0.91883\n",
      "[934]\ttrain-auc:0.91889\n",
      "[935]\ttrain-auc:0.91898\n",
      "[936]\ttrain-auc:0.91901\n",
      "[937]\ttrain-auc:0.91904\n",
      "[938]\ttrain-auc:0.91906\n",
      "[939]\ttrain-auc:0.91911\n",
      "[940]\ttrain-auc:0.91915\n",
      "[941]\ttrain-auc:0.91918\n",
      "[942]\ttrain-auc:0.91921\n",
      "[943]\ttrain-auc:0.91929\n",
      "[944]\ttrain-auc:0.91932\n",
      "[945]\ttrain-auc:0.91937\n",
      "[946]\ttrain-auc:0.91944\n",
      "[947]\ttrain-auc:0.91948\n",
      "[948]\ttrain-auc:0.91950\n",
      "[949]\ttrain-auc:0.91955\n",
      "[950]\ttrain-auc:0.91957\n",
      "[951]\ttrain-auc:0.91963\n",
      "[952]\ttrain-auc:0.91970\n",
      "[953]\ttrain-auc:0.91979\n",
      "[954]\ttrain-auc:0.91983\n",
      "[955]\ttrain-auc:0.91986\n",
      "[956]\ttrain-auc:0.91992\n",
      "[957]\ttrain-auc:0.91997\n",
      "[958]\ttrain-auc:0.92002\n",
      "[959]\ttrain-auc:0.92010\n",
      "[960]\ttrain-auc:0.92019\n",
      "[961]\ttrain-auc:0.92024\n",
      "[962]\ttrain-auc:0.92030\n",
      "[963]\ttrain-auc:0.92034\n",
      "[964]\ttrain-auc:0.92039\n",
      "[965]\ttrain-auc:0.92046\n",
      "[966]\ttrain-auc:0.92050\n",
      "[967]\ttrain-auc:0.92053\n",
      "[968]\ttrain-auc:0.92058\n",
      "[969]\ttrain-auc:0.92061\n",
      "[970]\ttrain-auc:0.92066\n",
      "[971]\ttrain-auc:0.92070\n",
      "[972]\ttrain-auc:0.92076\n",
      "[973]\ttrain-auc:0.92082\n",
      "[974]\ttrain-auc:0.92087\n",
      "[975]\ttrain-auc:0.92092\n",
      "[976]\ttrain-auc:0.92094\n",
      "[977]\ttrain-auc:0.92095\n",
      "[978]\ttrain-auc:0.92098\n",
      "[979]\ttrain-auc:0.92101\n",
      "[980]\ttrain-auc:0.92104\n",
      "[981]\ttrain-auc:0.92107\n",
      "[982]\ttrain-auc:0.92114\n",
      "[983]\ttrain-auc:0.92115\n",
      "[984]\ttrain-auc:0.92119\n",
      "[985]\ttrain-auc:0.92121\n",
      "[986]\ttrain-auc:0.92124\n",
      "[987]\ttrain-auc:0.92125\n",
      "[988]\ttrain-auc:0.92132\n",
      "[989]\ttrain-auc:0.92137\n",
      "[990]\ttrain-auc:0.92144\n",
      "[991]\ttrain-auc:0.92148\n",
      "[992]\ttrain-auc:0.92153\n",
      "[993]\ttrain-auc:0.92154\n",
      "[994]\ttrain-auc:0.92156\n",
      "[995]\ttrain-auc:0.92158\n",
      "[996]\ttrain-auc:0.92161\n",
      "[997]\ttrain-auc:0.92163\n",
      "[998]\ttrain-auc:0.92166\n",
      "[999]\ttrain-auc:0.92170\n"
     ]
    }
   ],
   "source": [
    "xgb_train2=xgb.DMatrix(pd.concat([train_x,df2],axis=1),train_y)\n",
    "watchlist = [(xgb_train2,'train')]\n",
    "xgbst = xgb.train(params,  \n",
    "                xgb_train2,  \n",
    "                num_boost_round=1000,\n",
    "                 evals=watchlist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = xgbst.predict(xgb.DMatrix(pd.concat([test_x,df_p2],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([train_x,test_x],axis=0))\n",
    "train_x_neu = scaler.transform(train_x)\n",
    "\n",
    "X, val_X, y, val_y = train_test_split(  \n",
    "    np.hstack((train_x_neu,df2)),  \n",
    "    train_y,  \n",
    "    test_size=0.2,  \n",
    "    random_state=1,  \n",
    "    stratify=train_y # 这里保证分割后y的比例分布与原数据一致  \n",
    ")  \n",
    "\n",
    "X_train = X  \n",
    "y_train = y  \n",
    "X_test = val_X  \n",
    "y_test = val_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/800\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.9363 - binary_accuracy: 0.3769 - val_loss: 0.7712 - val_binary_accuracy: 0.3706\n",
      "Epoch 2/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.8534 - binary_accuracy: 0.4312 - val_loss: 0.7040 - val_binary_accuracy: 0.4771\n",
      "Epoch 3/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.7804 - binary_accuracy: 0.4834 - val_loss: 0.6491 - val_binary_accuracy: 0.5927\n",
      "Epoch 4/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.7205 - binary_accuracy: 0.5410 - val_loss: 0.6053 - val_binary_accuracy: 0.6847\n",
      "Epoch 5/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.6738 - binary_accuracy: 0.5946 - val_loss: 0.5712 - val_binary_accuracy: 0.7455\n",
      "Epoch 6/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.6372 - binary_accuracy: 0.6335 - val_loss: 0.5449 - val_binary_accuracy: 0.7790\n",
      "Epoch 7/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.6081 - binary_accuracy: 0.6662 - val_loss: 0.5249 - val_binary_accuracy: 0.7913\n",
      "Epoch 8/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5856 - binary_accuracy: 0.6963 - val_loss: 0.5101 - val_binary_accuracy: 0.7942\n",
      "Epoch 9/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5701 - binary_accuracy: 0.7177 - val_loss: 0.4992 - val_binary_accuracy: 0.7953\n",
      "Epoch 10/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5546 - binary_accuracy: 0.7357 - val_loss: 0.4912 - val_binary_accuracy: 0.7961\n",
      "Epoch 11/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5461 - binary_accuracy: 0.7467 - val_loss: 0.4853 - val_binary_accuracy: 0.7961\n",
      "Epoch 12/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5367 - binary_accuracy: 0.7569 - val_loss: 0.4808 - val_binary_accuracy: 0.7961\n",
      "Epoch 13/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5320 - binary_accuracy: 0.7614 - val_loss: 0.4773 - val_binary_accuracy: 0.7961\n",
      "Epoch 14/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5261 - binary_accuracy: 0.7679 - val_loss: 0.4743 - val_binary_accuracy: 0.7961\n",
      "Epoch 15/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5239 - binary_accuracy: 0.7701 - val_loss: 0.4718 - val_binary_accuracy: 0.7961\n",
      "Epoch 16/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5228 - binary_accuracy: 0.7705 - val_loss: 0.4695 - val_binary_accuracy: 0.7961\n",
      "Epoch 17/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5181 - binary_accuracy: 0.7747 - val_loss: 0.4673 - val_binary_accuracy: 0.7961\n",
      "Epoch 18/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5142 - binary_accuracy: 0.7785 - val_loss: 0.4653 - val_binary_accuracy: 0.7961\n",
      "Epoch 19/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5107 - binary_accuracy: 0.7775 - val_loss: 0.4634 - val_binary_accuracy: 0.7961\n",
      "Epoch 20/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5103 - binary_accuracy: 0.7778 - val_loss: 0.4617 - val_binary_accuracy: 0.7961\n",
      "Epoch 21/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5073 - binary_accuracy: 0.7792 - val_loss: 0.4600 - val_binary_accuracy: 0.7961\n",
      "Epoch 22/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5057 - binary_accuracy: 0.7793 - val_loss: 0.4584 - val_binary_accuracy: 0.7961\n",
      "Epoch 23/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5018 - binary_accuracy: 0.7814 - val_loss: 0.4569 - val_binary_accuracy: 0.7961\n",
      "Epoch 24/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.5015 - binary_accuracy: 0.7820 - val_loss: 0.4555 - val_binary_accuracy: 0.7961\n",
      "Epoch 25/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4966 - binary_accuracy: 0.7835 - val_loss: 0.4541 - val_binary_accuracy: 0.7961\n",
      "Epoch 26/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4940 - binary_accuracy: 0.7823 - val_loss: 0.4528 - val_binary_accuracy: 0.7961\n",
      "Epoch 27/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4924 - binary_accuracy: 0.7821 - val_loss: 0.4515 - val_binary_accuracy: 0.7961\n",
      "Epoch 28/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4921 - binary_accuracy: 0.7838 - val_loss: 0.4503 - val_binary_accuracy: 0.7961\n",
      "Epoch 29/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4890 - binary_accuracy: 0.7843 - val_loss: 0.4492 - val_binary_accuracy: 0.7961\n",
      "Epoch 30/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4894 - binary_accuracy: 0.7851 - val_loss: 0.4480 - val_binary_accuracy: 0.7961\n",
      "Epoch 31/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4857 - binary_accuracy: 0.7846 - val_loss: 0.4469 - val_binary_accuracy: 0.7961\n",
      "Epoch 32/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4846 - binary_accuracy: 0.7864 - val_loss: 0.4459 - val_binary_accuracy: 0.7961\n",
      "Epoch 33/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4852 - binary_accuracy: 0.7873 - val_loss: 0.4449 - val_binary_accuracy: 0.7961\n",
      "Epoch 34/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4797 - binary_accuracy: 0.7865 - val_loss: 0.4439 - val_binary_accuracy: 0.7961\n",
      "Epoch 35/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4803 - binary_accuracy: 0.7885 - val_loss: 0.4429 - val_binary_accuracy: 0.7961\n",
      "Epoch 36/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4803 - binary_accuracy: 0.7898 - val_loss: 0.4420 - val_binary_accuracy: 0.7961\n",
      "Epoch 37/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4783 - binary_accuracy: 0.7885 - val_loss: 0.4412 - val_binary_accuracy: 0.7961\n",
      "Epoch 38/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4756 - binary_accuracy: 0.7878 - val_loss: 0.4403 - val_binary_accuracy: 0.7961\n",
      "Epoch 39/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4746 - binary_accuracy: 0.7893 - val_loss: 0.4395 - val_binary_accuracy: 0.7961\n",
      "Epoch 40/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4737 - binary_accuracy: 0.7891 - val_loss: 0.4387 - val_binary_accuracy: 0.7961\n",
      "Epoch 41/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4703 - binary_accuracy: 0.7901 - val_loss: 0.4379 - val_binary_accuracy: 0.7961\n",
      "Epoch 42/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4720 - binary_accuracy: 0.7890 - val_loss: 0.4372 - val_binary_accuracy: 0.7961\n",
      "Epoch 43/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4725 - binary_accuracy: 0.7894 - val_loss: 0.4364 - val_binary_accuracy: 0.7961\n",
      "Epoch 44/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4697 - binary_accuracy: 0.7896 - val_loss: 0.4356 - val_binary_accuracy: 0.7961\n",
      "Epoch 45/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4683 - binary_accuracy: 0.7910 - val_loss: 0.4349 - val_binary_accuracy: 0.7961\n",
      "Epoch 46/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4668 - binary_accuracy: 0.7913 - val_loss: 0.4342 - val_binary_accuracy: 0.7961\n",
      "Epoch 47/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4659 - binary_accuracy: 0.7914 - val_loss: 0.4335 - val_binary_accuracy: 0.7961\n",
      "Epoch 48/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4669 - binary_accuracy: 0.7904 - val_loss: 0.4328 - val_binary_accuracy: 0.7961\n",
      "Epoch 49/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4661 - binary_accuracy: 0.7909 - val_loss: 0.4321 - val_binary_accuracy: 0.7961\n",
      "Epoch 50/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4622 - binary_accuracy: 0.7919 - val_loss: 0.4314 - val_binary_accuracy: 0.7961\n",
      "Epoch 51/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4631 - binary_accuracy: 0.7909 - val_loss: 0.4308 - val_binary_accuracy: 0.7961\n",
      "Epoch 52/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4605 - binary_accuracy: 0.7919 - val_loss: 0.4302 - val_binary_accuracy: 0.7961\n",
      "Epoch 53/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4611 - binary_accuracy: 0.7920 - val_loss: 0.4296 - val_binary_accuracy: 0.7962\n",
      "Epoch 54/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4588 - binary_accuracy: 0.7935 - val_loss: 0.4290 - val_binary_accuracy: 0.7965\n",
      "Epoch 55/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4588 - binary_accuracy: 0.7929 - val_loss: 0.4284 - val_binary_accuracy: 0.7965\n",
      "Epoch 56/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4579 - binary_accuracy: 0.7917 - val_loss: 0.4278 - val_binary_accuracy: 0.7966\n",
      "Epoch 57/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4571 - binary_accuracy: 0.7922 - val_loss: 0.4273 - val_binary_accuracy: 0.7966\n",
      "Epoch 58/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4581 - binary_accuracy: 0.7927 - val_loss: 0.4267 - val_binary_accuracy: 0.7966\n",
      "Epoch 59/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4551 - binary_accuracy: 0.7938 - val_loss: 0.4262 - val_binary_accuracy: 0.7967\n",
      "Epoch 60/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4564 - binary_accuracy: 0.7936 - val_loss: 0.4257 - val_binary_accuracy: 0.7968\n",
      "Epoch 61/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4531 - binary_accuracy: 0.7942 - val_loss: 0.4252 - val_binary_accuracy: 0.7969\n",
      "Epoch 62/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4541 - binary_accuracy: 0.7930 - val_loss: 0.4247 - val_binary_accuracy: 0.7971\n",
      "Epoch 63/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4511 - binary_accuracy: 0.7933 - val_loss: 0.4242 - val_binary_accuracy: 0.7971\n",
      "Epoch 64/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4521 - binary_accuracy: 0.7932 - val_loss: 0.4237 - val_binary_accuracy: 0.7972\n",
      "Epoch 65/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4529 - binary_accuracy: 0.7927 - val_loss: 0.4232 - val_binary_accuracy: 0.7971\n",
      "Epoch 66/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4499 - binary_accuracy: 0.7940 - val_loss: 0.4228 - val_binary_accuracy: 0.7973\n",
      "Epoch 67/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4495 - binary_accuracy: 0.7934 - val_loss: 0.4223 - val_binary_accuracy: 0.7977\n",
      "Epoch 68/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4500 - binary_accuracy: 0.7929 - val_loss: 0.4218 - val_binary_accuracy: 0.7979\n",
      "Epoch 69/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4497 - binary_accuracy: 0.7951 - val_loss: 0.4214 - val_binary_accuracy: 0.7981\n",
      "Epoch 70/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4489 - binary_accuracy: 0.7947 - val_loss: 0.4209 - val_binary_accuracy: 0.7985\n",
      "Epoch 71/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4468 - binary_accuracy: 0.7943 - val_loss: 0.4205 - val_binary_accuracy: 0.7988\n",
      "Epoch 72/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4472 - binary_accuracy: 0.7954 - val_loss: 0.4201 - val_binary_accuracy: 0.7989\n",
      "Epoch 73/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4463 - binary_accuracy: 0.7954 - val_loss: 0.4197 - val_binary_accuracy: 0.7991\n",
      "Epoch 74/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4454 - binary_accuracy: 0.7952 - val_loss: 0.4192 - val_binary_accuracy: 0.7997\n",
      "Epoch 75/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4448 - binary_accuracy: 0.7945 - val_loss: 0.4188 - val_binary_accuracy: 0.8002\n",
      "Epoch 76/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4446 - binary_accuracy: 0.7946 - val_loss: 0.4184 - val_binary_accuracy: 0.7998\n",
      "Epoch 77/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4440 - binary_accuracy: 0.7954 - val_loss: 0.4180 - val_binary_accuracy: 0.7998\n",
      "Epoch 78/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4447 - binary_accuracy: 0.7954 - val_loss: 0.4177 - val_binary_accuracy: 0.8002\n",
      "Epoch 79/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4415 - binary_accuracy: 0.7959 - val_loss: 0.4173 - val_binary_accuracy: 0.8006\n",
      "Epoch 80/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4418 - binary_accuracy: 0.7956 - val_loss: 0.4170 - val_binary_accuracy: 0.8007\n",
      "Epoch 81/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4410 - binary_accuracy: 0.7961 - val_loss: 0.4166 - val_binary_accuracy: 0.8012\n",
      "Epoch 82/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4417 - binary_accuracy: 0.7950 - val_loss: 0.4163 - val_binary_accuracy: 0.8018\n",
      "Epoch 83/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4385 - binary_accuracy: 0.7975 - val_loss: 0.4159 - val_binary_accuracy: 0.8018\n",
      "Epoch 84/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4398 - binary_accuracy: 0.7955 - val_loss: 0.4156 - val_binary_accuracy: 0.8023\n",
      "Epoch 85/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4399 - binary_accuracy: 0.7965 - val_loss: 0.4153 - val_binary_accuracy: 0.8026\n",
      "Epoch 86/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4392 - binary_accuracy: 0.7974 - val_loss: 0.4150 - val_binary_accuracy: 0.8033\n",
      "Epoch 87/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4404 - binary_accuracy: 0.7975 - val_loss: 0.4148 - val_binary_accuracy: 0.8039\n",
      "Epoch 88/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4375 - binary_accuracy: 0.7974 - val_loss: 0.4146 - val_binary_accuracy: 0.8045\n",
      "Epoch 89/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4367 - binary_accuracy: 0.7973 - val_loss: 0.4143 - val_binary_accuracy: 0.8049\n",
      "Epoch 90/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4396 - binary_accuracy: 0.7967 - val_loss: 0.4140 - val_binary_accuracy: 0.8049\n",
      "Epoch 91/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4378 - binary_accuracy: 0.7972 - val_loss: 0.4137 - val_binary_accuracy: 0.8048\n",
      "Epoch 92/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4361 - binary_accuracy: 0.7961 - val_loss: 0.4134 - val_binary_accuracy: 0.8050\n",
      "Epoch 93/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4361 - binary_accuracy: 0.7981 - val_loss: 0.4132 - val_binary_accuracy: 0.8052\n",
      "Epoch 94/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4371 - binary_accuracy: 0.7968 - val_loss: 0.4129 - val_binary_accuracy: 0.8052\n",
      "Epoch 95/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4361 - binary_accuracy: 0.7976 - val_loss: 0.4126 - val_binary_accuracy: 0.8053\n",
      "Epoch 96/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4362 - binary_accuracy: 0.7981 - val_loss: 0.4123 - val_binary_accuracy: 0.8060\n",
      "Epoch 97/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4373 - binary_accuracy: 0.7968 - val_loss: 0.4120 - val_binary_accuracy: 0.8065\n",
      "Epoch 98/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4332 - binary_accuracy: 0.7988 - val_loss: 0.4118 - val_binary_accuracy: 0.8067\n",
      "Epoch 99/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4346 - binary_accuracy: 0.7986 - val_loss: 0.4115 - val_binary_accuracy: 0.8068\n",
      "Epoch 100/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4349 - binary_accuracy: 0.7979 - val_loss: 0.4112 - val_binary_accuracy: 0.8067\n",
      "Epoch 101/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4333 - binary_accuracy: 0.7979 - val_loss: 0.4110 - val_binary_accuracy: 0.8067\n",
      "Epoch 102/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4314 - binary_accuracy: 0.7989 - val_loss: 0.4107 - val_binary_accuracy: 0.8071\n",
      "Epoch 103/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4320 - binary_accuracy: 0.7987 - val_loss: 0.4104 - val_binary_accuracy: 0.8072\n",
      "Epoch 104/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4323 - binary_accuracy: 0.7981 - val_loss: 0.4102 - val_binary_accuracy: 0.8075\n",
      "Epoch 105/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4328 - binary_accuracy: 0.7985 - val_loss: 0.4100 - val_binary_accuracy: 0.8077\n",
      "Epoch 106/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4315 - binary_accuracy: 0.7993 - val_loss: 0.4099 - val_binary_accuracy: 0.8082\n",
      "Epoch 107/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4311 - binary_accuracy: 0.7992 - val_loss: 0.4097 - val_binary_accuracy: 0.8087\n",
      "Epoch 108/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4321 - binary_accuracy: 0.7990 - val_loss: 0.4095 - val_binary_accuracy: 0.8093\n",
      "Epoch 109/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4322 - binary_accuracy: 0.8004 - val_loss: 0.4094 - val_binary_accuracy: 0.8092\n",
      "Epoch 110/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4293 - binary_accuracy: 0.8003 - val_loss: 0.4093 - val_binary_accuracy: 0.8097\n",
      "Epoch 111/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4310 - binary_accuracy: 0.7991 - val_loss: 0.4091 - val_binary_accuracy: 0.8102\n",
      "Epoch 112/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4287 - binary_accuracy: 0.8002 - val_loss: 0.4089 - val_binary_accuracy: 0.8105\n",
      "Epoch 113/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4307 - binary_accuracy: 0.8003 - val_loss: 0.4087 - val_binary_accuracy: 0.8108\n",
      "Epoch 114/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4281 - binary_accuracy: 0.7993 - val_loss: 0.4084 - val_binary_accuracy: 0.8109\n",
      "Epoch 115/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4289 - binary_accuracy: 0.7977 - val_loss: 0.4082 - val_binary_accuracy: 0.8110\n",
      "Epoch 116/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4291 - binary_accuracy: 0.7991 - val_loss: 0.4080 - val_binary_accuracy: 0.8113\n",
      "Epoch 117/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4282 - binary_accuracy: 0.7996 - val_loss: 0.4078 - val_binary_accuracy: 0.8114\n",
      "Epoch 118/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4271 - binary_accuracy: 0.8009 - val_loss: 0.4076 - val_binary_accuracy: 0.8115\n",
      "Epoch 119/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4271 - binary_accuracy: 0.7998 - val_loss: 0.4074 - val_binary_accuracy: 0.8117\n",
      "Epoch 120/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4281 - binary_accuracy: 0.8013 - val_loss: 0.4072 - val_binary_accuracy: 0.8120\n",
      "Epoch 121/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4283 - binary_accuracy: 0.8008 - val_loss: 0.4071 - val_binary_accuracy: 0.8122\n",
      "Epoch 122/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4271 - binary_accuracy: 0.7993 - val_loss: 0.4069 - val_binary_accuracy: 0.8123\n",
      "Epoch 123/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4255 - binary_accuracy: 0.8006 - val_loss: 0.4067 - val_binary_accuracy: 0.8124\n",
      "Epoch 124/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4261 - binary_accuracy: 0.8008 - val_loss: 0.4065 - val_binary_accuracy: 0.8127\n",
      "Epoch 125/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4261 - binary_accuracy: 0.8021 - val_loss: 0.4063 - val_binary_accuracy: 0.8128\n",
      "Epoch 126/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4251 - binary_accuracy: 0.8015 - val_loss: 0.4061 - val_binary_accuracy: 0.8128\n",
      "Epoch 127/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4278 - binary_accuracy: 0.8022 - val_loss: 0.4059 - val_binary_accuracy: 0.8130\n",
      "Epoch 128/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4249 - binary_accuracy: 0.8017 - val_loss: 0.4058 - val_binary_accuracy: 0.8128\n",
      "Epoch 129/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4234 - binary_accuracy: 0.8032 - val_loss: 0.4057 - val_binary_accuracy: 0.8130\n",
      "Epoch 130/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4264 - binary_accuracy: 0.8020 - val_loss: 0.4056 - val_binary_accuracy: 0.8135\n",
      "Epoch 131/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4238 - binary_accuracy: 0.8025 - val_loss: 0.4054 - val_binary_accuracy: 0.8138\n",
      "Epoch 132/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4250 - binary_accuracy: 0.8013 - val_loss: 0.4052 - val_binary_accuracy: 0.8138\n",
      "Epoch 133/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4226 - binary_accuracy: 0.8043 - val_loss: 0.4050 - val_binary_accuracy: 0.8141\n",
      "Epoch 134/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4220 - binary_accuracy: 0.8019 - val_loss: 0.4049 - val_binary_accuracy: 0.8141\n",
      "Epoch 135/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4230 - binary_accuracy: 0.8026 - val_loss: 0.4048 - val_binary_accuracy: 0.8137\n",
      "Epoch 136/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4238 - binary_accuracy: 0.8013 - val_loss: 0.4047 - val_binary_accuracy: 0.8144\n",
      "Epoch 137/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4235 - binary_accuracy: 0.8027 - val_loss: 0.4046 - val_binary_accuracy: 0.8142\n",
      "Epoch 138/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4234 - binary_accuracy: 0.8025 - val_loss: 0.4044 - val_binary_accuracy: 0.8143\n",
      "Epoch 139/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4223 - binary_accuracy: 0.8037 - val_loss: 0.4043 - val_binary_accuracy: 0.8146\n",
      "Epoch 140/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4227 - binary_accuracy: 0.8024 - val_loss: 0.4041 - val_binary_accuracy: 0.8146\n",
      "Epoch 141/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4218 - binary_accuracy: 0.8027 - val_loss: 0.4040 - val_binary_accuracy: 0.8147\n",
      "Epoch 142/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4198 - binary_accuracy: 0.8034 - val_loss: 0.4038 - val_binary_accuracy: 0.8147\n",
      "Epoch 143/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4207 - binary_accuracy: 0.8028 - val_loss: 0.4037 - val_binary_accuracy: 0.8149\n",
      "Epoch 144/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4217 - binary_accuracy: 0.8044 - val_loss: 0.4035 - val_binary_accuracy: 0.8153\n",
      "Epoch 145/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4195 - binary_accuracy: 0.8041 - val_loss: 0.4034 - val_binary_accuracy: 0.8153\n",
      "Epoch 146/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4218 - binary_accuracy: 0.8031 - val_loss: 0.4033 - val_binary_accuracy: 0.8152\n",
      "Epoch 147/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4200 - binary_accuracy: 0.8030 - val_loss: 0.4031 - val_binary_accuracy: 0.8154\n",
      "Epoch 148/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4199 - binary_accuracy: 0.8049 - val_loss: 0.4030 - val_binary_accuracy: 0.8157\n",
      "Epoch 149/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4187 - binary_accuracy: 0.8047 - val_loss: 0.4028 - val_binary_accuracy: 0.8158\n",
      "Epoch 150/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4191 - binary_accuracy: 0.8053 - val_loss: 0.4027 - val_binary_accuracy: 0.8160\n",
      "Epoch 151/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4201 - binary_accuracy: 0.8052 - val_loss: 0.4025 - val_binary_accuracy: 0.8159\n",
      "Epoch 152/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4174 - binary_accuracy: 0.8068 - val_loss: 0.4024 - val_binary_accuracy: 0.8159\n",
      "Epoch 153/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4182 - binary_accuracy: 0.8047 - val_loss: 0.4023 - val_binary_accuracy: 0.8159\n",
      "Epoch 154/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4180 - binary_accuracy: 0.8062 - val_loss: 0.4022 - val_binary_accuracy: 0.8162\n",
      "Epoch 155/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4184 - binary_accuracy: 0.8057 - val_loss: 0.4021 - val_binary_accuracy: 0.8162\n",
      "Epoch 156/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4172 - binary_accuracy: 0.8057 - val_loss: 0.4020 - val_binary_accuracy: 0.8165\n",
      "Epoch 157/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4191 - binary_accuracy: 0.8041 - val_loss: 0.4019 - val_binary_accuracy: 0.8163\n",
      "Epoch 158/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4184 - binary_accuracy: 0.8048 - val_loss: 0.4017 - val_binary_accuracy: 0.8162\n",
      "Epoch 159/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4173 - binary_accuracy: 0.8043 - val_loss: 0.4016 - val_binary_accuracy: 0.8165\n",
      "Epoch 160/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4178 - binary_accuracy: 0.8045 - val_loss: 0.4015 - val_binary_accuracy: 0.8165\n",
      "Epoch 161/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4165 - binary_accuracy: 0.8067 - val_loss: 0.4013 - val_binary_accuracy: 0.8164\n",
      "Epoch 162/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4168 - binary_accuracy: 0.8062 - val_loss: 0.4012 - val_binary_accuracy: 0.8162\n",
      "Epoch 163/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4158 - binary_accuracy: 0.8080 - val_loss: 0.4011 - val_binary_accuracy: 0.8164\n",
      "Epoch 164/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4174 - binary_accuracy: 0.8056 - val_loss: 0.4010 - val_binary_accuracy: 0.8168\n",
      "Epoch 165/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4154 - binary_accuracy: 0.8066 - val_loss: 0.4009 - val_binary_accuracy: 0.8168\n",
      "Epoch 166/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4159 - binary_accuracy: 0.8048 - val_loss: 0.4008 - val_binary_accuracy: 0.8172\n",
      "Epoch 167/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4161 - binary_accuracy: 0.8073 - val_loss: 0.4007 - val_binary_accuracy: 0.8174\n",
      "Epoch 168/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4170 - binary_accuracy: 0.8059 - val_loss: 0.4005 - val_binary_accuracy: 0.8177\n",
      "Epoch 169/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4132 - binary_accuracy: 0.8059 - val_loss: 0.4003 - val_binary_accuracy: 0.8177\n",
      "Epoch 170/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4143 - binary_accuracy: 0.8060 - val_loss: 0.4002 - val_binary_accuracy: 0.8177\n",
      "Epoch 171/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4163 - binary_accuracy: 0.8043 - val_loss: 0.4001 - val_binary_accuracy: 0.8179\n",
      "Epoch 172/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4139 - binary_accuracy: 0.8059 - val_loss: 0.4000 - val_binary_accuracy: 0.8181\n",
      "Epoch 173/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4151 - binary_accuracy: 0.8060 - val_loss: 0.3999 - val_binary_accuracy: 0.8183\n",
      "Epoch 174/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4137 - binary_accuracy: 0.8073 - val_loss: 0.3999 - val_binary_accuracy: 0.8183\n",
      "Epoch 175/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4148 - binary_accuracy: 0.8076 - val_loss: 0.3997 - val_binary_accuracy: 0.8182\n",
      "Epoch 176/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4143 - binary_accuracy: 0.8052 - val_loss: 0.3996 - val_binary_accuracy: 0.8183\n",
      "Epoch 177/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4139 - binary_accuracy: 0.8071 - val_loss: 0.3995 - val_binary_accuracy: 0.8187\n",
      "Epoch 178/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4126 - binary_accuracy: 0.8051 - val_loss: 0.3993 - val_binary_accuracy: 0.8187\n",
      "Epoch 179/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4128 - binary_accuracy: 0.8072 - val_loss: 0.3992 - val_binary_accuracy: 0.8189\n",
      "Epoch 180/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4152 - binary_accuracy: 0.8069 - val_loss: 0.3991 - val_binary_accuracy: 0.8189\n",
      "Epoch 181/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4122 - binary_accuracy: 0.8082 - val_loss: 0.3990 - val_binary_accuracy: 0.8190\n",
      "Epoch 182/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4135 - binary_accuracy: 0.8082 - val_loss: 0.3989 - val_binary_accuracy: 0.8189\n",
      "Epoch 183/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4109 - binary_accuracy: 0.8083 - val_loss: 0.3988 - val_binary_accuracy: 0.8187\n",
      "Epoch 184/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4116 - binary_accuracy: 0.8089 - val_loss: 0.3987 - val_binary_accuracy: 0.8189\n",
      "Epoch 185/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4115 - binary_accuracy: 0.8089 - val_loss: 0.3985 - val_binary_accuracy: 0.8188\n",
      "Epoch 186/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4127 - binary_accuracy: 0.8073 - val_loss: 0.3984 - val_binary_accuracy: 0.8188\n",
      "Epoch 187/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4122 - binary_accuracy: 0.8090 - val_loss: 0.3983 - val_binary_accuracy: 0.8192\n",
      "Epoch 188/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4104 - binary_accuracy: 0.8085 - val_loss: 0.3982 - val_binary_accuracy: 0.8195\n",
      "Epoch 189/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4135 - binary_accuracy: 0.8072 - val_loss: 0.3981 - val_binary_accuracy: 0.8197\n",
      "Epoch 190/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4115 - binary_accuracy: 0.8078 - val_loss: 0.3980 - val_binary_accuracy: 0.8201\n",
      "Epoch 191/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4094 - binary_accuracy: 0.8092 - val_loss: 0.3979 - val_binary_accuracy: 0.8200\n",
      "Epoch 192/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4108 - binary_accuracy: 0.8081 - val_loss: 0.3978 - val_binary_accuracy: 0.8197\n",
      "Epoch 193/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4114 - binary_accuracy: 0.8087 - val_loss: 0.3977 - val_binary_accuracy: 0.8199\n",
      "Epoch 194/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4109 - binary_accuracy: 0.8099 - val_loss: 0.3976 - val_binary_accuracy: 0.8201\n",
      "Epoch 195/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4098 - binary_accuracy: 0.8106 - val_loss: 0.3974 - val_binary_accuracy: 0.8200\n",
      "Epoch 196/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4112 - binary_accuracy: 0.8086 - val_loss: 0.3974 - val_binary_accuracy: 0.8200\n",
      "Epoch 197/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.4100 - binary_accuracy: 0.8090 - val_loss: 0.3973 - val_binary_accuracy: 0.8203\n",
      "Epoch 198/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4098 - binary_accuracy: 0.8102 - val_loss: 0.3972 - val_binary_accuracy: 0.8203\n",
      "Epoch 199/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4087 - binary_accuracy: 0.8086 - val_loss: 0.3970 - val_binary_accuracy: 0.8204\n",
      "Epoch 200/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4088 - binary_accuracy: 0.8076 - val_loss: 0.3969 - val_binary_accuracy: 0.8204\n",
      "Epoch 201/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4090 - binary_accuracy: 0.8099 - val_loss: 0.3968 - val_binary_accuracy: 0.8203\n",
      "Epoch 202/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4094 - binary_accuracy: 0.8095 - val_loss: 0.3967 - val_binary_accuracy: 0.8203\n",
      "Epoch 203/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4093 - binary_accuracy: 0.8095 - val_loss: 0.3966 - val_binary_accuracy: 0.8204\n",
      "Epoch 204/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4094 - binary_accuracy: 0.8092 - val_loss: 0.3965 - val_binary_accuracy: 0.8208\n",
      "Epoch 205/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4086 - binary_accuracy: 0.8100 - val_loss: 0.3964 - val_binary_accuracy: 0.8207\n",
      "Epoch 206/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4101 - binary_accuracy: 0.8098 - val_loss: 0.3963 - val_binary_accuracy: 0.8209\n",
      "Epoch 207/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4074 - binary_accuracy: 0.8118 - val_loss: 0.3963 - val_binary_accuracy: 0.8207\n",
      "Epoch 208/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4076 - binary_accuracy: 0.8104 - val_loss: 0.3963 - val_binary_accuracy: 0.8208\n",
      "Epoch 209/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4077 - binary_accuracy: 0.8086 - val_loss: 0.3961 - val_binary_accuracy: 0.8209\n",
      "Epoch 210/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4079 - binary_accuracy: 0.8090 - val_loss: 0.3960 - val_binary_accuracy: 0.8210\n",
      "Epoch 211/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4066 - binary_accuracy: 0.8114 - val_loss: 0.3958 - val_binary_accuracy: 0.8212\n",
      "Epoch 212/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4075 - binary_accuracy: 0.8122 - val_loss: 0.3957 - val_binary_accuracy: 0.8211\n",
      "Epoch 213/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4078 - binary_accuracy: 0.8096 - val_loss: 0.3956 - val_binary_accuracy: 0.8210\n",
      "Epoch 214/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4071 - binary_accuracy: 0.8105 - val_loss: 0.3956 - val_binary_accuracy: 0.8209\n",
      "Epoch 215/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4068 - binary_accuracy: 0.8119 - val_loss: 0.3955 - val_binary_accuracy: 0.8209\n",
      "Epoch 216/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4070 - binary_accuracy: 0.8114 - val_loss: 0.3953 - val_binary_accuracy: 0.8210\n",
      "Epoch 217/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4056 - binary_accuracy: 0.8112 - val_loss: 0.3952 - val_binary_accuracy: 0.8208\n",
      "Epoch 218/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4071 - binary_accuracy: 0.8108 - val_loss: 0.3950 - val_binary_accuracy: 0.8206\n",
      "Epoch 219/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4053 - binary_accuracy: 0.8111 - val_loss: 0.3949 - val_binary_accuracy: 0.8204\n",
      "Epoch 220/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4055 - binary_accuracy: 0.8120 - val_loss: 0.3948 - val_binary_accuracy: 0.8204\n",
      "Epoch 221/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4063 - binary_accuracy: 0.8099 - val_loss: 0.3947 - val_binary_accuracy: 0.8203\n",
      "Epoch 222/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4038 - binary_accuracy: 0.8124 - val_loss: 0.3947 - val_binary_accuracy: 0.8199\n",
      "Epoch 223/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4051 - binary_accuracy: 0.8129 - val_loss: 0.3945 - val_binary_accuracy: 0.8198\n",
      "Epoch 224/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4060 - binary_accuracy: 0.8110 - val_loss: 0.3944 - val_binary_accuracy: 0.8201\n",
      "Epoch 225/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4043 - binary_accuracy: 0.8115 - val_loss: 0.3944 - val_binary_accuracy: 0.8202\n",
      "Epoch 226/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4044 - binary_accuracy: 0.8121 - val_loss: 0.3942 - val_binary_accuracy: 0.8202\n",
      "Epoch 227/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4050 - binary_accuracy: 0.8129 - val_loss: 0.3942 - val_binary_accuracy: 0.8202\n",
      "Epoch 228/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4049 - binary_accuracy: 0.8114 - val_loss: 0.3941 - val_binary_accuracy: 0.8203\n",
      "Epoch 229/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4058 - binary_accuracy: 0.8119 - val_loss: 0.3940 - val_binary_accuracy: 0.8207\n",
      "Epoch 230/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4041 - binary_accuracy: 0.8117 - val_loss: 0.3939 - val_binary_accuracy: 0.8211\n",
      "Epoch 231/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4036 - binary_accuracy: 0.8127 - val_loss: 0.3938 - val_binary_accuracy: 0.8213\n",
      "Epoch 232/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4042 - binary_accuracy: 0.8129 - val_loss: 0.3937 - val_binary_accuracy: 0.8212\n",
      "Epoch 233/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4059 - binary_accuracy: 0.8119 - val_loss: 0.3936 - val_binary_accuracy: 0.8212\n",
      "Epoch 234/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4043 - binary_accuracy: 0.8141 - val_loss: 0.3935 - val_binary_accuracy: 0.8217\n",
      "Epoch 235/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4051 - binary_accuracy: 0.8129 - val_loss: 0.3935 - val_binary_accuracy: 0.8217\n",
      "Epoch 236/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4053 - binary_accuracy: 0.8129 - val_loss: 0.3934 - val_binary_accuracy: 0.8220\n",
      "Epoch 237/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4026 - binary_accuracy: 0.8121 - val_loss: 0.3934 - val_binary_accuracy: 0.8219\n",
      "Epoch 238/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4033 - binary_accuracy: 0.8129 - val_loss: 0.3932 - val_binary_accuracy: 0.8223\n",
      "Epoch 239/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4029 - binary_accuracy: 0.8123 - val_loss: 0.3930 - val_binary_accuracy: 0.8222\n",
      "Epoch 240/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4033 - binary_accuracy: 0.8133 - val_loss: 0.3929 - val_binary_accuracy: 0.8220\n",
      "Epoch 241/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4013 - binary_accuracy: 0.8144 - val_loss: 0.3928 - val_binary_accuracy: 0.8223\n",
      "Epoch 242/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4019 - binary_accuracy: 0.8135 - val_loss: 0.3926 - val_binary_accuracy: 0.8221\n",
      "Epoch 243/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4002 - binary_accuracy: 0.8137 - val_loss: 0.3925 - val_binary_accuracy: 0.8222\n",
      "Epoch 244/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4025 - binary_accuracy: 0.8137 - val_loss: 0.3924 - val_binary_accuracy: 0.8224\n",
      "Epoch 245/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3998 - binary_accuracy: 0.8129 - val_loss: 0.3924 - val_binary_accuracy: 0.8226\n",
      "Epoch 246/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4035 - binary_accuracy: 0.8138 - val_loss: 0.3923 - val_binary_accuracy: 0.8222\n",
      "Epoch 247/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4021 - binary_accuracy: 0.8139 - val_loss: 0.3923 - val_binary_accuracy: 0.8218\n",
      "Epoch 248/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4000 - binary_accuracy: 0.8133 - val_loss: 0.3922 - val_binary_accuracy: 0.8215\n",
      "Epoch 249/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4021 - binary_accuracy: 0.8137 - val_loss: 0.3921 - val_binary_accuracy: 0.8218\n",
      "Epoch 250/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4015 - binary_accuracy: 0.8131 - val_loss: 0.3920 - val_binary_accuracy: 0.8223\n",
      "Epoch 251/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4031 - binary_accuracy: 0.8139 - val_loss: 0.3919 - val_binary_accuracy: 0.8227\n",
      "Epoch 252/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4041 - binary_accuracy: 0.8134 - val_loss: 0.3918 - val_binary_accuracy: 0.8228\n",
      "Epoch 253/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4004 - binary_accuracy: 0.8150 - val_loss: 0.3918 - val_binary_accuracy: 0.8229\n",
      "Epoch 254/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4018 - binary_accuracy: 0.8146 - val_loss: 0.3916 - val_binary_accuracy: 0.8230\n",
      "Epoch 255/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4010 - binary_accuracy: 0.8143 - val_loss: 0.3915 - val_binary_accuracy: 0.8230\n",
      "Epoch 256/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3990 - binary_accuracy: 0.8142 - val_loss: 0.3914 - val_binary_accuracy: 0.8233\n",
      "Epoch 257/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4013 - binary_accuracy: 0.8143 - val_loss: 0.3912 - val_binary_accuracy: 0.8232\n",
      "Epoch 258/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3999 - binary_accuracy: 0.8155 - val_loss: 0.3911 - val_binary_accuracy: 0.8232\n",
      "Epoch 259/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4003 - binary_accuracy: 0.8149 - val_loss: 0.3911 - val_binary_accuracy: 0.8233\n",
      "Epoch 260/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4002 - binary_accuracy: 0.8138 - val_loss: 0.3910 - val_binary_accuracy: 0.8238\n",
      "Epoch 261/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4016 - binary_accuracy: 0.8161 - val_loss: 0.3910 - val_binary_accuracy: 0.8232\n",
      "Epoch 262/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4012 - binary_accuracy: 0.8154 - val_loss: 0.3909 - val_binary_accuracy: 0.8236\n",
      "Epoch 263/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.4003 - binary_accuracy: 0.8145 - val_loss: 0.3909 - val_binary_accuracy: 0.8233\n",
      "Epoch 264/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3991 - binary_accuracy: 0.8154 - val_loss: 0.3908 - val_binary_accuracy: 0.8235\n",
      "Epoch 265/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3982 - binary_accuracy: 0.8168 - val_loss: 0.3906 - val_binary_accuracy: 0.8236\n",
      "Epoch 266/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3996 - binary_accuracy: 0.8159 - val_loss: 0.3905 - val_binary_accuracy: 0.8235\n",
      "Epoch 267/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3993 - binary_accuracy: 0.8155 - val_loss: 0.3904 - val_binary_accuracy: 0.8237\n",
      "Epoch 268/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3991 - binary_accuracy: 0.8147 - val_loss: 0.3903 - val_binary_accuracy: 0.8238\n",
      "Epoch 269/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3994 - binary_accuracy: 0.8146 - val_loss: 0.3902 - val_binary_accuracy: 0.8238\n",
      "Epoch 270/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3987 - binary_accuracy: 0.8147 - val_loss: 0.3901 - val_binary_accuracy: 0.8240\n",
      "Epoch 271/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3981 - binary_accuracy: 0.8157 - val_loss: 0.3900 - val_binary_accuracy: 0.8242\n",
      "Epoch 272/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3987 - binary_accuracy: 0.8149 - val_loss: 0.3899 - val_binary_accuracy: 0.8243\n",
      "Epoch 273/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3981 - binary_accuracy: 0.8158 - val_loss: 0.3898 - val_binary_accuracy: 0.8245\n",
      "Epoch 274/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3977 - binary_accuracy: 0.8152 - val_loss: 0.3897 - val_binary_accuracy: 0.8242\n",
      "Epoch 275/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3992 - binary_accuracy: 0.8152 - val_loss: 0.3896 - val_binary_accuracy: 0.8248\n",
      "Epoch 276/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3980 - binary_accuracy: 0.8167 - val_loss: 0.3896 - val_binary_accuracy: 0.8248\n",
      "Epoch 277/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3983 - binary_accuracy: 0.8169 - val_loss: 0.3895 - val_binary_accuracy: 0.8249\n",
      "Epoch 278/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3990 - binary_accuracy: 0.8156 - val_loss: 0.3894 - val_binary_accuracy: 0.8251\n",
      "Epoch 279/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3976 - binary_accuracy: 0.8166 - val_loss: 0.3894 - val_binary_accuracy: 0.8248\n",
      "Epoch 280/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3961 - binary_accuracy: 0.8175 - val_loss: 0.3893 - val_binary_accuracy: 0.8249\n",
      "Epoch 281/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3974 - binary_accuracy: 0.8172 - val_loss: 0.3891 - val_binary_accuracy: 0.8251\n",
      "Epoch 282/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3975 - binary_accuracy: 0.8174 - val_loss: 0.3890 - val_binary_accuracy: 0.8249\n",
      "Epoch 283/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3963 - binary_accuracy: 0.8168 - val_loss: 0.3889 - val_binary_accuracy: 0.8253\n",
      "Epoch 284/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3981 - binary_accuracy: 0.8176 - val_loss: 0.3888 - val_binary_accuracy: 0.8254\n",
      "Epoch 285/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3950 - binary_accuracy: 0.8183 - val_loss: 0.3887 - val_binary_accuracy: 0.8252\n",
      "Epoch 286/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3965 - binary_accuracy: 0.8177 - val_loss: 0.3886 - val_binary_accuracy: 0.8252\n",
      "Epoch 287/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3969 - binary_accuracy: 0.8195 - val_loss: 0.3885 - val_binary_accuracy: 0.8254\n",
      "Epoch 288/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3967 - binary_accuracy: 0.8181 - val_loss: 0.3884 - val_binary_accuracy: 0.8258\n",
      "Epoch 289/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3957 - binary_accuracy: 0.8176 - val_loss: 0.3883 - val_binary_accuracy: 0.8260\n",
      "Epoch 290/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3962 - binary_accuracy: 0.8171 - val_loss: 0.3883 - val_binary_accuracy: 0.8262\n",
      "Epoch 291/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3968 - binary_accuracy: 0.8169 - val_loss: 0.3882 - val_binary_accuracy: 0.8263\n",
      "Epoch 292/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3957 - binary_accuracy: 0.8172 - val_loss: 0.3882 - val_binary_accuracy: 0.8261\n",
      "Epoch 293/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3957 - binary_accuracy: 0.8181 - val_loss: 0.3881 - val_binary_accuracy: 0.8260\n",
      "Epoch 294/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3948 - binary_accuracy: 0.8172 - val_loss: 0.3880 - val_binary_accuracy: 0.8261\n",
      "Epoch 295/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3951 - binary_accuracy: 0.8182 - val_loss: 0.3879 - val_binary_accuracy: 0.8263\n",
      "Epoch 296/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3956 - binary_accuracy: 0.8170 - val_loss: 0.3878 - val_binary_accuracy: 0.8262\n",
      "Epoch 297/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3963 - binary_accuracy: 0.8161 - val_loss: 0.3877 - val_binary_accuracy: 0.8264\n",
      "Epoch 298/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3950 - binary_accuracy: 0.8181 - val_loss: 0.3877 - val_binary_accuracy: 0.8265\n",
      "Epoch 299/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3940 - binary_accuracy: 0.8178 - val_loss: 0.3876 - val_binary_accuracy: 0.8262\n",
      "Epoch 300/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3962 - binary_accuracy: 0.8174 - val_loss: 0.3875 - val_binary_accuracy: 0.8267\n",
      "Epoch 301/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3955 - binary_accuracy: 0.8160 - val_loss: 0.3874 - val_binary_accuracy: 0.8265\n",
      "Epoch 302/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3947 - binary_accuracy: 0.8190 - val_loss: 0.3873 - val_binary_accuracy: 0.8269\n",
      "Epoch 303/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3962 - binary_accuracy: 0.8183 - val_loss: 0.3871 - val_binary_accuracy: 0.8266\n",
      "Epoch 304/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3947 - binary_accuracy: 0.8170 - val_loss: 0.3870 - val_binary_accuracy: 0.8266\n",
      "Epoch 305/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3951 - binary_accuracy: 0.8189 - val_loss: 0.3869 - val_binary_accuracy: 0.8268\n",
      "Epoch 306/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3940 - binary_accuracy: 0.8190 - val_loss: 0.3868 - val_binary_accuracy: 0.8269\n",
      "Epoch 307/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3935 - binary_accuracy: 0.8180 - val_loss: 0.3867 - val_binary_accuracy: 0.8269\n",
      "Epoch 308/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3927 - binary_accuracy: 0.8207 - val_loss: 0.3866 - val_binary_accuracy: 0.8270\n",
      "Epoch 309/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3919 - binary_accuracy: 0.8188 - val_loss: 0.3865 - val_binary_accuracy: 0.8272\n",
      "Epoch 310/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3945 - binary_accuracy: 0.8184 - val_loss: 0.3864 - val_binary_accuracy: 0.8272\n",
      "Epoch 311/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3940 - binary_accuracy: 0.8185 - val_loss: 0.3864 - val_binary_accuracy: 0.8272\n",
      "Epoch 312/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3935 - binary_accuracy: 0.8200 - val_loss: 0.3863 - val_binary_accuracy: 0.8275\n",
      "Epoch 313/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3947 - binary_accuracy: 0.8182 - val_loss: 0.3862 - val_binary_accuracy: 0.8275\n",
      "Epoch 314/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3936 - binary_accuracy: 0.8192 - val_loss: 0.3861 - val_binary_accuracy: 0.8278\n",
      "Epoch 315/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3924 - binary_accuracy: 0.8193 - val_loss: 0.3860 - val_binary_accuracy: 0.8282\n",
      "Epoch 316/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3941 - binary_accuracy: 0.8195 - val_loss: 0.3860 - val_binary_accuracy: 0.8282\n",
      "Epoch 317/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3917 - binary_accuracy: 0.8204 - val_loss: 0.3859 - val_binary_accuracy: 0.8283\n",
      "Epoch 318/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3929 - binary_accuracy: 0.8179 - val_loss: 0.3857 - val_binary_accuracy: 0.8282\n",
      "Epoch 319/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3930 - binary_accuracy: 0.8208 - val_loss: 0.3856 - val_binary_accuracy: 0.8280\n",
      "Epoch 320/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3910 - binary_accuracy: 0.8197 - val_loss: 0.3855 - val_binary_accuracy: 0.8287\n",
      "Epoch 321/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3929 - binary_accuracy: 0.8183 - val_loss: 0.3854 - val_binary_accuracy: 0.8286\n",
      "Epoch 322/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3913 - binary_accuracy: 0.8189 - val_loss: 0.3854 - val_binary_accuracy: 0.8285\n",
      "Epoch 323/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3926 - binary_accuracy: 0.8183 - val_loss: 0.3853 - val_binary_accuracy: 0.8285\n",
      "Epoch 324/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3912 - binary_accuracy: 0.8202 - val_loss: 0.3852 - val_binary_accuracy: 0.8288\n",
      "Epoch 325/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3914 - binary_accuracy: 0.8192 - val_loss: 0.3852 - val_binary_accuracy: 0.8290\n",
      "Epoch 326/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3907 - binary_accuracy: 0.8210 - val_loss: 0.3851 - val_binary_accuracy: 0.8290\n",
      "Epoch 327/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3916 - binary_accuracy: 0.8203 - val_loss: 0.3850 - val_binary_accuracy: 0.8288\n",
      "Epoch 328/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3913 - binary_accuracy: 0.8208 - val_loss: 0.3849 - val_binary_accuracy: 0.8287\n",
      "Epoch 329/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3912 - binary_accuracy: 0.8203 - val_loss: 0.3848 - val_binary_accuracy: 0.8288\n",
      "Epoch 330/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3903 - binary_accuracy: 0.8198 - val_loss: 0.3847 - val_binary_accuracy: 0.8290\n",
      "Epoch 331/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3897 - binary_accuracy: 0.8211 - val_loss: 0.3846 - val_binary_accuracy: 0.8290\n",
      "Epoch 332/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3918 - binary_accuracy: 0.8199 - val_loss: 0.3845 - val_binary_accuracy: 0.8289\n",
      "Epoch 333/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3909 - binary_accuracy: 0.8210 - val_loss: 0.3845 - val_binary_accuracy: 0.8290\n",
      "Epoch 334/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3910 - binary_accuracy: 0.8220 - val_loss: 0.3844 - val_binary_accuracy: 0.8292\n",
      "Epoch 335/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3906 - binary_accuracy: 0.8208 - val_loss: 0.3843 - val_binary_accuracy: 0.8290\n",
      "Epoch 336/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3919 - binary_accuracy: 0.8197 - val_loss: 0.3843 - val_binary_accuracy: 0.8292\n",
      "Epoch 337/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3890 - binary_accuracy: 0.8220 - val_loss: 0.3842 - val_binary_accuracy: 0.8290\n",
      "Epoch 338/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3911 - binary_accuracy: 0.8203 - val_loss: 0.3841 - val_binary_accuracy: 0.8291\n",
      "Epoch 339/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3907 - binary_accuracy: 0.8225 - val_loss: 0.3839 - val_binary_accuracy: 0.8288\n",
      "Epoch 340/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3905 - binary_accuracy: 0.8207 - val_loss: 0.3839 - val_binary_accuracy: 0.8288\n",
      "Epoch 341/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3918 - binary_accuracy: 0.8199 - val_loss: 0.3839 - val_binary_accuracy: 0.8288\n",
      "Epoch 342/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3901 - binary_accuracy: 0.8206 - val_loss: 0.3839 - val_binary_accuracy: 0.8288\n",
      "Epoch 343/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3890 - binary_accuracy: 0.8215 - val_loss: 0.3837 - val_binary_accuracy: 0.8287\n",
      "Epoch 344/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3897 - binary_accuracy: 0.8228 - val_loss: 0.3835 - val_binary_accuracy: 0.8287\n",
      "Epoch 345/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3890 - binary_accuracy: 0.8216 - val_loss: 0.3834 - val_binary_accuracy: 0.8288\n",
      "Epoch 346/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3900 - binary_accuracy: 0.8201 - val_loss: 0.3833 - val_binary_accuracy: 0.8288\n",
      "Epoch 347/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3889 - binary_accuracy: 0.8232 - val_loss: 0.3833 - val_binary_accuracy: 0.8288\n",
      "Epoch 348/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3884 - binary_accuracy: 0.8207 - val_loss: 0.3832 - val_binary_accuracy: 0.8288\n",
      "Epoch 349/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3878 - binary_accuracy: 0.8216 - val_loss: 0.3830 - val_binary_accuracy: 0.8284\n",
      "Epoch 350/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3880 - binary_accuracy: 0.8213 - val_loss: 0.3829 - val_binary_accuracy: 0.8286\n",
      "Epoch 351/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3886 - binary_accuracy: 0.8215 - val_loss: 0.3829 - val_binary_accuracy: 0.8287\n",
      "Epoch 352/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3880 - binary_accuracy: 0.8212 - val_loss: 0.3828 - val_binary_accuracy: 0.8286\n",
      "Epoch 353/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3881 - binary_accuracy: 0.8225 - val_loss: 0.3827 - val_binary_accuracy: 0.8287\n",
      "Epoch 354/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3893 - binary_accuracy: 0.8215 - val_loss: 0.3827 - val_binary_accuracy: 0.8288\n",
      "Epoch 355/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3879 - binary_accuracy: 0.8225 - val_loss: 0.3826 - val_binary_accuracy: 0.8289\n",
      "Epoch 356/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3871 - binary_accuracy: 0.8226 - val_loss: 0.3824 - val_binary_accuracy: 0.8288\n",
      "Epoch 357/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3882 - binary_accuracy: 0.8226 - val_loss: 0.3823 - val_binary_accuracy: 0.8288\n",
      "Epoch 358/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3876 - binary_accuracy: 0.8219 - val_loss: 0.3822 - val_binary_accuracy: 0.8288\n",
      "Epoch 359/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3880 - binary_accuracy: 0.8221 - val_loss: 0.3821 - val_binary_accuracy: 0.8288\n",
      "Epoch 360/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3886 - binary_accuracy: 0.8229 - val_loss: 0.3821 - val_binary_accuracy: 0.8289\n",
      "Epoch 361/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3877 - binary_accuracy: 0.8223 - val_loss: 0.3820 - val_binary_accuracy: 0.8288\n",
      "Epoch 362/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3862 - binary_accuracy: 0.8222 - val_loss: 0.3819 - val_binary_accuracy: 0.8289\n",
      "Epoch 363/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3884 - binary_accuracy: 0.8228 - val_loss: 0.3818 - val_binary_accuracy: 0.8290\n",
      "Epoch 364/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3855 - binary_accuracy: 0.8232 - val_loss: 0.3817 - val_binary_accuracy: 0.8290\n",
      "Epoch 365/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3872 - binary_accuracy: 0.8221 - val_loss: 0.3817 - val_binary_accuracy: 0.8294\n",
      "Epoch 366/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3880 - binary_accuracy: 0.8230 - val_loss: 0.3816 - val_binary_accuracy: 0.8296\n",
      "Epoch 367/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3862 - binary_accuracy: 0.8225 - val_loss: 0.3816 - val_binary_accuracy: 0.8296\n",
      "Epoch 368/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3867 - binary_accuracy: 0.8242 - val_loss: 0.3815 - val_binary_accuracy: 0.8293\n",
      "Epoch 369/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3872 - binary_accuracy: 0.8223 - val_loss: 0.3814 - val_binary_accuracy: 0.8294\n",
      "Epoch 370/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3866 - binary_accuracy: 0.8232 - val_loss: 0.3813 - val_binary_accuracy: 0.8294\n",
      "Epoch 371/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3878 - binary_accuracy: 0.8225 - val_loss: 0.3812 - val_binary_accuracy: 0.8297\n",
      "Epoch 372/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3880 - binary_accuracy: 0.8235 - val_loss: 0.3811 - val_binary_accuracy: 0.8297\n",
      "Epoch 373/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3869 - binary_accuracy: 0.8234 - val_loss: 0.3811 - val_binary_accuracy: 0.8300\n",
      "Epoch 374/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3869 - binary_accuracy: 0.8229 - val_loss: 0.3810 - val_binary_accuracy: 0.8298\n",
      "Epoch 375/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3852 - binary_accuracy: 0.8236 - val_loss: 0.3808 - val_binary_accuracy: 0.8299\n",
      "Epoch 376/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3857 - binary_accuracy: 0.8237 - val_loss: 0.3808 - val_binary_accuracy: 0.8299\n",
      "Epoch 377/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3860 - binary_accuracy: 0.8238 - val_loss: 0.3807 - val_binary_accuracy: 0.8301\n",
      "Epoch 378/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3862 - binary_accuracy: 0.8233 - val_loss: 0.3805 - val_binary_accuracy: 0.8302\n",
      "Epoch 379/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3862 - binary_accuracy: 0.8233 - val_loss: 0.3805 - val_binary_accuracy: 0.8305\n",
      "Epoch 380/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3861 - binary_accuracy: 0.8230 - val_loss: 0.3804 - val_binary_accuracy: 0.8307\n",
      "Epoch 381/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3846 - binary_accuracy: 0.8235 - val_loss: 0.3803 - val_binary_accuracy: 0.8310\n",
      "Epoch 382/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3858 - binary_accuracy: 0.8223 - val_loss: 0.3802 - val_binary_accuracy: 0.8311\n",
      "Epoch 383/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3860 - binary_accuracy: 0.8235 - val_loss: 0.3801 - val_binary_accuracy: 0.8313\n",
      "Epoch 384/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3860 - binary_accuracy: 0.8233 - val_loss: 0.3801 - val_binary_accuracy: 0.8308\n",
      "Epoch 385/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3857 - binary_accuracy: 0.8232 - val_loss: 0.3801 - val_binary_accuracy: 0.8307\n",
      "Epoch 386/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3857 - binary_accuracy: 0.8236 - val_loss: 0.3799 - val_binary_accuracy: 0.8308\n",
      "Epoch 387/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3846 - binary_accuracy: 0.8241 - val_loss: 0.3798 - val_binary_accuracy: 0.8307\n",
      "Epoch 388/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3830 - binary_accuracy: 0.8238 - val_loss: 0.3797 - val_binary_accuracy: 0.8308\n",
      "Epoch 389/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3843 - binary_accuracy: 0.8238 - val_loss: 0.3796 - val_binary_accuracy: 0.8308\n",
      "Epoch 390/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3838 - binary_accuracy: 0.8244 - val_loss: 0.3794 - val_binary_accuracy: 0.8309\n",
      "Epoch 391/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3844 - binary_accuracy: 0.8235 - val_loss: 0.3793 - val_binary_accuracy: 0.8310\n",
      "Epoch 392/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3832 - binary_accuracy: 0.8255 - val_loss: 0.3793 - val_binary_accuracy: 0.8308\n",
      "Epoch 393/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3859 - binary_accuracy: 0.8243 - val_loss: 0.3792 - val_binary_accuracy: 0.8306\n",
      "Epoch 394/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3845 - binary_accuracy: 0.8252 - val_loss: 0.3791 - val_binary_accuracy: 0.8307\n",
      "Epoch 395/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3821 - binary_accuracy: 0.8250 - val_loss: 0.3791 - val_binary_accuracy: 0.8308\n",
      "Epoch 396/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3841 - binary_accuracy: 0.8245 - val_loss: 0.3790 - val_binary_accuracy: 0.8311\n",
      "Epoch 397/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3832 - binary_accuracy: 0.8256 - val_loss: 0.3789 - val_binary_accuracy: 0.8313\n",
      "Epoch 398/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3838 - binary_accuracy: 0.8248 - val_loss: 0.3788 - val_binary_accuracy: 0.8313\n",
      "Epoch 399/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3845 - binary_accuracy: 0.8237 - val_loss: 0.3787 - val_binary_accuracy: 0.8315\n",
      "Epoch 400/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3830 - binary_accuracy: 0.8255 - val_loss: 0.3786 - val_binary_accuracy: 0.8315\n",
      "Epoch 401/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3825 - binary_accuracy: 0.8243 - val_loss: 0.3785 - val_binary_accuracy: 0.8318\n",
      "Epoch 402/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3840 - binary_accuracy: 0.8249 - val_loss: 0.3783 - val_binary_accuracy: 0.8317\n",
      "Epoch 403/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3822 - binary_accuracy: 0.8254 - val_loss: 0.3783 - val_binary_accuracy: 0.8317\n",
      "Epoch 404/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3820 - binary_accuracy: 0.8246 - val_loss: 0.3783 - val_binary_accuracy: 0.8316\n",
      "Epoch 405/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3833 - binary_accuracy: 0.8259 - val_loss: 0.3782 - val_binary_accuracy: 0.8316\n",
      "Epoch 406/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3828 - binary_accuracy: 0.8240 - val_loss: 0.3782 - val_binary_accuracy: 0.8315\n",
      "Epoch 407/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3828 - binary_accuracy: 0.8256 - val_loss: 0.3781 - val_binary_accuracy: 0.8315\n",
      "Epoch 408/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3824 - binary_accuracy: 0.8253 - val_loss: 0.3780 - val_binary_accuracy: 0.8313\n",
      "Epoch 409/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3816 - binary_accuracy: 0.8252 - val_loss: 0.3779 - val_binary_accuracy: 0.8313\n",
      "Epoch 410/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3812 - binary_accuracy: 0.8284 - val_loss: 0.3777 - val_binary_accuracy: 0.8315\n",
      "Epoch 411/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3816 - binary_accuracy: 0.8276 - val_loss: 0.3777 - val_binary_accuracy: 0.8318\n",
      "Epoch 412/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3827 - binary_accuracy: 0.8265 - val_loss: 0.3776 - val_binary_accuracy: 0.8317\n",
      "Epoch 413/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3823 - binary_accuracy: 0.8250 - val_loss: 0.3776 - val_binary_accuracy: 0.8318\n",
      "Epoch 414/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3810 - binary_accuracy: 0.8274 - val_loss: 0.3775 - val_binary_accuracy: 0.8319\n",
      "Epoch 415/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3821 - binary_accuracy: 0.8254 - val_loss: 0.3775 - val_binary_accuracy: 0.8318\n",
      "Epoch 416/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3805 - binary_accuracy: 0.8273 - val_loss: 0.3774 - val_binary_accuracy: 0.8317\n",
      "Epoch 417/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.3820 - binary_accuracy: 0.8257 - val_loss: 0.3773 - val_binary_accuracy: 0.8318\n",
      "Epoch 418/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3805 - binary_accuracy: 0.8258 - val_loss: 0.3771 - val_binary_accuracy: 0.8322\n",
      "Epoch 419/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3832 - binary_accuracy: 0.8254 - val_loss: 0.3770 - val_binary_accuracy: 0.8325\n",
      "Epoch 420/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3805 - binary_accuracy: 0.8261 - val_loss: 0.3770 - val_binary_accuracy: 0.8322\n",
      "Epoch 421/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3806 - binary_accuracy: 0.8267 - val_loss: 0.3768 - val_binary_accuracy: 0.8321\n",
      "Epoch 422/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3816 - binary_accuracy: 0.8256 - val_loss: 0.3768 - val_binary_accuracy: 0.8321\n",
      "Epoch 423/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3810 - binary_accuracy: 0.8265 - val_loss: 0.3767 - val_binary_accuracy: 0.8324\n",
      "Epoch 424/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3804 - binary_accuracy: 0.8263 - val_loss: 0.3767 - val_binary_accuracy: 0.8324\n",
      "Epoch 425/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3833 - binary_accuracy: 0.8256 - val_loss: 0.3768 - val_binary_accuracy: 0.8322\n",
      "Epoch 426/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3822 - binary_accuracy: 0.8251 - val_loss: 0.3767 - val_binary_accuracy: 0.8325\n",
      "Epoch 427/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3799 - binary_accuracy: 0.8278 - val_loss: 0.3766 - val_binary_accuracy: 0.8327\n",
      "Epoch 428/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3796 - binary_accuracy: 0.8268 - val_loss: 0.3765 - val_binary_accuracy: 0.8327\n",
      "Epoch 429/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3819 - binary_accuracy: 0.8261 - val_loss: 0.3764 - val_binary_accuracy: 0.8329\n",
      "Epoch 430/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3792 - binary_accuracy: 0.8284 - val_loss: 0.3762 - val_binary_accuracy: 0.8328\n",
      "Epoch 431/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3802 - binary_accuracy: 0.8263 - val_loss: 0.3761 - val_binary_accuracy: 0.8329\n",
      "Epoch 432/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3811 - binary_accuracy: 0.8272 - val_loss: 0.3760 - val_binary_accuracy: 0.8333\n",
      "Epoch 433/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3799 - binary_accuracy: 0.8278 - val_loss: 0.3759 - val_binary_accuracy: 0.8335\n",
      "Epoch 434/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3801 - binary_accuracy: 0.8269 - val_loss: 0.3759 - val_binary_accuracy: 0.8334\n",
      "Epoch 435/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3809 - binary_accuracy: 0.8262 - val_loss: 0.3758 - val_binary_accuracy: 0.8334\n",
      "Epoch 436/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3798 - binary_accuracy: 0.8269 - val_loss: 0.3757 - val_binary_accuracy: 0.8332\n",
      "Epoch 437/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3795 - binary_accuracy: 0.8264 - val_loss: 0.3756 - val_binary_accuracy: 0.8328\n",
      "Epoch 438/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3800 - binary_accuracy: 0.8274 - val_loss: 0.3755 - val_binary_accuracy: 0.8331\n",
      "Epoch 439/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3786 - binary_accuracy: 0.8278 - val_loss: 0.3753 - val_binary_accuracy: 0.8334\n",
      "Epoch 440/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3774 - binary_accuracy: 0.8270 - val_loss: 0.3752 - val_binary_accuracy: 0.8333\n",
      "Epoch 441/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3787 - binary_accuracy: 0.8279 - val_loss: 0.3750 - val_binary_accuracy: 0.8335\n",
      "Epoch 442/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3794 - binary_accuracy: 0.8278 - val_loss: 0.3749 - val_binary_accuracy: 0.8334\n",
      "Epoch 443/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3789 - binary_accuracy: 0.8278 - val_loss: 0.3749 - val_binary_accuracy: 0.8334\n",
      "Epoch 444/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3801 - binary_accuracy: 0.8281 - val_loss: 0.3748 - val_binary_accuracy: 0.8337\n",
      "Epoch 445/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3780 - binary_accuracy: 0.8276 - val_loss: 0.3748 - val_binary_accuracy: 0.8334\n",
      "Epoch 446/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3803 - binary_accuracy: 0.8281 - val_loss: 0.3747 - val_binary_accuracy: 0.8335\n",
      "Epoch 447/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3772 - binary_accuracy: 0.8277 - val_loss: 0.3747 - val_binary_accuracy: 0.8337\n",
      "Epoch 448/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3777 - binary_accuracy: 0.8287 - val_loss: 0.3746 - val_binary_accuracy: 0.8335\n",
      "Epoch 449/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3786 - binary_accuracy: 0.8274 - val_loss: 0.3745 - val_binary_accuracy: 0.8335\n",
      "Epoch 450/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3786 - binary_accuracy: 0.8284 - val_loss: 0.3743 - val_binary_accuracy: 0.8336\n",
      "Epoch 451/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3774 - binary_accuracy: 0.8269 - val_loss: 0.3743 - val_binary_accuracy: 0.8341\n",
      "Epoch 452/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3785 - binary_accuracy: 0.8281 - val_loss: 0.3742 - val_binary_accuracy: 0.8346\n",
      "Epoch 453/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3795 - binary_accuracy: 0.8283 - val_loss: 0.3741 - val_binary_accuracy: 0.8344\n",
      "Epoch 454/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3775 - binary_accuracy: 0.8282 - val_loss: 0.3740 - val_binary_accuracy: 0.8340\n",
      "Epoch 455/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3776 - binary_accuracy: 0.8290 - val_loss: 0.3740 - val_binary_accuracy: 0.8340\n",
      "Epoch 456/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3783 - binary_accuracy: 0.8291 - val_loss: 0.3739 - val_binary_accuracy: 0.8341\n",
      "Epoch 457/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3771 - binary_accuracy: 0.8281 - val_loss: 0.3739 - val_binary_accuracy: 0.8337\n",
      "Epoch 458/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3757 - binary_accuracy: 0.8293 - val_loss: 0.3738 - val_binary_accuracy: 0.8335\n",
      "Epoch 459/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3766 - binary_accuracy: 0.8278 - val_loss: 0.3737 - val_binary_accuracy: 0.8337\n",
      "Epoch 460/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3757 - binary_accuracy: 0.8284 - val_loss: 0.3735 - val_binary_accuracy: 0.8342\n",
      "Epoch 461/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3775 - binary_accuracy: 0.8288 - val_loss: 0.3734 - val_binary_accuracy: 0.8342\n",
      "Epoch 462/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3763 - binary_accuracy: 0.8288 - val_loss: 0.3733 - val_binary_accuracy: 0.8344\n",
      "Epoch 463/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3774 - binary_accuracy: 0.8277 - val_loss: 0.3732 - val_binary_accuracy: 0.8347\n",
      "Epoch 464/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3767 - binary_accuracy: 0.8285 - val_loss: 0.3731 - val_binary_accuracy: 0.8345\n",
      "Epoch 465/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3767 - binary_accuracy: 0.8288 - val_loss: 0.3731 - val_binary_accuracy: 0.8344\n",
      "Epoch 466/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3762 - binary_accuracy: 0.8282 - val_loss: 0.3731 - val_binary_accuracy: 0.8346\n",
      "Epoch 467/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3764 - binary_accuracy: 0.8291 - val_loss: 0.3730 - val_binary_accuracy: 0.8345\n",
      "Epoch 468/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3769 - binary_accuracy: 0.8291 - val_loss: 0.3729 - val_binary_accuracy: 0.8344\n",
      "Epoch 469/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3772 - binary_accuracy: 0.8282 - val_loss: 0.3730 - val_binary_accuracy: 0.8347\n",
      "Epoch 470/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3752 - binary_accuracy: 0.8300 - val_loss: 0.3728 - val_binary_accuracy: 0.8343\n",
      "Epoch 471/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3746 - binary_accuracy: 0.8292 - val_loss: 0.3727 - val_binary_accuracy: 0.8345\n",
      "Epoch 472/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3754 - binary_accuracy: 0.8295 - val_loss: 0.3725 - val_binary_accuracy: 0.8347\n",
      "Epoch 473/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3753 - binary_accuracy: 0.8303 - val_loss: 0.3724 - val_binary_accuracy: 0.8350\n",
      "Epoch 474/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3759 - binary_accuracy: 0.8284 - val_loss: 0.3723 - val_binary_accuracy: 0.8357\n",
      "Epoch 475/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3757 - binary_accuracy: 0.8291 - val_loss: 0.3722 - val_binary_accuracy: 0.8352\n",
      "Epoch 476/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3751 - binary_accuracy: 0.8297 - val_loss: 0.3721 - val_binary_accuracy: 0.8356\n",
      "Epoch 477/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3762 - binary_accuracy: 0.8289 - val_loss: 0.3721 - val_binary_accuracy: 0.8358\n",
      "Epoch 478/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3752 - binary_accuracy: 0.8306 - val_loss: 0.3721 - val_binary_accuracy: 0.8354\n",
      "Epoch 479/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3746 - binary_accuracy: 0.8304 - val_loss: 0.3720 - val_binary_accuracy: 0.8357\n",
      "Epoch 480/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3749 - binary_accuracy: 0.8288 - val_loss: 0.3720 - val_binary_accuracy: 0.8356\n",
      "Epoch 481/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3755 - binary_accuracy: 0.8296 - val_loss: 0.3719 - val_binary_accuracy: 0.8358\n",
      "Epoch 482/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3760 - binary_accuracy: 0.8295 - val_loss: 0.3718 - val_binary_accuracy: 0.8359\n",
      "Epoch 483/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3752 - binary_accuracy: 0.8304 - val_loss: 0.3718 - val_binary_accuracy: 0.8357\n",
      "Epoch 484/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3745 - binary_accuracy: 0.8294 - val_loss: 0.3717 - val_binary_accuracy: 0.8358\n",
      "Epoch 485/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3750 - binary_accuracy: 0.8299 - val_loss: 0.3716 - val_binary_accuracy: 0.8354\n",
      "Epoch 486/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3748 - binary_accuracy: 0.8298 - val_loss: 0.3716 - val_binary_accuracy: 0.8352\n",
      "Epoch 487/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3742 - binary_accuracy: 0.8294 - val_loss: 0.3715 - val_binary_accuracy: 0.8354\n",
      "Epoch 488/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3743 - binary_accuracy: 0.8292 - val_loss: 0.3714 - val_binary_accuracy: 0.8352\n",
      "Epoch 489/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3735 - binary_accuracy: 0.8298 - val_loss: 0.3713 - val_binary_accuracy: 0.8358\n",
      "Epoch 490/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3734 - binary_accuracy: 0.8291 - val_loss: 0.3713 - val_binary_accuracy: 0.8360\n",
      "Epoch 491/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3751 - binary_accuracy: 0.8297 - val_loss: 0.3712 - val_binary_accuracy: 0.8359\n",
      "Epoch 492/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3748 - binary_accuracy: 0.8304 - val_loss: 0.3711 - val_binary_accuracy: 0.8358\n",
      "Epoch 493/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3742 - binary_accuracy: 0.8309 - val_loss: 0.3710 - val_binary_accuracy: 0.8357\n",
      "Epoch 494/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3749 - binary_accuracy: 0.8303 - val_loss: 0.3709 - val_binary_accuracy: 0.8360\n",
      "Epoch 495/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3734 - binary_accuracy: 0.8298 - val_loss: 0.3709 - val_binary_accuracy: 0.8361\n",
      "Epoch 496/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3732 - binary_accuracy: 0.8316 - val_loss: 0.3707 - val_binary_accuracy: 0.8363\n",
      "Epoch 497/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3728 - binary_accuracy: 0.8302 - val_loss: 0.3706 - val_binary_accuracy: 0.8361\n",
      "Epoch 498/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3723 - binary_accuracy: 0.8309 - val_loss: 0.3705 - val_binary_accuracy: 0.8361\n",
      "Epoch 499/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3724 - binary_accuracy: 0.8307 - val_loss: 0.3704 - val_binary_accuracy: 0.8361\n",
      "Epoch 500/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3718 - binary_accuracy: 0.8316 - val_loss: 0.3703 - val_binary_accuracy: 0.8361\n",
      "Epoch 501/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3717 - binary_accuracy: 0.8308 - val_loss: 0.3701 - val_binary_accuracy: 0.8363\n",
      "Epoch 502/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3724 - binary_accuracy: 0.8321 - val_loss: 0.3701 - val_binary_accuracy: 0.8361\n",
      "Epoch 503/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3722 - binary_accuracy: 0.8311 - val_loss: 0.3700 - val_binary_accuracy: 0.8366\n",
      "Epoch 504/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3719 - binary_accuracy: 0.8318 - val_loss: 0.3699 - val_binary_accuracy: 0.8363\n",
      "Epoch 505/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3728 - binary_accuracy: 0.8310 - val_loss: 0.3700 - val_binary_accuracy: 0.8358\n",
      "Epoch 506/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3728 - binary_accuracy: 0.8313 - val_loss: 0.3700 - val_binary_accuracy: 0.8358\n",
      "Epoch 507/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3715 - binary_accuracy: 0.8320 - val_loss: 0.3699 - val_binary_accuracy: 0.8362\n",
      "Epoch 508/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3719 - binary_accuracy: 0.8320 - val_loss: 0.3698 - val_binary_accuracy: 0.8364\n",
      "Epoch 509/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3713 - binary_accuracy: 0.8329 - val_loss: 0.3696 - val_binary_accuracy: 0.8371\n",
      "Epoch 510/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3721 - binary_accuracy: 0.8322 - val_loss: 0.3694 - val_binary_accuracy: 0.8369\n",
      "Epoch 511/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3719 - binary_accuracy: 0.8319 - val_loss: 0.3694 - val_binary_accuracy: 0.8366\n",
      "Epoch 512/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3710 - binary_accuracy: 0.8325 - val_loss: 0.3693 - val_binary_accuracy: 0.8363\n",
      "Epoch 513/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.3719 - binary_accuracy: 0.8315 - val_loss: 0.3692 - val_binary_accuracy: 0.8364\n",
      "Epoch 514/800\n",
      "48000/48000 [==============================] - 0s 3us/step - loss: 0.3704 - binary_accuracy: 0.8327 - val_loss: 0.3692 - val_binary_accuracy: 0.8368\n",
      "Epoch 515/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3711 - binary_accuracy: 0.8327 - val_loss: 0.3690 - val_binary_accuracy: 0.8368\n",
      "Epoch 516/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3712 - binary_accuracy: 0.8324 - val_loss: 0.3689 - val_binary_accuracy: 0.8368\n",
      "Epoch 517/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3714 - binary_accuracy: 0.8324 - val_loss: 0.3689 - val_binary_accuracy: 0.8369\n",
      "Epoch 518/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3719 - binary_accuracy: 0.8319 - val_loss: 0.3688 - val_binary_accuracy: 0.8370\n",
      "Epoch 519/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3722 - binary_accuracy: 0.8314 - val_loss: 0.3688 - val_binary_accuracy: 0.8373\n",
      "Epoch 520/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3691 - binary_accuracy: 0.8337 - val_loss: 0.3687 - val_binary_accuracy: 0.8372\n",
      "Epoch 521/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3713 - binary_accuracy: 0.8338 - val_loss: 0.3686 - val_binary_accuracy: 0.8371\n",
      "Epoch 522/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3700 - binary_accuracy: 0.8333 - val_loss: 0.3685 - val_binary_accuracy: 0.8367\n",
      "Epoch 523/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3707 - binary_accuracy: 0.8323 - val_loss: 0.3684 - val_binary_accuracy: 0.8369\n",
      "Epoch 524/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3702 - binary_accuracy: 0.8311 - val_loss: 0.3683 - val_binary_accuracy: 0.8368\n",
      "Epoch 525/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3699 - binary_accuracy: 0.8315 - val_loss: 0.3682 - val_binary_accuracy: 0.8367\n",
      "Epoch 526/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3690 - binary_accuracy: 0.8336 - val_loss: 0.3680 - val_binary_accuracy: 0.8371\n",
      "Epoch 527/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3706 - binary_accuracy: 0.8325 - val_loss: 0.3680 - val_binary_accuracy: 0.8370\n",
      "Epoch 528/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3692 - binary_accuracy: 0.8328 - val_loss: 0.3679 - val_binary_accuracy: 0.8376\n",
      "Epoch 529/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3697 - binary_accuracy: 0.8321 - val_loss: 0.3679 - val_binary_accuracy: 0.8371\n",
      "Epoch 530/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3698 - binary_accuracy: 0.8328 - val_loss: 0.3678 - val_binary_accuracy: 0.8377\n",
      "Epoch 531/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3702 - binary_accuracy: 0.8322 - val_loss: 0.3677 - val_binary_accuracy: 0.8377\n",
      "Epoch 532/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3695 - binary_accuracy: 0.8327 - val_loss: 0.3675 - val_binary_accuracy: 0.8377\n",
      "Epoch 533/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3701 - binary_accuracy: 0.8333 - val_loss: 0.3674 - val_binary_accuracy: 0.8382\n",
      "Epoch 534/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3695 - binary_accuracy: 0.8331 - val_loss: 0.3673 - val_binary_accuracy: 0.8381\n",
      "Epoch 535/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3696 - binary_accuracy: 0.8336 - val_loss: 0.3672 - val_binary_accuracy: 0.8380\n",
      "Epoch 536/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3677 - binary_accuracy: 0.8345 - val_loss: 0.3672 - val_binary_accuracy: 0.8375\n",
      "Epoch 537/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3698 - binary_accuracy: 0.8340 - val_loss: 0.3672 - val_binary_accuracy: 0.8377\n",
      "Epoch 538/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3683 - binary_accuracy: 0.8336 - val_loss: 0.3672 - val_binary_accuracy: 0.8377\n",
      "Epoch 539/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3695 - binary_accuracy: 0.8341 - val_loss: 0.3671 - val_binary_accuracy: 0.8381\n",
      "Epoch 540/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3699 - binary_accuracy: 0.8329 - val_loss: 0.3670 - val_binary_accuracy: 0.8380\n",
      "Epoch 541/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3686 - binary_accuracy: 0.8331 - val_loss: 0.3669 - val_binary_accuracy: 0.8382\n",
      "Epoch 542/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3679 - binary_accuracy: 0.8337 - val_loss: 0.3667 - val_binary_accuracy: 0.8379\n",
      "Epoch 543/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3690 - binary_accuracy: 0.8343 - val_loss: 0.3666 - val_binary_accuracy: 0.8381\n",
      "Epoch 544/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3683 - binary_accuracy: 0.8338 - val_loss: 0.3665 - val_binary_accuracy: 0.8382\n",
      "Epoch 545/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3683 - binary_accuracy: 0.8342 - val_loss: 0.3665 - val_binary_accuracy: 0.8380\n",
      "Epoch 546/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3685 - binary_accuracy: 0.8334 - val_loss: 0.3664 - val_binary_accuracy: 0.8379\n",
      "Epoch 547/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3676 - binary_accuracy: 0.8341 - val_loss: 0.3663 - val_binary_accuracy: 0.8380\n",
      "Epoch 548/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3695 - binary_accuracy: 0.8339 - val_loss: 0.3662 - val_binary_accuracy: 0.8382\n",
      "Epoch 549/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3681 - binary_accuracy: 0.8342 - val_loss: 0.3661 - val_binary_accuracy: 0.8385\n",
      "Epoch 550/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3665 - binary_accuracy: 0.8352 - val_loss: 0.3660 - val_binary_accuracy: 0.8386\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3674 - binary_accuracy: 0.8346 - val_loss: 0.3658 - val_binary_accuracy: 0.8387\n",
      "Epoch 552/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3658 - binary_accuracy: 0.8357 - val_loss: 0.3657 - val_binary_accuracy: 0.8384\n",
      "Epoch 553/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3675 - binary_accuracy: 0.8350 - val_loss: 0.3656 - val_binary_accuracy: 0.8392\n",
      "Epoch 554/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3666 - binary_accuracy: 0.8345 - val_loss: 0.3656 - val_binary_accuracy: 0.8392\n",
      "Epoch 555/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3665 - binary_accuracy: 0.8342 - val_loss: 0.3656 - val_binary_accuracy: 0.8389\n",
      "Epoch 556/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3662 - binary_accuracy: 0.8343 - val_loss: 0.3655 - val_binary_accuracy: 0.8387\n",
      "Epoch 557/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3667 - binary_accuracy: 0.8348 - val_loss: 0.3653 - val_binary_accuracy: 0.8386\n",
      "Epoch 558/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3686 - binary_accuracy: 0.8341 - val_loss: 0.3652 - val_binary_accuracy: 0.8386\n",
      "Epoch 559/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3676 - binary_accuracy: 0.8339 - val_loss: 0.3652 - val_binary_accuracy: 0.8386\n",
      "Epoch 560/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3667 - binary_accuracy: 0.8352 - val_loss: 0.3652 - val_binary_accuracy: 0.8388\n",
      "Epoch 561/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3665 - binary_accuracy: 0.8352 - val_loss: 0.3652 - val_binary_accuracy: 0.8392\n",
      "Epoch 562/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3680 - binary_accuracy: 0.8342 - val_loss: 0.3651 - val_binary_accuracy: 0.8394\n",
      "Epoch 563/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3661 - binary_accuracy: 0.8348 - val_loss: 0.3650 - val_binary_accuracy: 0.8392\n",
      "Epoch 564/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3664 - binary_accuracy: 0.8345 - val_loss: 0.3649 - val_binary_accuracy: 0.8397\n",
      "Epoch 565/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3660 - binary_accuracy: 0.8349 - val_loss: 0.3647 - val_binary_accuracy: 0.8397\n",
      "Epoch 566/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3656 - binary_accuracy: 0.8356 - val_loss: 0.3646 - val_binary_accuracy: 0.8396\n",
      "Epoch 567/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3662 - binary_accuracy: 0.8356 - val_loss: 0.3645 - val_binary_accuracy: 0.8397\n",
      "Epoch 568/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3646 - binary_accuracy: 0.8365 - val_loss: 0.3644 - val_binary_accuracy: 0.8401\n",
      "Epoch 569/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3647 - binary_accuracy: 0.8357 - val_loss: 0.3643 - val_binary_accuracy: 0.8400\n",
      "Epoch 570/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3650 - binary_accuracy: 0.8360 - val_loss: 0.3642 - val_binary_accuracy: 0.8402\n",
      "Epoch 571/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3653 - binary_accuracy: 0.8344 - val_loss: 0.3641 - val_binary_accuracy: 0.8402\n",
      "Epoch 572/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3654 - binary_accuracy: 0.8363 - val_loss: 0.3640 - val_binary_accuracy: 0.8400\n",
      "Epoch 573/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3666 - binary_accuracy: 0.8351 - val_loss: 0.3639 - val_binary_accuracy: 0.8402\n",
      "Epoch 574/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3653 - binary_accuracy: 0.8357 - val_loss: 0.3639 - val_binary_accuracy: 0.8401\n",
      "Epoch 575/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3649 - binary_accuracy: 0.8368 - val_loss: 0.3639 - val_binary_accuracy: 0.8399\n",
      "Epoch 576/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3653 - binary_accuracy: 0.8357 - val_loss: 0.3638 - val_binary_accuracy: 0.8398\n",
      "Epoch 577/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3657 - binary_accuracy: 0.8374 - val_loss: 0.3638 - val_binary_accuracy: 0.8401\n",
      "Epoch 578/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3650 - binary_accuracy: 0.8357 - val_loss: 0.3637 - val_binary_accuracy: 0.8398\n",
      "Epoch 579/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3648 - binary_accuracy: 0.8354 - val_loss: 0.3636 - val_binary_accuracy: 0.8402\n",
      "Epoch 580/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3651 - binary_accuracy: 0.8363 - val_loss: 0.3634 - val_binary_accuracy: 0.8397\n",
      "Epoch 581/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3645 - binary_accuracy: 0.8356 - val_loss: 0.3633 - val_binary_accuracy: 0.8402\n",
      "Epoch 582/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3649 - binary_accuracy: 0.8359 - val_loss: 0.3633 - val_binary_accuracy: 0.8405\n",
      "Epoch 583/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3630 - binary_accuracy: 0.8371 - val_loss: 0.3632 - val_binary_accuracy: 0.8402\n",
      "Epoch 584/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3645 - binary_accuracy: 0.8367 - val_loss: 0.3631 - val_binary_accuracy: 0.8404\n",
      "Epoch 585/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3635 - binary_accuracy: 0.8377 - val_loss: 0.3630 - val_binary_accuracy: 0.8402\n",
      "Epoch 586/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3643 - binary_accuracy: 0.8359 - val_loss: 0.3629 - val_binary_accuracy: 0.8403\n",
      "Epoch 587/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3632 - binary_accuracy: 0.8365 - val_loss: 0.3628 - val_binary_accuracy: 0.8402\n",
      "Epoch 588/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3646 - binary_accuracy: 0.8364 - val_loss: 0.3627 - val_binary_accuracy: 0.8405\n",
      "Epoch 589/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3647 - binary_accuracy: 0.8367 - val_loss: 0.3627 - val_binary_accuracy: 0.8407\n",
      "Epoch 590/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3645 - binary_accuracy: 0.8368 - val_loss: 0.3626 - val_binary_accuracy: 0.8405\n",
      "Epoch 591/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3640 - binary_accuracy: 0.8366 - val_loss: 0.3625 - val_binary_accuracy: 0.8406\n",
      "Epoch 592/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3633 - binary_accuracy: 0.8366 - val_loss: 0.3624 - val_binary_accuracy: 0.8407\n",
      "Epoch 593/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3616 - binary_accuracy: 0.8374 - val_loss: 0.3623 - val_binary_accuracy: 0.8404\n",
      "Epoch 594/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3643 - binary_accuracy: 0.8373 - val_loss: 0.3622 - val_binary_accuracy: 0.8406\n",
      "Epoch 595/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3627 - binary_accuracy: 0.8384 - val_loss: 0.3622 - val_binary_accuracy: 0.8403\n",
      "Epoch 596/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3623 - binary_accuracy: 0.8360 - val_loss: 0.3621 - val_binary_accuracy: 0.8404\n",
      "Epoch 597/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3615 - binary_accuracy: 0.8369 - val_loss: 0.3620 - val_binary_accuracy: 0.8403\n",
      "Epoch 598/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3631 - binary_accuracy: 0.8367 - val_loss: 0.3619 - val_binary_accuracy: 0.8404\n",
      "Epoch 599/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3638 - binary_accuracy: 0.8359 - val_loss: 0.3619 - val_binary_accuracy: 0.8403\n",
      "Epoch 600/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3638 - binary_accuracy: 0.8373 - val_loss: 0.3618 - val_binary_accuracy: 0.8406\n",
      "Epoch 601/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3627 - binary_accuracy: 0.8374 - val_loss: 0.3617 - val_binary_accuracy: 0.8402\n",
      "Epoch 602/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3625 - binary_accuracy: 0.8382 - val_loss: 0.3616 - val_binary_accuracy: 0.8405\n",
      "Epoch 603/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3626 - binary_accuracy: 0.8372 - val_loss: 0.3615 - val_binary_accuracy: 0.8405\n",
      "Epoch 604/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3621 - binary_accuracy: 0.8375 - val_loss: 0.3614 - val_binary_accuracy: 0.8402\n",
      "Epoch 605/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3628 - binary_accuracy: 0.8379 - val_loss: 0.3614 - val_binary_accuracy: 0.8404\n",
      "Epoch 606/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3615 - binary_accuracy: 0.8390 - val_loss: 0.3613 - val_binary_accuracy: 0.8402\n",
      "Epoch 607/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3620 - binary_accuracy: 0.8372 - val_loss: 0.3612 - val_binary_accuracy: 0.8402\n",
      "Epoch 608/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3641 - binary_accuracy: 0.8366 - val_loss: 0.3612 - val_binary_accuracy: 0.8408\n",
      "Epoch 609/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3612 - binary_accuracy: 0.8381 - val_loss: 0.3611 - val_binary_accuracy: 0.8409\n",
      "Epoch 610/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3610 - binary_accuracy: 0.8384 - val_loss: 0.3610 - val_binary_accuracy: 0.8410\n",
      "Epoch 611/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3596 - binary_accuracy: 0.8393 - val_loss: 0.3609 - val_binary_accuracy: 0.8408\n",
      "Epoch 612/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3634 - binary_accuracy: 0.8369 - val_loss: 0.3608 - val_binary_accuracy: 0.8409\n",
      "Epoch 613/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3607 - binary_accuracy: 0.8392 - val_loss: 0.3608 - val_binary_accuracy: 0.8410\n",
      "Epoch 614/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3616 - binary_accuracy: 0.8377 - val_loss: 0.3607 - val_binary_accuracy: 0.8413\n",
      "Epoch 615/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3616 - binary_accuracy: 0.8379 - val_loss: 0.3606 - val_binary_accuracy: 0.8415\n",
      "Epoch 616/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3615 - binary_accuracy: 0.8379 - val_loss: 0.3606 - val_binary_accuracy: 0.8413\n",
      "Epoch 617/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3599 - binary_accuracy: 0.8383 - val_loss: 0.3605 - val_binary_accuracy: 0.8412\n",
      "Epoch 618/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3620 - binary_accuracy: 0.8395 - val_loss: 0.3604 - val_binary_accuracy: 0.8407\n",
      "Epoch 619/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3618 - binary_accuracy: 0.8383 - val_loss: 0.3603 - val_binary_accuracy: 0.8406\n",
      "Epoch 620/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3602 - binary_accuracy: 0.8384 - val_loss: 0.3602 - val_binary_accuracy: 0.8407\n",
      "Epoch 621/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3609 - binary_accuracy: 0.8385 - val_loss: 0.3601 - val_binary_accuracy: 0.8417\n",
      "Epoch 622/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3612 - binary_accuracy: 0.8385 - val_loss: 0.3600 - val_binary_accuracy: 0.8415\n",
      "Epoch 623/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3613 - binary_accuracy: 0.8376 - val_loss: 0.3600 - val_binary_accuracy: 0.8411\n",
      "Epoch 624/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3597 - binary_accuracy: 0.8390 - val_loss: 0.3600 - val_binary_accuracy: 0.8410\n",
      "Epoch 625/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3621 - binary_accuracy: 0.8384 - val_loss: 0.3599 - val_binary_accuracy: 0.8412\n",
      "Epoch 626/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3608 - binary_accuracy: 0.8380 - val_loss: 0.3599 - val_binary_accuracy: 0.8415\n",
      "Epoch 627/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3593 - binary_accuracy: 0.8391 - val_loss: 0.3598 - val_binary_accuracy: 0.8416\n",
      "Epoch 628/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3591 - binary_accuracy: 0.8379 - val_loss: 0.3596 - val_binary_accuracy: 0.8416\n",
      "Epoch 629/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3600 - binary_accuracy: 0.8401 - val_loss: 0.3596 - val_binary_accuracy: 0.8416\n",
      "Epoch 630/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3604 - binary_accuracy: 0.8400 - val_loss: 0.3596 - val_binary_accuracy: 0.8419\n",
      "Epoch 631/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3598 - binary_accuracy: 0.8391 - val_loss: 0.3596 - val_binary_accuracy: 0.8419\n",
      "Epoch 632/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3591 - binary_accuracy: 0.8380 - val_loss: 0.3595 - val_binary_accuracy: 0.8420\n",
      "Epoch 633/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3584 - binary_accuracy: 0.8396 - val_loss: 0.3594 - val_binary_accuracy: 0.8419\n",
      "Epoch 634/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3597 - binary_accuracy: 0.8394 - val_loss: 0.3593 - val_binary_accuracy: 0.8421\n",
      "Epoch 635/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3597 - binary_accuracy: 0.8396 - val_loss: 0.3592 - val_binary_accuracy: 0.8420\n",
      "Epoch 636/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3592 - binary_accuracy: 0.8392 - val_loss: 0.3591 - val_binary_accuracy: 0.8417\n",
      "Epoch 637/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3596 - binary_accuracy: 0.8403 - val_loss: 0.3591 - val_binary_accuracy: 0.8418\n",
      "Epoch 638/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3593 - binary_accuracy: 0.8396 - val_loss: 0.3590 - val_binary_accuracy: 0.8421\n",
      "Epoch 639/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3594 - binary_accuracy: 0.8396 - val_loss: 0.3590 - val_binary_accuracy: 0.8423\n",
      "Epoch 640/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3586 - binary_accuracy: 0.8385 - val_loss: 0.3590 - val_binary_accuracy: 0.8422\n",
      "Epoch 641/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3582 - binary_accuracy: 0.8397 - val_loss: 0.3589 - val_binary_accuracy: 0.8422\n",
      "Epoch 642/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3581 - binary_accuracy: 0.8409 - val_loss: 0.3588 - val_binary_accuracy: 0.8422\n",
      "Epoch 643/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3587 - binary_accuracy: 0.8385 - val_loss: 0.3588 - val_binary_accuracy: 0.8418\n",
      "Epoch 644/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3577 - binary_accuracy: 0.8389 - val_loss: 0.3587 - val_binary_accuracy: 0.8419\n",
      "Epoch 645/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3581 - binary_accuracy: 0.8405 - val_loss: 0.3586 - val_binary_accuracy: 0.8424\n",
      "Epoch 646/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3594 - binary_accuracy: 0.8395 - val_loss: 0.3586 - val_binary_accuracy: 0.8419\n",
      "Epoch 647/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3576 - binary_accuracy: 0.8397 - val_loss: 0.3585 - val_binary_accuracy: 0.8419\n",
      "Epoch 648/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3577 - binary_accuracy: 0.8392 - val_loss: 0.3584 - val_binary_accuracy: 0.8419\n",
      "Epoch 649/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3568 - binary_accuracy: 0.8411 - val_loss: 0.3584 - val_binary_accuracy: 0.8420\n",
      "Epoch 650/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3574 - binary_accuracy: 0.8401 - val_loss: 0.3583 - val_binary_accuracy: 0.8420\n",
      "Epoch 651/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3595 - binary_accuracy: 0.8403 - val_loss: 0.3582 - val_binary_accuracy: 0.8423\n",
      "Epoch 652/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3594 - binary_accuracy: 0.8400 - val_loss: 0.3581 - val_binary_accuracy: 0.8423\n",
      "Epoch 653/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3567 - binary_accuracy: 0.8405 - val_loss: 0.3581 - val_binary_accuracy: 0.8420\n",
      "Epoch 654/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3570 - binary_accuracy: 0.8403 - val_loss: 0.3580 - val_binary_accuracy: 0.8424\n",
      "Epoch 655/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3580 - binary_accuracy: 0.8404 - val_loss: 0.3580 - val_binary_accuracy: 0.8425\n",
      "Epoch 656/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3594 - binary_accuracy: 0.8391 - val_loss: 0.3579 - val_binary_accuracy: 0.8423\n",
      "Epoch 657/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3571 - binary_accuracy: 0.8402 - val_loss: 0.3579 - val_binary_accuracy: 0.8425\n",
      "Epoch 658/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3570 - binary_accuracy: 0.8403 - val_loss: 0.3578 - val_binary_accuracy: 0.8425\n",
      "Epoch 659/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3571 - binary_accuracy: 0.8415 - val_loss: 0.3578 - val_binary_accuracy: 0.8428\n",
      "Epoch 660/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3574 - binary_accuracy: 0.8421 - val_loss: 0.3579 - val_binary_accuracy: 0.8423\n",
      "Epoch 661/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3559 - binary_accuracy: 0.8414 - val_loss: 0.3578 - val_binary_accuracy: 0.8425\n",
      "Epoch 662/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3576 - binary_accuracy: 0.8397 - val_loss: 0.3576 - val_binary_accuracy: 0.8427\n",
      "Epoch 663/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3569 - binary_accuracy: 0.8407 - val_loss: 0.3575 - val_binary_accuracy: 0.8424\n",
      "Epoch 664/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3572 - binary_accuracy: 0.8408 - val_loss: 0.3574 - val_binary_accuracy: 0.8427\n",
      "Epoch 665/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3583 - binary_accuracy: 0.8404 - val_loss: 0.3574 - val_binary_accuracy: 0.8427\n",
      "Epoch 666/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3557 - binary_accuracy: 0.8407 - val_loss: 0.3573 - val_binary_accuracy: 0.8426\n",
      "Epoch 667/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3575 - binary_accuracy: 0.8407 - val_loss: 0.3573 - val_binary_accuracy: 0.8426\n",
      "Epoch 668/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3575 - binary_accuracy: 0.8411 - val_loss: 0.3573 - val_binary_accuracy: 0.8424\n",
      "Epoch 669/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3551 - binary_accuracy: 0.8413 - val_loss: 0.3573 - val_binary_accuracy: 0.8421\n",
      "Epoch 670/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3566 - binary_accuracy: 0.8415 - val_loss: 0.3572 - val_binary_accuracy: 0.8419\n",
      "Epoch 671/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3550 - binary_accuracy: 0.8411 - val_loss: 0.3571 - val_binary_accuracy: 0.8423\n",
      "Epoch 672/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3564 - binary_accuracy: 0.8402 - val_loss: 0.3571 - val_binary_accuracy: 0.8425\n",
      "Epoch 673/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3560 - binary_accuracy: 0.8410 - val_loss: 0.3571 - val_binary_accuracy: 0.8428\n",
      "Epoch 674/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3553 - binary_accuracy: 0.8410 - val_loss: 0.3570 - val_binary_accuracy: 0.8432\n",
      "Epoch 675/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3556 - binary_accuracy: 0.8416 - val_loss: 0.3570 - val_binary_accuracy: 0.8430\n",
      "Epoch 676/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3554 - binary_accuracy: 0.8410 - val_loss: 0.3569 - val_binary_accuracy: 0.8434\n",
      "Epoch 677/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3550 - binary_accuracy: 0.8411 - val_loss: 0.3568 - val_binary_accuracy: 0.8437\n",
      "Epoch 678/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3568 - binary_accuracy: 0.8411 - val_loss: 0.3567 - val_binary_accuracy: 0.8433\n",
      "Epoch 679/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3548 - binary_accuracy: 0.8414 - val_loss: 0.3567 - val_binary_accuracy: 0.8434\n",
      "Epoch 680/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3558 - binary_accuracy: 0.8412 - val_loss: 0.3567 - val_binary_accuracy: 0.8429\n",
      "Epoch 681/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3548 - binary_accuracy: 0.8414 - val_loss: 0.3566 - val_binary_accuracy: 0.8426\n",
      "Epoch 682/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3551 - binary_accuracy: 0.8422 - val_loss: 0.3566 - val_binary_accuracy: 0.8424\n",
      "Epoch 683/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3561 - binary_accuracy: 0.8406 - val_loss: 0.3565 - val_binary_accuracy: 0.8426\n",
      "Epoch 684/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3555 - binary_accuracy: 0.8421 - val_loss: 0.3564 - val_binary_accuracy: 0.8426\n",
      "Epoch 685/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3543 - binary_accuracy: 0.8428 - val_loss: 0.3563 - val_binary_accuracy: 0.8426\n",
      "Epoch 686/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3546 - binary_accuracy: 0.8422 - val_loss: 0.3564 - val_binary_accuracy: 0.8431\n",
      "Epoch 687/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3543 - binary_accuracy: 0.8414 - val_loss: 0.3563 - val_binary_accuracy: 0.8434\n",
      "Epoch 688/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3543 - binary_accuracy: 0.8426 - val_loss: 0.3563 - val_binary_accuracy: 0.8433\n",
      "Epoch 689/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3546 - binary_accuracy: 0.8411 - val_loss: 0.3562 - val_binary_accuracy: 0.8429\n",
      "Epoch 690/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3523 - binary_accuracy: 0.8430 - val_loss: 0.3562 - val_binary_accuracy: 0.8430\n",
      "Epoch 691/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3544 - binary_accuracy: 0.8424 - val_loss: 0.3561 - val_binary_accuracy: 0.8435\n",
      "Epoch 692/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3540 - binary_accuracy: 0.8412 - val_loss: 0.3560 - val_binary_accuracy: 0.8429\n",
      "Epoch 693/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3526 - binary_accuracy: 0.8431 - val_loss: 0.3559 - val_binary_accuracy: 0.8427\n",
      "Epoch 694/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3550 - binary_accuracy: 0.8414 - val_loss: 0.3559 - val_binary_accuracy: 0.8432\n",
      "Epoch 695/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3543 - binary_accuracy: 0.8426 - val_loss: 0.3559 - val_binary_accuracy: 0.8432\n",
      "Epoch 696/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3537 - binary_accuracy: 0.8428 - val_loss: 0.3559 - val_binary_accuracy: 0.8433\n",
      "Epoch 697/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3541 - binary_accuracy: 0.8431 - val_loss: 0.3558 - val_binary_accuracy: 0.8430\n",
      "Epoch 698/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3538 - binary_accuracy: 0.8418 - val_loss: 0.3558 - val_binary_accuracy: 0.8430\n",
      "Epoch 699/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3531 - binary_accuracy: 0.8427 - val_loss: 0.3558 - val_binary_accuracy: 0.8428\n",
      "Epoch 700/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3535 - binary_accuracy: 0.8424 - val_loss: 0.3558 - val_binary_accuracy: 0.8427\n",
      "Epoch 701/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3544 - binary_accuracy: 0.8417 - val_loss: 0.3557 - val_binary_accuracy: 0.8427\n",
      "Epoch 702/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3536 - binary_accuracy: 0.8426 - val_loss: 0.3556 - val_binary_accuracy: 0.8427\n",
      "Epoch 703/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3536 - binary_accuracy: 0.8427 - val_loss: 0.3556 - val_binary_accuracy: 0.8429\n",
      "Epoch 704/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3533 - binary_accuracy: 0.8424 - val_loss: 0.3556 - val_binary_accuracy: 0.8432\n",
      "Epoch 705/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3535 - binary_accuracy: 0.8420 - val_loss: 0.3555 - val_binary_accuracy: 0.8432\n",
      "Epoch 706/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3543 - binary_accuracy: 0.8426 - val_loss: 0.3555 - val_binary_accuracy: 0.8426\n",
      "Epoch 707/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3529 - binary_accuracy: 0.8424 - val_loss: 0.3555 - val_binary_accuracy: 0.8430\n",
      "Epoch 708/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3532 - binary_accuracy: 0.8425 - val_loss: 0.3555 - val_binary_accuracy: 0.8427\n",
      "Epoch 709/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3511 - binary_accuracy: 0.8436 - val_loss: 0.3553 - val_binary_accuracy: 0.8430\n",
      "Epoch 710/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3524 - binary_accuracy: 0.8436 - val_loss: 0.3553 - val_binary_accuracy: 0.8430\n",
      "Epoch 711/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3523 - binary_accuracy: 0.8437 - val_loss: 0.3552 - val_binary_accuracy: 0.8433\n",
      "Epoch 712/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3546 - binary_accuracy: 0.8426 - val_loss: 0.3552 - val_binary_accuracy: 0.8435\n",
      "Epoch 713/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3527 - binary_accuracy: 0.8435 - val_loss: 0.3551 - val_binary_accuracy: 0.8433\n",
      "Epoch 714/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3515 - binary_accuracy: 0.8426 - val_loss: 0.3551 - val_binary_accuracy: 0.8439\n",
      "Epoch 715/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3524 - binary_accuracy: 0.8431 - val_loss: 0.3551 - val_binary_accuracy: 0.8438\n",
      "Epoch 716/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3519 - binary_accuracy: 0.8431 - val_loss: 0.3551 - val_binary_accuracy: 0.8438\n",
      "Epoch 717/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3517 - binary_accuracy: 0.8432 - val_loss: 0.3551 - val_binary_accuracy: 0.8437\n",
      "Epoch 718/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3516 - binary_accuracy: 0.8434 - val_loss: 0.3550 - val_binary_accuracy: 0.8432\n",
      "Epoch 719/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3523 - binary_accuracy: 0.8431 - val_loss: 0.3550 - val_binary_accuracy: 0.8435\n",
      "Epoch 720/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3511 - binary_accuracy: 0.8430 - val_loss: 0.3549 - val_binary_accuracy: 0.8438\n",
      "Epoch 721/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3524 - binary_accuracy: 0.8429 - val_loss: 0.3549 - val_binary_accuracy: 0.8442\n",
      "Epoch 722/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3521 - binary_accuracy: 0.8437 - val_loss: 0.3549 - val_binary_accuracy: 0.8442\n",
      "Epoch 723/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3524 - binary_accuracy: 0.8435 - val_loss: 0.3549 - val_binary_accuracy: 0.8441\n",
      "Epoch 724/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3522 - binary_accuracy: 0.8441 - val_loss: 0.3547 - val_binary_accuracy: 0.8434\n",
      "Epoch 725/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3504 - binary_accuracy: 0.8441 - val_loss: 0.3546 - val_binary_accuracy: 0.8433\n",
      "Epoch 726/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3512 - binary_accuracy: 0.8439 - val_loss: 0.3546 - val_binary_accuracy: 0.8437\n",
      "Epoch 727/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3526 - binary_accuracy: 0.8428 - val_loss: 0.3546 - val_binary_accuracy: 0.8438\n",
      "Epoch 728/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3510 - binary_accuracy: 0.8448 - val_loss: 0.3546 - val_binary_accuracy: 0.8439\n",
      "Epoch 729/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3506 - binary_accuracy: 0.8430 - val_loss: 0.3545 - val_binary_accuracy: 0.8442\n",
      "Epoch 730/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3518 - binary_accuracy: 0.8428 - val_loss: 0.3544 - val_binary_accuracy: 0.8442\n",
      "Epoch 731/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3514 - binary_accuracy: 0.8445 - val_loss: 0.3542 - val_binary_accuracy: 0.8439\n",
      "Epoch 732/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3499 - binary_accuracy: 0.8458 - val_loss: 0.3543 - val_binary_accuracy: 0.8440\n",
      "Epoch 733/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3512 - binary_accuracy: 0.8445 - val_loss: 0.3543 - val_binary_accuracy: 0.8440\n",
      "Epoch 734/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3511 - binary_accuracy: 0.8442 - val_loss: 0.3544 - val_binary_accuracy: 0.8437\n",
      "Epoch 735/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3510 - binary_accuracy: 0.8433 - val_loss: 0.3543 - val_binary_accuracy: 0.8443\n",
      "Epoch 736/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3510 - binary_accuracy: 0.8436 - val_loss: 0.3542 - val_binary_accuracy: 0.8442\n",
      "Epoch 737/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3505 - binary_accuracy: 0.8446 - val_loss: 0.3542 - val_binary_accuracy: 0.8441\n",
      "Epoch 738/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3496 - binary_accuracy: 0.8449 - val_loss: 0.3541 - val_binary_accuracy: 0.8440\n",
      "Epoch 739/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3493 - binary_accuracy: 0.8439 - val_loss: 0.3540 - val_binary_accuracy: 0.8440\n",
      "Epoch 740/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3500 - binary_accuracy: 0.8443 - val_loss: 0.3541 - val_binary_accuracy: 0.8445\n",
      "Epoch 741/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3511 - binary_accuracy: 0.8442 - val_loss: 0.3541 - val_binary_accuracy: 0.8452\n",
      "Epoch 742/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3501 - binary_accuracy: 0.8444 - val_loss: 0.3540 - val_binary_accuracy: 0.8451\n",
      "Epoch 743/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3502 - binary_accuracy: 0.8454 - val_loss: 0.3540 - val_binary_accuracy: 0.8450\n",
      "Epoch 744/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3509 - binary_accuracy: 0.8429 - val_loss: 0.3540 - val_binary_accuracy: 0.8446\n",
      "Epoch 745/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3489 - binary_accuracy: 0.8443 - val_loss: 0.3539 - val_binary_accuracy: 0.8448\n",
      "Epoch 746/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3492 - binary_accuracy: 0.8448 - val_loss: 0.3538 - val_binary_accuracy: 0.8448\n",
      "Epoch 747/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3508 - binary_accuracy: 0.8439 - val_loss: 0.3538 - val_binary_accuracy: 0.8444\n",
      "Epoch 748/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3504 - binary_accuracy: 0.8436 - val_loss: 0.3539 - val_binary_accuracy: 0.8447\n",
      "Epoch 749/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3508 - binary_accuracy: 0.8431 - val_loss: 0.3539 - val_binary_accuracy: 0.8450\n",
      "Epoch 750/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3496 - binary_accuracy: 0.8453 - val_loss: 0.3538 - val_binary_accuracy: 0.8447\n",
      "Epoch 751/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3502 - binary_accuracy: 0.8433 - val_loss: 0.3538 - val_binary_accuracy: 0.8444\n",
      "Epoch 752/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3475 - binary_accuracy: 0.8450 - val_loss: 0.3537 - val_binary_accuracy: 0.8446\n",
      "Epoch 753/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3483 - binary_accuracy: 0.8448 - val_loss: 0.3536 - val_binary_accuracy: 0.8444\n",
      "Epoch 754/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3495 - binary_accuracy: 0.8440 - val_loss: 0.3536 - val_binary_accuracy: 0.8445\n",
      "Epoch 755/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3490 - binary_accuracy: 0.8450 - val_loss: 0.3537 - val_binary_accuracy: 0.8445\n",
      "Epoch 756/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3505 - binary_accuracy: 0.8447 - val_loss: 0.3537 - val_binary_accuracy: 0.8445\n",
      "Epoch 757/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3494 - binary_accuracy: 0.8451 - val_loss: 0.3536 - val_binary_accuracy: 0.8444\n",
      "Epoch 758/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3509 - binary_accuracy: 0.8440 - val_loss: 0.3535 - val_binary_accuracy: 0.8445\n",
      "Epoch 759/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3500 - binary_accuracy: 0.8451 - val_loss: 0.3535 - val_binary_accuracy: 0.8445\n",
      "Epoch 760/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3497 - binary_accuracy: 0.8449 - val_loss: 0.3535 - val_binary_accuracy: 0.8443\n",
      "Epoch 761/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3481 - binary_accuracy: 0.8437 - val_loss: 0.3536 - val_binary_accuracy: 0.8443\n",
      "Epoch 762/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3488 - binary_accuracy: 0.8429 - val_loss: 0.3534 - val_binary_accuracy: 0.8442\n",
      "Epoch 763/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3486 - binary_accuracy: 0.8455 - val_loss: 0.3534 - val_binary_accuracy: 0.8442\n",
      "Epoch 764/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3486 - binary_accuracy: 0.8447 - val_loss: 0.3533 - val_binary_accuracy: 0.8447\n",
      "Epoch 765/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3505 - binary_accuracy: 0.8450 - val_loss: 0.3532 - val_binary_accuracy: 0.8449\n",
      "Epoch 766/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3485 - binary_accuracy: 0.8444 - val_loss: 0.3531 - val_binary_accuracy: 0.8447\n",
      "Epoch 767/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3483 - binary_accuracy: 0.8447 - val_loss: 0.3532 - val_binary_accuracy: 0.8447\n",
      "Epoch 768/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3488 - binary_accuracy: 0.8453 - val_loss: 0.3531 - val_binary_accuracy: 0.8447\n",
      "Epoch 769/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3478 - binary_accuracy: 0.8451 - val_loss: 0.3531 - val_binary_accuracy: 0.8445\n",
      "Epoch 770/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3487 - binary_accuracy: 0.8454 - val_loss: 0.3531 - val_binary_accuracy: 0.8444\n",
      "Epoch 771/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3491 - binary_accuracy: 0.8450 - val_loss: 0.3531 - val_binary_accuracy: 0.8445\n",
      "Epoch 772/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3475 - binary_accuracy: 0.8455 - val_loss: 0.3531 - val_binary_accuracy: 0.8446\n",
      "Epoch 773/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3481 - binary_accuracy: 0.8452 - val_loss: 0.3530 - val_binary_accuracy: 0.8444\n",
      "Epoch 774/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3473 - binary_accuracy: 0.8449 - val_loss: 0.3530 - val_binary_accuracy: 0.8444\n",
      "Epoch 775/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3476 - binary_accuracy: 0.8457 - val_loss: 0.3531 - val_binary_accuracy: 0.8446\n",
      "Epoch 776/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3496 - binary_accuracy: 0.8453 - val_loss: 0.3531 - val_binary_accuracy: 0.8443\n",
      "Epoch 777/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3479 - binary_accuracy: 0.8461 - val_loss: 0.3530 - val_binary_accuracy: 0.8443\n",
      "Epoch 778/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3492 - binary_accuracy: 0.8455 - val_loss: 0.3530 - val_binary_accuracy: 0.8443\n",
      "Epoch 779/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3480 - binary_accuracy: 0.8455 - val_loss: 0.3529 - val_binary_accuracy: 0.8444\n",
      "Epoch 780/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3473 - binary_accuracy: 0.8456 - val_loss: 0.3529 - val_binary_accuracy: 0.8447\n",
      "Epoch 781/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3466 - binary_accuracy: 0.8460 - val_loss: 0.3529 - val_binary_accuracy: 0.8448\n",
      "Epoch 782/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3470 - binary_accuracy: 0.8452 - val_loss: 0.3529 - val_binary_accuracy: 0.8451\n",
      "Epoch 783/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3498 - binary_accuracy: 0.8444 - val_loss: 0.3527 - val_binary_accuracy: 0.8453\n",
      "Epoch 784/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3484 - binary_accuracy: 0.8456 - val_loss: 0.3526 - val_binary_accuracy: 0.8449\n",
      "Epoch 785/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3474 - binary_accuracy: 0.8443 - val_loss: 0.3527 - val_binary_accuracy: 0.8447\n",
      "Epoch 786/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3477 - binary_accuracy: 0.8465 - val_loss: 0.3527 - val_binary_accuracy: 0.8446\n",
      "Epoch 787/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3464 - binary_accuracy: 0.8460 - val_loss: 0.3526 - val_binary_accuracy: 0.8447\n",
      "Epoch 788/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3471 - binary_accuracy: 0.8451 - val_loss: 0.3525 - val_binary_accuracy: 0.8447\n",
      "Epoch 789/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3470 - binary_accuracy: 0.8453 - val_loss: 0.3524 - val_binary_accuracy: 0.8450\n",
      "Epoch 790/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3468 - binary_accuracy: 0.8451 - val_loss: 0.3523 - val_binary_accuracy: 0.8447\n",
      "Epoch 791/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3470 - binary_accuracy: 0.8452 - val_loss: 0.3523 - val_binary_accuracy: 0.8449\n",
      "Epoch 792/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3481 - binary_accuracy: 0.8450 - val_loss: 0.3524 - val_binary_accuracy: 0.8450\n",
      "Epoch 793/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3480 - binary_accuracy: 0.8453 - val_loss: 0.3523 - val_binary_accuracy: 0.8451\n",
      "Epoch 794/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3466 - binary_accuracy: 0.8457 - val_loss: 0.3524 - val_binary_accuracy: 0.8453\n",
      "Epoch 795/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3465 - binary_accuracy: 0.8459 - val_loss: 0.3522 - val_binary_accuracy: 0.8454\n",
      "Epoch 796/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3469 - binary_accuracy: 0.8450 - val_loss: 0.3521 - val_binary_accuracy: 0.8453\n",
      "Epoch 797/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3463 - binary_accuracy: 0.8470 - val_loss: 0.3521 - val_binary_accuracy: 0.8455\n",
      "Epoch 798/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3474 - binary_accuracy: 0.8454 - val_loss: 0.3521 - val_binary_accuracy: 0.8452\n",
      "Epoch 799/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3459 - binary_accuracy: 0.8457 - val_loss: 0.3522 - val_binary_accuracy: 0.8451\n",
      "Epoch 800/800\n",
      "48000/48000 [==============================] - 0s 2us/step - loss: 0.3463 - binary_accuracy: 0.8460 - val_loss: 0.3522 - val_binary_accuracy: 0.8453\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models,layers,losses,metrics,optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(150, activation='relu', input_shape=(131,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    " \n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*precision*recall/(precision+recall+K.epsilon())\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001),#optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=800,\n",
    "                    batch_size=10240,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3513 - binary_accuracy: 0.8445\n",
      "Epoch 2/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3524 - binary_accuracy: 0.8449\n",
      "Epoch 3/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3507 - binary_accuracy: 0.8437\n",
      "Epoch 4/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3517 - binary_accuracy: 0.8455\n",
      "Epoch 5/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3506 - binary_accuracy: 0.8434\n",
      "Epoch 6/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3506 - binary_accuracy: 0.8447\n",
      "Epoch 7/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3511 - binary_accuracy: 0.8451\n",
      "Epoch 8/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3498 - binary_accuracy: 0.8446\n",
      "Epoch 9/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3500 - binary_accuracy: 0.8452\n",
      "Epoch 10/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3505 - binary_accuracy: 0.8441\n",
      "Epoch 11/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3506 - binary_accuracy: 0.8441\n",
      "Epoch 12/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3515 - binary_accuracy: 0.8460\n",
      "Epoch 13/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3507 - binary_accuracy: 0.8460\n",
      "Epoch 14/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3496 - binary_accuracy: 0.8449\n",
      "Epoch 15/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3493 - binary_accuracy: 0.8455\n",
      "Epoch 16/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3505 - binary_accuracy: 0.8444\n",
      "Epoch 17/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3499 - binary_accuracy: 0.8452\n",
      "Epoch 18/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3498 - binary_accuracy: 0.8459\n",
      "Epoch 19/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3504 - binary_accuracy: 0.8459\n",
      "Epoch 20/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3492 - binary_accuracy: 0.8443\n",
      "Epoch 21/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3497 - binary_accuracy: 0.8453\n",
      "Epoch 22/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3499 - binary_accuracy: 0.8460\n",
      "Epoch 23/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3490 - binary_accuracy: 0.8452\n",
      "Epoch 24/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3493 - binary_accuracy: 0.8455\n",
      "Epoch 25/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3492 - binary_accuracy: 0.8459\n",
      "Epoch 26/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3491 - binary_accuracy: 0.8462\n",
      "Epoch 27/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3507 - binary_accuracy: 0.8446\n",
      "Epoch 28/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3495 - binary_accuracy: 0.8447\n",
      "Epoch 29/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3480 - binary_accuracy: 0.8472\n",
      "Epoch 30/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3482 - binary_accuracy: 0.8459\n",
      "Epoch 31/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3494 - binary_accuracy: 0.8464\n",
      "Epoch 32/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3488 - binary_accuracy: 0.8448\n",
      "Epoch 33/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3483 - binary_accuracy: 0.8462\n",
      "Epoch 34/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3481 - binary_accuracy: 0.8457\n",
      "Epoch 35/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3498 - binary_accuracy: 0.8440\n",
      "Epoch 36/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3482 - binary_accuracy: 0.8465\n",
      "Epoch 37/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3489 - binary_accuracy: 0.8447\n",
      "Epoch 38/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3510 - binary_accuracy: 0.8441\n",
      "Epoch 39/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3479 - binary_accuracy: 0.8463\n",
      "Epoch 40/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3493 - binary_accuracy: 0.8454\n",
      "Epoch 41/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3488 - binary_accuracy: 0.8461\n",
      "Epoch 42/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3482 - binary_accuracy: 0.8453\n",
      "Epoch 43/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3469 - binary_accuracy: 0.8460\n",
      "Epoch 44/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3482 - binary_accuracy: 0.8456\n",
      "Epoch 45/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3482 - binary_accuracy: 0.8461\n",
      "Epoch 46/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3471 - binary_accuracy: 0.8468\n",
      "Epoch 47/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3468 - binary_accuracy: 0.8452\n",
      "Epoch 48/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3474 - binary_accuracy: 0.8458\n",
      "Epoch 49/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3489 - binary_accuracy: 0.8466\n",
      "Epoch 50/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3479 - binary_accuracy: 0.8466\n",
      "Epoch 51/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3468 - binary_accuracy: 0.8467\n",
      "Epoch 52/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3465 - binary_accuracy: 0.8465\n",
      "Epoch 53/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3476 - binary_accuracy: 0.8467\n",
      "Epoch 54/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3469 - binary_accuracy: 0.8462\n",
      "Epoch 55/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3466 - binary_accuracy: 0.8473\n",
      "Epoch 56/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3467 - binary_accuracy: 0.8459\n",
      "Epoch 57/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3463 - binary_accuracy: 0.8474\n",
      "Epoch 58/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3465 - binary_accuracy: 0.8467\n",
      "Epoch 59/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3472 - binary_accuracy: 0.8473\n",
      "Epoch 60/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3469 - binary_accuracy: 0.8460\n",
      "Epoch 61/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3467 - binary_accuracy: 0.8459\n",
      "Epoch 62/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3447 - binary_accuracy: 0.8475\n",
      "Epoch 63/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3483 - binary_accuracy: 0.8477\n",
      "Epoch 64/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3458 - binary_accuracy: 0.8473\n",
      "Epoch 65/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3459 - binary_accuracy: 0.8472\n",
      "Epoch 66/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3467 - binary_accuracy: 0.8467\n",
      "Epoch 67/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3466 - binary_accuracy: 0.8470\n",
      "Epoch 68/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3464 - binary_accuracy: 0.8476\n",
      "Epoch 69/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3476 - binary_accuracy: 0.8467\n",
      "Epoch 70/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3462 - binary_accuracy: 0.8465\n",
      "Epoch 71/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3467 - binary_accuracy: 0.8467\n",
      "Epoch 72/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3451 - binary_accuracy: 0.8475\n",
      "Epoch 73/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3468 - binary_accuracy: 0.8475\n",
      "Epoch 74/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3456 - binary_accuracy: 0.8465\n",
      "Epoch 75/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3464 - binary_accuracy: 0.8469\n",
      "Epoch 76/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3470 - binary_accuracy: 0.8475\n",
      "Epoch 77/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3450 - binary_accuracy: 0.8469\n",
      "Epoch 78/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3453 - binary_accuracy: 0.8467\n",
      "Epoch 79/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3443 - binary_accuracy: 0.8481\n",
      "Epoch 80/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3456 - binary_accuracy: 0.8469\n",
      "Epoch 81/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3456 - binary_accuracy: 0.8478\n",
      "Epoch 82/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3449 - binary_accuracy: 0.8481\n",
      "Epoch 83/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3452 - binary_accuracy: 0.8469\n",
      "Epoch 84/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3462 - binary_accuracy: 0.8467\n",
      "Epoch 85/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3456 - binary_accuracy: 0.8478\n",
      "Epoch 86/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3464 - binary_accuracy: 0.8471\n",
      "Epoch 87/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3460 - binary_accuracy: 0.8483\n",
      "Epoch 88/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3449 - binary_accuracy: 0.8479\n",
      "Epoch 89/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3453 - binary_accuracy: 0.8476\n",
      "Epoch 90/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3447 - binary_accuracy: 0.8474\n",
      "Epoch 91/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3447 - binary_accuracy: 0.8466\n",
      "Epoch 92/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3450 - binary_accuracy: 0.8479\n",
      "Epoch 93/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3456 - binary_accuracy: 0.8457\n",
      "Epoch 94/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3437 - binary_accuracy: 0.8479\n",
      "Epoch 95/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3454 - binary_accuracy: 0.8476\n",
      "Epoch 96/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3440 - binary_accuracy: 0.8473\n",
      "Epoch 97/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3455 - binary_accuracy: 0.8468\n",
      "Epoch 98/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3446 - binary_accuracy: 0.8481\n",
      "Epoch 99/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3446 - binary_accuracy: 0.8478\n",
      "Epoch 100/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3453 - binary_accuracy: 0.8469\n",
      "Epoch 101/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3444 - binary_accuracy: 0.8480\n",
      "Epoch 102/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3449 - binary_accuracy: 0.8475\n",
      "Epoch 103/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3439 - binary_accuracy: 0.8486\n",
      "Epoch 104/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3436 - binary_accuracy: 0.8488\n",
      "Epoch 105/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3445 - binary_accuracy: 0.8482\n",
      "Epoch 106/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3447 - binary_accuracy: 0.8476\n",
      "Epoch 107/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3430 - binary_accuracy: 0.8480\n",
      "Epoch 108/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3438 - binary_accuracy: 0.8481\n",
      "Epoch 109/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3438 - binary_accuracy: 0.8488\n",
      "Epoch 110/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3446 - binary_accuracy: 0.8481\n",
      "Epoch 111/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3448 - binary_accuracy: 0.8482\n",
      "Epoch 112/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3446 - binary_accuracy: 0.8474\n",
      "Epoch 113/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3422 - binary_accuracy: 0.8494\n",
      "Epoch 114/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3433 - binary_accuracy: 0.8486\n",
      "Epoch 115/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3448 - binary_accuracy: 0.8479\n",
      "Epoch 116/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3443 - binary_accuracy: 0.8487\n",
      "Epoch 117/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3437 - binary_accuracy: 0.8481\n",
      "Epoch 118/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3433 - binary_accuracy: 0.8483\n",
      "Epoch 119/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3430 - binary_accuracy: 0.8488\n",
      "Epoch 120/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3439 - binary_accuracy: 0.8485\n",
      "Epoch 121/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3431 - binary_accuracy: 0.8488\n",
      "Epoch 122/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3427 - binary_accuracy: 0.8487\n",
      "Epoch 123/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3423 - binary_accuracy: 0.8487\n",
      "Epoch 124/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3432 - binary_accuracy: 0.8491\n",
      "Epoch 125/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3435 - binary_accuracy: 0.8468\n",
      "Epoch 126/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3435 - binary_accuracy: 0.8479\n",
      "Epoch 127/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3424 - binary_accuracy: 0.8480\n",
      "Epoch 128/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3440 - binary_accuracy: 0.8488\n",
      "Epoch 129/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3441 - binary_accuracy: 0.8471\n",
      "Epoch 130/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3436 - binary_accuracy: 0.8479\n",
      "Epoch 131/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3434 - binary_accuracy: 0.8483\n",
      "Epoch 132/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3447 - binary_accuracy: 0.8485\n",
      "Epoch 133/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3448 - binary_accuracy: 0.8475\n",
      "Epoch 134/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3429 - binary_accuracy: 0.8472\n",
      "Epoch 135/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3420 - binary_accuracy: 0.8493\n",
      "Epoch 136/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3427 - binary_accuracy: 0.8492\n",
      "Epoch 137/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3445 - binary_accuracy: 0.8475\n",
      "Epoch 138/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3426 - binary_accuracy: 0.8484\n",
      "Epoch 139/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3423 - binary_accuracy: 0.8493\n",
      "Epoch 140/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3425 - binary_accuracy: 0.8485\n",
      "Epoch 141/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3431 - binary_accuracy: 0.8496\n",
      "Epoch 142/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3438 - binary_accuracy: 0.8487\n",
      "Epoch 143/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3434 - binary_accuracy: 0.8476\n",
      "Epoch 144/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3428 - binary_accuracy: 0.8485\n",
      "Epoch 145/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8492\n",
      "Epoch 146/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3412 - binary_accuracy: 0.8493\n",
      "Epoch 147/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3424 - binary_accuracy: 0.8479\n",
      "Epoch 148/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8487\n",
      "Epoch 149/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3432 - binary_accuracy: 0.8487\n",
      "Epoch 150/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3415 - binary_accuracy: 0.8505\n",
      "Epoch 151/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3427 - binary_accuracy: 0.8491\n",
      "Epoch 152/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8496\n",
      "Epoch 153/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8496\n",
      "Epoch 154/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3418 - binary_accuracy: 0.8489\n",
      "Epoch 155/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3419 - binary_accuracy: 0.8488\n",
      "Epoch 156/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3405 - binary_accuracy: 0.8500\n",
      "Epoch 157/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3412 - binary_accuracy: 0.8488\n",
      "Epoch 158/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3409 - binary_accuracy: 0.8489\n",
      "Epoch 159/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8500\n",
      "Epoch 160/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3413 - binary_accuracy: 0.8499\n",
      "Epoch 161/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3418 - binary_accuracy: 0.8504\n",
      "Epoch 162/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3424 - binary_accuracy: 0.8499\n",
      "Epoch 163/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3410 - binary_accuracy: 0.8497\n",
      "Epoch 164/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3409 - binary_accuracy: 0.8488\n",
      "Epoch 165/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3428 - binary_accuracy: 0.8487\n",
      "Epoch 166/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3405 - binary_accuracy: 0.8491\n",
      "Epoch 167/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3415 - binary_accuracy: 0.8484\n",
      "Epoch 168/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3397 - binary_accuracy: 0.8506\n",
      "Epoch 169/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3421 - binary_accuracy: 0.8488\n",
      "Epoch 170/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3408 - binary_accuracy: 0.8485\n",
      "Epoch 171/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3422 - binary_accuracy: 0.8494\n",
      "Epoch 172/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3399 - binary_accuracy: 0.8500\n",
      "Epoch 173/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3420 - binary_accuracy: 0.8490\n",
      "Epoch 174/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3407 - binary_accuracy: 0.8504\n",
      "Epoch 175/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3414 - binary_accuracy: 0.8490\n",
      "Epoch 176/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3395 - binary_accuracy: 0.8503\n",
      "Epoch 177/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3404 - binary_accuracy: 0.8508\n",
      "Epoch 178/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3417 - binary_accuracy: 0.8489\n",
      "Epoch 179/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3406 - binary_accuracy: 0.8499\n",
      "Epoch 180/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3408 - binary_accuracy: 0.8501\n",
      "Epoch 181/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3409 - binary_accuracy: 0.8497\n",
      "Epoch 182/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3392 - binary_accuracy: 0.8500\n",
      "Epoch 183/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3394 - binary_accuracy: 0.8494\n",
      "Epoch 184/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3407 - binary_accuracy: 0.8495\n",
      "Epoch 185/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3396 - binary_accuracy: 0.8495\n",
      "Epoch 186/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3403 - binary_accuracy: 0.8493\n",
      "Epoch 187/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3407 - binary_accuracy: 0.8497\n",
      "Epoch 188/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3407 - binary_accuracy: 0.8496\n",
      "Epoch 189/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3395 - binary_accuracy: 0.8503\n",
      "Epoch 190/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3401 - binary_accuracy: 0.8506\n",
      "Epoch 191/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3397 - binary_accuracy: 0.8508\n",
      "Epoch 192/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3410 - binary_accuracy: 0.8488\n",
      "Epoch 193/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3410 - binary_accuracy: 0.8512\n",
      "Epoch 194/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3397 - binary_accuracy: 0.8504\n",
      "Epoch 195/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3397 - binary_accuracy: 0.8505\n",
      "Epoch 196/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3407 - binary_accuracy: 0.8502\n",
      "Epoch 197/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3400 - binary_accuracy: 0.8511\n",
      "Epoch 198/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3393 - binary_accuracy: 0.8500\n",
      "Epoch 199/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3396 - binary_accuracy: 0.8497\n",
      "Epoch 200/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3395 - binary_accuracy: 0.8500\n",
      "Epoch 201/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3408 - binary_accuracy: 0.8500\n",
      "Epoch 202/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3398 - binary_accuracy: 0.8491\n",
      "Epoch 203/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3389 - binary_accuracy: 0.8508\n",
      "Epoch 204/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3413 - binary_accuracy: 0.8490\n",
      "Epoch 205/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3390 - binary_accuracy: 0.8506\n",
      "Epoch 206/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3381 - binary_accuracy: 0.8500\n",
      "Epoch 207/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3397 - binary_accuracy: 0.8505\n",
      "Epoch 208/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3396 - binary_accuracy: 0.8504\n",
      "Epoch 209/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3391 - binary_accuracy: 0.8506\n",
      "Epoch 210/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3401 - binary_accuracy: 0.8503\n",
      "Epoch 211/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3401 - binary_accuracy: 0.8502\n",
      "Epoch 212/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3399 - binary_accuracy: 0.8512\n",
      "Epoch 213/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3395 - binary_accuracy: 0.8498\n",
      "Epoch 214/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3399 - binary_accuracy: 0.8502\n",
      "Epoch 215/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3389 - binary_accuracy: 0.8503\n",
      "Epoch 216/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3406 - binary_accuracy: 0.8502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3391 - binary_accuracy: 0.8505\n",
      "Epoch 218/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3391 - binary_accuracy: 0.8506\n",
      "Epoch 219/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3389 - binary_accuracy: 0.8496\n",
      "Epoch 220/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3387 - binary_accuracy: 0.8498\n",
      "Epoch 221/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3380 - binary_accuracy: 0.8504\n",
      "Epoch 222/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3386 - binary_accuracy: 0.8497\n",
      "Epoch 223/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3378 - binary_accuracy: 0.8499\n",
      "Epoch 224/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3390 - binary_accuracy: 0.8512\n",
      "Epoch 225/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3385 - binary_accuracy: 0.8505\n",
      "Epoch 226/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3372 - binary_accuracy: 0.8511\n",
      "Epoch 227/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3392 - binary_accuracy: 0.8504\n",
      "Epoch 228/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3394 - binary_accuracy: 0.8503\n",
      "Epoch 229/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3379 - binary_accuracy: 0.8506\n",
      "Epoch 230/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3393 - binary_accuracy: 0.8499\n",
      "Epoch 231/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8511\n",
      "Epoch 232/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3365 - binary_accuracy: 0.8513\n",
      "Epoch 233/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3390 - binary_accuracy: 0.8509\n",
      "Epoch 234/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3399 - binary_accuracy: 0.8501\n",
      "Epoch 235/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3369 - binary_accuracy: 0.8520\n",
      "Epoch 236/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3370 - binary_accuracy: 0.8514\n",
      "Epoch 237/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3385 - binary_accuracy: 0.8502\n",
      "Epoch 238/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3369 - binary_accuracy: 0.8510\n",
      "Epoch 239/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3388 - binary_accuracy: 0.8507\n",
      "Epoch 240/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3383 - binary_accuracy: 0.8510\n",
      "Epoch 241/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3386 - binary_accuracy: 0.8512\n",
      "Epoch 242/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3371 - binary_accuracy: 0.8515\n",
      "Epoch 243/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3385 - binary_accuracy: 0.8505\n",
      "Epoch 244/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3377 - binary_accuracy: 0.8512\n",
      "Epoch 245/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3374 - binary_accuracy: 0.8513\n",
      "Epoch 246/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3376 - binary_accuracy: 0.8508\n",
      "Epoch 247/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3386 - binary_accuracy: 0.8500\n",
      "Epoch 248/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3380 - binary_accuracy: 0.8508\n",
      "Epoch 249/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3365 - binary_accuracy: 0.8523\n",
      "Epoch 250/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3371 - binary_accuracy: 0.8514\n",
      "Epoch 251/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8499\n",
      "Epoch 252/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3369 - binary_accuracy: 0.8513\n",
      "Epoch 253/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3382 - binary_accuracy: 0.8505\n",
      "Epoch 254/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3365 - binary_accuracy: 0.8514\n",
      "Epoch 255/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8503\n",
      "Epoch 256/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3372 - binary_accuracy: 0.8511\n",
      "Epoch 257/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3367 - binary_accuracy: 0.8503\n",
      "Epoch 258/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8503\n",
      "Epoch 259/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3373 - binary_accuracy: 0.8505\n",
      "Epoch 260/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3382 - binary_accuracy: 0.8504\n",
      "Epoch 261/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3393 - binary_accuracy: 0.8509\n",
      "Epoch 262/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3362 - binary_accuracy: 0.8511\n",
      "Epoch 263/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3380 - binary_accuracy: 0.8510\n",
      "Epoch 264/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3379 - binary_accuracy: 0.8505\n",
      "Epoch 265/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3364 - binary_accuracy: 0.8512\n",
      "Epoch 266/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3363 - binary_accuracy: 0.8507\n",
      "Epoch 267/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8511\n",
      "Epoch 268/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3376 - binary_accuracy: 0.8515\n",
      "Epoch 269/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3372 - binary_accuracy: 0.8503\n",
      "Epoch 270/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3363 - binary_accuracy: 0.8513\n",
      "Epoch 271/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3363 - binary_accuracy: 0.8518\n",
      "Epoch 272/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3374 - binary_accuracy: 0.8506\n",
      "Epoch 273/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3359 - binary_accuracy: 0.8524\n",
      "Epoch 274/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3378 - binary_accuracy: 0.8510\n",
      "Epoch 275/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3358 - binary_accuracy: 0.8513\n",
      "Epoch 276/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3386 - binary_accuracy: 0.8503\n",
      "Epoch 277/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3368 - binary_accuracy: 0.8518\n",
      "Epoch 278/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3357 - binary_accuracy: 0.8518\n",
      "Epoch 279/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3365 - binary_accuracy: 0.8513\n",
      "Epoch 280/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3356 - binary_accuracy: 0.8508\n",
      "Epoch 281/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3368 - binary_accuracy: 0.8529\n",
      "Epoch 282/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3360 - binary_accuracy: 0.8518\n",
      "Epoch 283/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3360 - binary_accuracy: 0.8519\n",
      "Epoch 284/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3365 - binary_accuracy: 0.8516\n",
      "Epoch 285/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3360 - binary_accuracy: 0.8520\n",
      "Epoch 286/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3372 - binary_accuracy: 0.8515\n",
      "Epoch 287/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3367 - binary_accuracy: 0.8515\n",
      "Epoch 288/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3355 - binary_accuracy: 0.8523\n",
      "Epoch 289/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3351 - binary_accuracy: 0.8517\n",
      "Epoch 290/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3358 - binary_accuracy: 0.8532\n",
      "Epoch 291/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3352 - binary_accuracy: 0.8529\n",
      "Epoch 292/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3368 - binary_accuracy: 0.8518\n",
      "Epoch 293/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3362 - binary_accuracy: 0.8510\n",
      "Epoch 294/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3361 - binary_accuracy: 0.8516\n",
      "Epoch 295/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3351 - binary_accuracy: 0.8514\n",
      "Epoch 296/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3364 - binary_accuracy: 0.8527\n",
      "Epoch 297/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3380 - binary_accuracy: 0.8507\n",
      "Epoch 298/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3350 - binary_accuracy: 0.8516\n",
      "Epoch 299/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3343 - binary_accuracy: 0.8529\n",
      "Epoch 300/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3360 - binary_accuracy: 0.8519\n",
      "Epoch 301/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3357 - binary_accuracy: 0.8517\n",
      "Epoch 302/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3355 - binary_accuracy: 0.8522\n",
      "Epoch 303/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3358 - binary_accuracy: 0.8524\n",
      "Epoch 304/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3355 - binary_accuracy: 0.8522\n",
      "Epoch 305/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3364 - binary_accuracy: 0.8512\n",
      "Epoch 306/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3357 - binary_accuracy: 0.8519\n",
      "Epoch 307/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3352 - binary_accuracy: 0.8522\n",
      "Epoch 308/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3344 - binary_accuracy: 0.8526\n",
      "Epoch 309/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3345 - binary_accuracy: 0.8515\n",
      "Epoch 310/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3347 - binary_accuracy: 0.8509\n",
      "Epoch 311/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3348 - binary_accuracy: 0.8520\n",
      "Epoch 312/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3350 - binary_accuracy: 0.8506\n",
      "Epoch 313/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3357 - binary_accuracy: 0.8511\n",
      "Epoch 314/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3352 - binary_accuracy: 0.8513\n",
      "Epoch 315/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3334 - binary_accuracy: 0.8533\n",
      "Epoch 316/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3349 - binary_accuracy: 0.8530\n",
      "Epoch 317/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3368 - binary_accuracy: 0.8520\n",
      "Epoch 318/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3353 - binary_accuracy: 0.8522\n",
      "Epoch 319/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3334 - binary_accuracy: 0.8529\n",
      "Epoch 320/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3356 - binary_accuracy: 0.8532\n",
      "Epoch 321/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3342 - binary_accuracy: 0.8531\n",
      "Epoch 322/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3348 - binary_accuracy: 0.8524\n",
      "Epoch 323/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3351 - binary_accuracy: 0.8529\n",
      "Epoch 324/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3370 - binary_accuracy: 0.8515\n",
      "Epoch 325/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3352 - binary_accuracy: 0.8512\n",
      "Epoch 326/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3344 - binary_accuracy: 0.8526\n",
      "Epoch 327/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3352 - binary_accuracy: 0.8525\n",
      "Epoch 328/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3356 - binary_accuracy: 0.8526\n",
      "Epoch 329/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3363 - binary_accuracy: 0.8509\n",
      "Epoch 330/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3349 - binary_accuracy: 0.8527\n",
      "Epoch 331/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3346 - binary_accuracy: 0.8533\n",
      "Epoch 332/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3338 - binary_accuracy: 0.8515\n",
      "Epoch 333/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3349 - binary_accuracy: 0.8535\n",
      "Epoch 334/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3356 - binary_accuracy: 0.8524\n",
      "Epoch 335/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3344 - binary_accuracy: 0.8531\n",
      "Epoch 336/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3332 - binary_accuracy: 0.8534\n",
      "Epoch 337/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3350 - binary_accuracy: 0.8532\n",
      "Epoch 338/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3349 - binary_accuracy: 0.8519\n",
      "Epoch 339/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3347 - binary_accuracy: 0.8530\n",
      "Epoch 340/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8532\n",
      "Epoch 341/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3331 - binary_accuracy: 0.8525\n",
      "Epoch 342/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8519\n",
      "Epoch 343/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3338 - binary_accuracy: 0.8525\n",
      "Epoch 344/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8524\n",
      "Epoch 345/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3347 - binary_accuracy: 0.8531\n",
      "Epoch 346/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3341 - binary_accuracy: 0.8522\n",
      "Epoch 347/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3331 - binary_accuracy: 0.8523\n",
      "Epoch 348/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3336 - binary_accuracy: 0.8529\n",
      "Epoch 349/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3337 - binary_accuracy: 0.8509\n",
      "Epoch 350/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3332 - binary_accuracy: 0.8531\n",
      "Epoch 351/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8518\n",
      "Epoch 352/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3336 - binary_accuracy: 0.8527\n",
      "Epoch 353/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3325 - binary_accuracy: 0.8524\n",
      "Epoch 354/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3336 - binary_accuracy: 0.8530\n",
      "Epoch 355/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3344 - binary_accuracy: 0.8532\n",
      "Epoch 356/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3333 - binary_accuracy: 0.8527\n",
      "Epoch 357/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3323 - binary_accuracy: 0.8543\n",
      "Epoch 358/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3322 - binary_accuracy: 0.8535\n",
      "Epoch 359/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3336 - binary_accuracy: 0.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3337 - binary_accuracy: 0.8532\n",
      "Epoch 361/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8528\n",
      "Epoch 362/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3322 - binary_accuracy: 0.8534\n",
      "Epoch 363/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8529\n",
      "Epoch 364/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3327 - binary_accuracy: 0.8536\n",
      "Epoch 365/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3337 - binary_accuracy: 0.8528\n",
      "Epoch 366/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3341 - binary_accuracy: 0.8525\n",
      "Epoch 367/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3341 - binary_accuracy: 0.8529\n",
      "Epoch 368/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3332 - binary_accuracy: 0.8525\n",
      "Epoch 369/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3331 - binary_accuracy: 0.8523\n",
      "Epoch 370/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3338 - binary_accuracy: 0.8517\n",
      "Epoch 371/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3328 - binary_accuracy: 0.8539\n",
      "Epoch 372/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3325 - binary_accuracy: 0.8535\n",
      "Epoch 373/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3328 - binary_accuracy: 0.8526\n",
      "Epoch 374/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3321 - binary_accuracy: 0.8537\n",
      "Epoch 375/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3319 - binary_accuracy: 0.8530\n",
      "Epoch 376/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3335 - binary_accuracy: 0.8526\n",
      "Epoch 377/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8526\n",
      "Epoch 378/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3315 - binary_accuracy: 0.8538\n",
      "Epoch 379/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3317 - binary_accuracy: 0.8537\n",
      "Epoch 380/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8534\n",
      "Epoch 381/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3320 - binary_accuracy: 0.8540\n",
      "Epoch 382/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3322 - binary_accuracy: 0.8537\n",
      "Epoch 383/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3324 - binary_accuracy: 0.8539\n",
      "Epoch 384/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3340 - binary_accuracy: 0.8521\n",
      "Epoch 385/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3327 - binary_accuracy: 0.8545\n",
      "Epoch 386/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3330 - binary_accuracy: 0.8525\n",
      "Epoch 387/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3312 - binary_accuracy: 0.8527\n",
      "Epoch 388/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3336 - binary_accuracy: 0.8526\n",
      "Epoch 389/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3317 - binary_accuracy: 0.8540\n",
      "Epoch 390/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3328 - binary_accuracy: 0.8531\n",
      "Epoch 391/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8530\n",
      "Epoch 392/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3323 - binary_accuracy: 0.8527\n",
      "Epoch 393/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3323 - binary_accuracy: 0.8535\n",
      "Epoch 394/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3305 - binary_accuracy: 0.8541\n",
      "Epoch 395/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8530\n",
      "Epoch 396/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3327 - binary_accuracy: 0.8535\n",
      "Epoch 397/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3317 - binary_accuracy: 0.8540\n",
      "Epoch 398/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8545\n",
      "Epoch 399/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3314 - binary_accuracy: 0.8530\n",
      "Epoch 400/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3329 - binary_accuracy: 0.8530\n",
      "Epoch 401/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3323 - binary_accuracy: 0.8525\n",
      "Epoch 402/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3319 - binary_accuracy: 0.8532\n",
      "Epoch 403/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3306 - binary_accuracy: 0.8540\n",
      "Epoch 404/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3322 - binary_accuracy: 0.8534\n",
      "Epoch 405/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3312 - binary_accuracy: 0.8533\n",
      "Epoch 406/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3331 - binary_accuracy: 0.8545\n",
      "Epoch 407/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3318 - binary_accuracy: 0.8533\n",
      "Epoch 408/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3326 - binary_accuracy: 0.8534\n",
      "Epoch 409/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8530\n",
      "Epoch 410/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3311 - binary_accuracy: 0.8554\n",
      "Epoch 411/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8537\n",
      "Epoch 412/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3311 - binary_accuracy: 0.8541\n",
      "Epoch 413/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3314 - binary_accuracy: 0.8528\n",
      "Epoch 414/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3317 - binary_accuracy: 0.8533\n",
      "Epoch 415/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3313 - binary_accuracy: 0.8536\n",
      "Epoch 416/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3311 - binary_accuracy: 0.8537\n",
      "Epoch 417/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3313 - binary_accuracy: 0.8539\n",
      "Epoch 418/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3299 - binary_accuracy: 0.8541\n",
      "Epoch 419/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8530\n",
      "Epoch 420/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3310 - binary_accuracy: 0.8533\n",
      "Epoch 421/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3320 - binary_accuracy: 0.8529\n",
      "Epoch 422/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3317 - binary_accuracy: 0.8531\n",
      "Epoch 423/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8548\n",
      "Epoch 424/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3312 - binary_accuracy: 0.8539\n",
      "Epoch 425/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3313 - binary_accuracy: 0.8538\n",
      "Epoch 426/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3314 - binary_accuracy: 0.8542\n",
      "Epoch 427/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3311 - binary_accuracy: 0.8554\n",
      "Epoch 428/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3328 - binary_accuracy: 0.8527\n",
      "Epoch 429/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3307 - binary_accuracy: 0.8553\n",
      "Epoch 430/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8538\n",
      "Epoch 431/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3310 - binary_accuracy: 0.8542\n",
      "Epoch 432/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8539\n",
      "Epoch 433/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3310 - binary_accuracy: 0.8551\n",
      "Epoch 434/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3295 - binary_accuracy: 0.8553\n",
      "Epoch 435/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3305 - binary_accuracy: 0.8548\n",
      "Epoch 436/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8540\n",
      "Epoch 437/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3293 - binary_accuracy: 0.8550\n",
      "Epoch 438/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8544\n",
      "Epoch 439/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8532\n",
      "Epoch 440/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3310 - binary_accuracy: 0.8534\n",
      "Epoch 441/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3314 - binary_accuracy: 0.8544\n",
      "Epoch 442/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3295 - binary_accuracy: 0.8533\n",
      "Epoch 443/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3305 - binary_accuracy: 0.8547\n",
      "Epoch 444/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3318 - binary_accuracy: 0.8541\n",
      "Epoch 445/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3308 - binary_accuracy: 0.8546\n",
      "Epoch 446/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3297 - binary_accuracy: 0.8537\n",
      "Epoch 447/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8538\n",
      "Epoch 448/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3321 - binary_accuracy: 0.8539\n",
      "Epoch 449/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3307 - binary_accuracy: 0.8540\n",
      "Epoch 450/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8538\n",
      "Epoch 451/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8553\n",
      "Epoch 452/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3298 - binary_accuracy: 0.8544\n",
      "Epoch 453/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3299 - binary_accuracy: 0.8554\n",
      "Epoch 454/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3299 - binary_accuracy: 0.8553\n",
      "Epoch 455/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3301 - binary_accuracy: 0.8554\n",
      "Epoch 456/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3300 - binary_accuracy: 0.8545\n",
      "Epoch 457/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3313 - binary_accuracy: 0.8536\n",
      "Epoch 458/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3289 - binary_accuracy: 0.8546\n",
      "Epoch 459/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3303 - binary_accuracy: 0.8542\n",
      "Epoch 460/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8540\n",
      "Epoch 461/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3298 - binary_accuracy: 0.8544\n",
      "Epoch 462/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3296 - binary_accuracy: 0.8549\n",
      "Epoch 463/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3304 - binary_accuracy: 0.8546\n",
      "Epoch 464/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8541\n",
      "Epoch 465/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3300 - binary_accuracy: 0.8550\n",
      "Epoch 466/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3295 - binary_accuracy: 0.8551\n",
      "Epoch 467/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3307 - binary_accuracy: 0.8548\n",
      "Epoch 468/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3309 - binary_accuracy: 0.8548\n",
      "Epoch 469/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3302 - binary_accuracy: 0.8549\n",
      "Epoch 470/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3302 - binary_accuracy: 0.8547\n",
      "Epoch 471/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3292 - binary_accuracy: 0.8558\n",
      "Epoch 472/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3287 - binary_accuracy: 0.8548\n",
      "Epoch 473/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3285 - binary_accuracy: 0.8543\n",
      "Epoch 474/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8548\n",
      "Epoch 475/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8552\n",
      "Epoch 476/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3290 - binary_accuracy: 0.8538\n",
      "Epoch 477/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3298 - binary_accuracy: 0.8550\n",
      "Epoch 478/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3306 - binary_accuracy: 0.8555\n",
      "Epoch 479/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3300 - binary_accuracy: 0.8544\n",
      "Epoch 480/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3289 - binary_accuracy: 0.8550\n",
      "Epoch 481/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3298 - binary_accuracy: 0.8541\n",
      "Epoch 482/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3291 - binary_accuracy: 0.8561\n",
      "Epoch 483/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3293 - binary_accuracy: 0.8539\n",
      "Epoch 484/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3284 - binary_accuracy: 0.8555\n",
      "Epoch 485/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3275 - binary_accuracy: 0.8555\n",
      "Epoch 486/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3295 - binary_accuracy: 0.8553\n",
      "Epoch 487/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3302 - binary_accuracy: 0.8551\n",
      "Epoch 488/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8557\n",
      "Epoch 489/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8549\n",
      "Epoch 490/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3299 - binary_accuracy: 0.8547\n",
      "Epoch 491/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3291 - binary_accuracy: 0.8549\n",
      "Epoch 492/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3293 - binary_accuracy: 0.8539\n",
      "Epoch 493/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3284 - binary_accuracy: 0.8553\n",
      "Epoch 494/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3285 - binary_accuracy: 0.8546\n",
      "Epoch 495/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3294 - binary_accuracy: 0.8547\n",
      "Epoch 496/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3267 - binary_accuracy: 0.8558\n",
      "Epoch 497/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3291 - binary_accuracy: 0.8555\n",
      "Epoch 498/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3274 - binary_accuracy: 0.8560\n",
      "Epoch 499/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8551\n",
      "Epoch 500/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8553\n",
      "Epoch 501/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3273 - binary_accuracy: 0.8552\n",
      "Epoch 502/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3289 - binary_accuracy: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3285 - binary_accuracy: 0.8550\n",
      "Epoch 504/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3285 - binary_accuracy: 0.8552\n",
      "Epoch 505/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8551\n",
      "Epoch 506/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3283 - binary_accuracy: 0.8548\n",
      "Epoch 507/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3274 - binary_accuracy: 0.8565\n",
      "Epoch 508/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3292 - binary_accuracy: 0.8537\n",
      "Epoch 509/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3281 - binary_accuracy: 0.8555\n",
      "Epoch 510/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3289 - binary_accuracy: 0.8548\n",
      "Epoch 511/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3286 - binary_accuracy: 0.8552\n",
      "Epoch 512/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3281 - binary_accuracy: 0.8536\n",
      "Epoch 513/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3278 - binary_accuracy: 0.8556\n",
      "Epoch 514/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3271 - binary_accuracy: 0.8551\n",
      "Epoch 515/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3280 - binary_accuracy: 0.8558\n",
      "Epoch 516/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3284 - binary_accuracy: 0.8555\n",
      "Epoch 517/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3274 - binary_accuracy: 0.8565\n",
      "Epoch 518/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8555\n",
      "Epoch 519/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3294 - binary_accuracy: 0.8550\n",
      "Epoch 520/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3287 - binary_accuracy: 0.8545\n",
      "Epoch 521/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3294 - binary_accuracy: 0.8545\n",
      "Epoch 522/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8549\n",
      "Epoch 523/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3290 - binary_accuracy: 0.8545\n",
      "Epoch 524/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8555\n",
      "Epoch 525/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3283 - binary_accuracy: 0.8547\n",
      "Epoch 526/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3278 - binary_accuracy: 0.8555\n",
      "Epoch 527/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3276 - binary_accuracy: 0.8548\n",
      "Epoch 528/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3295 - binary_accuracy: 0.8553\n",
      "Epoch 529/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3272 - binary_accuracy: 0.8555\n",
      "Epoch 530/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8555\n",
      "Epoch 531/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3297 - binary_accuracy: 0.8550\n",
      "Epoch 532/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3278 - binary_accuracy: 0.8554\n",
      "Epoch 533/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3267 - binary_accuracy: 0.8559\n",
      "Epoch 534/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3275 - binary_accuracy: 0.8555\n",
      "Epoch 535/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3273 - binary_accuracy: 0.8562\n",
      "Epoch 536/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3278 - binary_accuracy: 0.8557\n",
      "Epoch 537/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3283 - binary_accuracy: 0.8548\n",
      "Epoch 538/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3264 - binary_accuracy: 0.8563\n",
      "Epoch 539/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3268 - binary_accuracy: 0.8559\n",
      "Epoch 540/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3291 - binary_accuracy: 0.8553\n",
      "Epoch 541/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3266 - binary_accuracy: 0.8557\n",
      "Epoch 542/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3257 - binary_accuracy: 0.8567\n",
      "Epoch 543/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3271 - binary_accuracy: 0.8563\n",
      "Epoch 544/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3272 - binary_accuracy: 0.8562\n",
      "Epoch 545/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3268 - binary_accuracy: 0.8571\n",
      "Epoch 546/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3282 - binary_accuracy: 0.8553\n",
      "Epoch 547/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3266 - binary_accuracy: 0.8561\n",
      "Epoch 548/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3269 - binary_accuracy: 0.8551\n",
      "Epoch 549/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3272 - binary_accuracy: 0.8566\n",
      "Epoch 550/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3259 - binary_accuracy: 0.8566\n",
      "Epoch 551/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3271 - binary_accuracy: 0.8567\n",
      "Epoch 552/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3272 - binary_accuracy: 0.8554\n",
      "Epoch 553/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3260 - binary_accuracy: 0.8564\n",
      "Epoch 554/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3289 - binary_accuracy: 0.8540\n",
      "Epoch 555/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3268 - binary_accuracy: 0.8566\n",
      "Epoch 556/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3288 - binary_accuracy: 0.8542\n",
      "Epoch 557/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3269 - binary_accuracy: 0.8563\n",
      "Epoch 558/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3260 - binary_accuracy: 0.8562\n",
      "Epoch 559/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3270 - binary_accuracy: 0.8544\n",
      "Epoch 560/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3269 - binary_accuracy: 0.8551\n",
      "Epoch 561/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3270 - binary_accuracy: 0.8560\n",
      "Epoch 562/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3275 - binary_accuracy: 0.8553\n",
      "Epoch 563/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3266 - binary_accuracy: 0.8568\n",
      "Epoch 564/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3274 - binary_accuracy: 0.8558\n",
      "Epoch 565/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3247 - binary_accuracy: 0.8575\n",
      "Epoch 566/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3279 - binary_accuracy: 0.8544\n",
      "Epoch 567/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3275 - binary_accuracy: 0.8557\n",
      "Epoch 568/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3262 - binary_accuracy: 0.8563\n",
      "Epoch 569/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3268 - binary_accuracy: 0.8557\n",
      "Epoch 570/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3250 - binary_accuracy: 0.8561\n",
      "Epoch 571/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3260 - binary_accuracy: 0.8556\n",
      "Epoch 572/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3269 - binary_accuracy: 0.8563\n",
      "Epoch 573/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3261 - binary_accuracy: 0.8562\n",
      "Epoch 574/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3254 - binary_accuracy: 0.8566\n",
      "Epoch 575/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3273 - binary_accuracy: 0.8558\n",
      "Epoch 576/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3277 - binary_accuracy: 0.8548\n",
      "Epoch 577/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3263 - binary_accuracy: 0.8559\n",
      "Epoch 578/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3274 - binary_accuracy: 0.8560\n",
      "Epoch 579/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3270 - binary_accuracy: 0.8548\n",
      "Epoch 580/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3249 - binary_accuracy: 0.8576\n",
      "Epoch 581/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3266 - binary_accuracy: 0.8558\n",
      "Epoch 582/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3259 - binary_accuracy: 0.8565\n",
      "Epoch 583/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3265 - binary_accuracy: 0.8569\n",
      "Epoch 584/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3257 - binary_accuracy: 0.8569\n",
      "Epoch 585/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3264 - binary_accuracy: 0.8569\n",
      "Epoch 586/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3258 - binary_accuracy: 0.8564\n",
      "Epoch 587/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3263 - binary_accuracy: 0.8562\n",
      "Epoch 588/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3259 - binary_accuracy: 0.8559\n",
      "Epoch 589/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3261 - binary_accuracy: 0.8559\n",
      "Epoch 590/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3265 - binary_accuracy: 0.8568\n",
      "Epoch 591/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3258 - binary_accuracy: 0.8557\n",
      "Epoch 592/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3264 - binary_accuracy: 0.8571\n",
      "Epoch 593/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3251 - binary_accuracy: 0.8570\n",
      "Epoch 594/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3264 - binary_accuracy: 0.8563\n",
      "Epoch 595/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3267 - binary_accuracy: 0.8563\n",
      "Epoch 596/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3260 - binary_accuracy: 0.8568\n",
      "Epoch 597/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3248 - binary_accuracy: 0.8569\n",
      "Epoch 598/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3264 - binary_accuracy: 0.8558\n",
      "Epoch 599/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3256 - binary_accuracy: 0.8565\n",
      "Epoch 600/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3277 - binary_accuracy: 0.8551\n",
      "Epoch 601/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3255 - binary_accuracy: 0.8553\n",
      "Epoch 602/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3261 - binary_accuracy: 0.8559\n",
      "Epoch 603/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3249 - binary_accuracy: 0.8565\n",
      "Epoch 604/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3245 - binary_accuracy: 0.8565\n",
      "Epoch 605/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3262 - binary_accuracy: 0.8571\n",
      "Epoch 606/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3253 - binary_accuracy: 0.8562\n",
      "Epoch 607/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3259 - binary_accuracy: 0.8562\n",
      "Epoch 608/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3252 - binary_accuracy: 0.8581\n",
      "Epoch 609/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3250 - binary_accuracy: 0.8561\n",
      "Epoch 610/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3240 - binary_accuracy: 0.8581\n",
      "Epoch 611/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3257 - binary_accuracy: 0.8574\n",
      "Epoch 612/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3256 - binary_accuracy: 0.8570\n",
      "Epoch 613/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3270 - binary_accuracy: 0.8562\n",
      "Epoch 614/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3261 - binary_accuracy: 0.8561\n",
      "Epoch 615/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3236 - binary_accuracy: 0.8577\n",
      "Epoch 616/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3257 - binary_accuracy: 0.8564\n",
      "Epoch 617/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3254 - binary_accuracy: 0.8566\n",
      "Epoch 618/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3255 - binary_accuracy: 0.8570\n",
      "Epoch 619/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3255 - binary_accuracy: 0.8560\n",
      "Epoch 620/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3259 - binary_accuracy: 0.8556\n",
      "Epoch 621/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3257 - binary_accuracy: 0.8561\n",
      "Epoch 622/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3244 - binary_accuracy: 0.8571\n",
      "Epoch 623/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3250 - binary_accuracy: 0.8566\n",
      "Epoch 624/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3245 - binary_accuracy: 0.8572\n",
      "Epoch 625/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3242 - binary_accuracy: 0.8567\n",
      "Epoch 626/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3241 - binary_accuracy: 0.8567\n",
      "Epoch 627/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3263 - binary_accuracy: 0.8561\n",
      "Epoch 628/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3238 - binary_accuracy: 0.8571\n",
      "Epoch 629/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3254 - binary_accuracy: 0.8564\n",
      "Epoch 630/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3251 - binary_accuracy: 0.8561\n",
      "Epoch 631/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3242 - binary_accuracy: 0.8568\n",
      "Epoch 632/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3239 - binary_accuracy: 0.8573\n",
      "Epoch 633/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3241 - binary_accuracy: 0.8568\n",
      "Epoch 634/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3247 - binary_accuracy: 0.8561\n",
      "Epoch 635/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3244 - binary_accuracy: 0.8562\n",
      "Epoch 636/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3249 - binary_accuracy: 0.8562\n",
      "Epoch 637/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3252 - binary_accuracy: 0.8560\n",
      "Epoch 638/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3255 - binary_accuracy: 0.8563\n",
      "Epoch 639/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3246 - binary_accuracy: 0.8570\n",
      "Epoch 640/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3249 - binary_accuracy: 0.8580\n",
      "Epoch 641/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3254 - binary_accuracy: 0.8566\n",
      "Epoch 642/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3237 - binary_accuracy: 0.8580\n",
      "Epoch 643/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3236 - binary_accuracy: 0.8569\n",
      "Epoch 644/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3247 - binary_accuracy: 0.8561\n",
      "Epoch 645/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3237 - binary_accuracy: 0.8573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3239 - binary_accuracy: 0.8568\n",
      "Epoch 647/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3237 - binary_accuracy: 0.8570\n",
      "Epoch 648/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3242 - binary_accuracy: 0.8581\n",
      "Epoch 649/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3256 - binary_accuracy: 0.8571\n",
      "Epoch 650/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3258 - binary_accuracy: 0.8563\n",
      "Epoch 651/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3240 - binary_accuracy: 0.8570\n",
      "Epoch 652/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3244 - binary_accuracy: 0.8574\n",
      "Epoch 653/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3239 - binary_accuracy: 0.8577\n",
      "Epoch 654/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3243 - binary_accuracy: 0.8576\n",
      "Epoch 655/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3248 - binary_accuracy: 0.8573\n",
      "Epoch 656/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3232 - binary_accuracy: 0.8579\n",
      "Epoch 657/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3242 - binary_accuracy: 0.8560\n",
      "Epoch 658/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3250 - binary_accuracy: 0.8573\n",
      "Epoch 659/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3233 - binary_accuracy: 0.8574\n",
      "Epoch 660/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3236 - binary_accuracy: 0.8580\n",
      "Epoch 661/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3230 - binary_accuracy: 0.8575\n",
      "Epoch 662/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3238 - binary_accuracy: 0.8572\n",
      "Epoch 663/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3228 - binary_accuracy: 0.8564\n",
      "Epoch 664/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3238 - binary_accuracy: 0.8565\n",
      "Epoch 665/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3234 - binary_accuracy: 0.8579\n",
      "Epoch 666/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3255 - binary_accuracy: 0.8569\n",
      "Epoch 667/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3253 - binary_accuracy: 0.8564\n",
      "Epoch 668/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3245 - binary_accuracy: 0.8558\n",
      "Epoch 669/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3235 - binary_accuracy: 0.8567\n",
      "Epoch 670/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3237 - binary_accuracy: 0.8572\n",
      "Epoch 671/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3229 - binary_accuracy: 0.8568\n",
      "Epoch 672/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3236 - binary_accuracy: 0.8570A: 0s - loss: 0.3230 - binary_accuracy: 0.857\n",
      "Epoch 673/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3218 - binary_accuracy: 0.8571\n",
      "Epoch 674/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3242 - binary_accuracy: 0.8577\n",
      "Epoch 675/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3225 - binary_accuracy: 0.8576\n",
      "Epoch 676/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3235 - binary_accuracy: 0.8580\n",
      "Epoch 677/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3247 - binary_accuracy: 0.8558\n",
      "Epoch 678/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3238 - binary_accuracy: 0.8578\n",
      "Epoch 679/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3235 - binary_accuracy: 0.8575\n",
      "Epoch 680/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3233 - binary_accuracy: 0.8569\n",
      "Epoch 681/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3237 - binary_accuracy: 0.8554\n",
      "Epoch 682/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3247 - binary_accuracy: 0.8576\n",
      "Epoch 683/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3236 - binary_accuracy: 0.8571\n",
      "Epoch 684/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3221 - binary_accuracy: 0.8582\n",
      "Epoch 685/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3233 - binary_accuracy: 0.8568\n",
      "Epoch 686/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3240 - binary_accuracy: 0.8571\n",
      "Epoch 687/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3222 - binary_accuracy: 0.8574\n",
      "Epoch 688/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3222 - binary_accuracy: 0.8570\n",
      "Epoch 689/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3237 - binary_accuracy: 0.8590\n",
      "Epoch 690/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3230 - binary_accuracy: 0.8581\n",
      "Epoch 691/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3241 - binary_accuracy: 0.8581\n",
      "Epoch 692/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3221 - binary_accuracy: 0.8584\n",
      "Epoch 693/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3237 - binary_accuracy: 0.8582\n",
      "Epoch 694/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3231 - binary_accuracy: 0.8566\n",
      "Epoch 695/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3233 - binary_accuracy: 0.8589\n",
      "Epoch 696/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3225 - binary_accuracy: 0.8574\n",
      "Epoch 697/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3238 - binary_accuracy: 0.8579\n",
      "Epoch 698/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3233 - binary_accuracy: 0.8577\n",
      "Epoch 699/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3238 - binary_accuracy: 0.8566\n",
      "Epoch 700/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3227 - binary_accuracy: 0.8585\n",
      "Epoch 701/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3219 - binary_accuracy: 0.8583\n",
      "Epoch 702/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3228 - binary_accuracy: 0.8578\n",
      "Epoch 703/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3231 - binary_accuracy: 0.8574\n",
      "Epoch 704/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3210 - binary_accuracy: 0.8589\n",
      "Epoch 705/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3238 - binary_accuracy: 0.8572\n",
      "Epoch 706/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3234 - binary_accuracy: 0.8570\n",
      "Epoch 707/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3237 - binary_accuracy: 0.8576\n",
      "Epoch 708/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3227 - binary_accuracy: 0.8582\n",
      "Epoch 709/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3231 - binary_accuracy: 0.8567\n",
      "Epoch 710/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3223 - binary_accuracy: 0.8589\n",
      "Epoch 711/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3227 - binary_accuracy: 0.8581\n",
      "Epoch 712/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3208 - binary_accuracy: 0.8587\n",
      "Epoch 713/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3216 - binary_accuracy: 0.8585\n",
      "Epoch 714/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3225 - binary_accuracy: 0.8578\n",
      "Epoch 715/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3228 - binary_accuracy: 0.8582\n",
      "Epoch 716/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3235 - binary_accuracy: 0.8587\n",
      "Epoch 717/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3217 - binary_accuracy: 0.8573\n",
      "Epoch 718/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3238 - binary_accuracy: 0.8580\n",
      "Epoch 719/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3216 - binary_accuracy: 0.8583\n",
      "Epoch 720/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3235 - binary_accuracy: 0.8578\n",
      "Epoch 721/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3229 - binary_accuracy: 0.8575\n",
      "Epoch 722/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3222 - binary_accuracy: 0.8570\n",
      "Epoch 723/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3224 - binary_accuracy: 0.8581\n",
      "Epoch 724/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3239 - binary_accuracy: 0.8570\n",
      "Epoch 725/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3230 - binary_accuracy: 0.8574\n",
      "Epoch 726/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3208 - binary_accuracy: 0.8596\n",
      "Epoch 727/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3216 - binary_accuracy: 0.8589\n",
      "Epoch 728/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3235 - binary_accuracy: 0.8579\n",
      "Epoch 729/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3212 - binary_accuracy: 0.8580\n",
      "Epoch 730/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3229 - binary_accuracy: 0.8577\n",
      "Epoch 731/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3231 - binary_accuracy: 0.8578\n",
      "Epoch 732/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3226 - binary_accuracy: 0.8579\n",
      "Epoch 733/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3208 - binary_accuracy: 0.8581\n",
      "Epoch 734/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3217 - binary_accuracy: 0.8580\n",
      "Epoch 735/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3232 - binary_accuracy: 0.8578\n",
      "Epoch 736/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3221 - binary_accuracy: 0.8587\n",
      "Epoch 737/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3220 - binary_accuracy: 0.8593\n",
      "Epoch 738/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3225 - binary_accuracy: 0.8574\n",
      "Epoch 739/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3230 - binary_accuracy: 0.8577\n",
      "Epoch 740/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3221 - binary_accuracy: 0.8582\n",
      "Epoch 741/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3212 - binary_accuracy: 0.8588\n",
      "Epoch 742/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3236 - binary_accuracy: 0.8572\n",
      "Epoch 743/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3219 - binary_accuracy: 0.8578\n",
      "Epoch 744/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3219 - binary_accuracy: 0.8577\n",
      "Epoch 745/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3209 - binary_accuracy: 0.8591\n",
      "Epoch 746/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3218 - binary_accuracy: 0.8587\n",
      "Epoch 747/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3221 - binary_accuracy: 0.8575\n",
      "Epoch 748/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3214 - binary_accuracy: 0.8591\n",
      "Epoch 749/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3224 - binary_accuracy: 0.8581\n",
      "Epoch 750/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3218 - binary_accuracy: 0.8587\n",
      "Epoch 751/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3208 - binary_accuracy: 0.8580\n",
      "Epoch 752/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3217 - binary_accuracy: 0.8580\n",
      "Epoch 753/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3217 - binary_accuracy: 0.8589\n",
      "Epoch 754/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3214 - binary_accuracy: 0.8575\n",
      "Epoch 755/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3206 - binary_accuracy: 0.8597\n",
      "Epoch 756/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3217 - binary_accuracy: 0.8583\n",
      "Epoch 757/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3221 - binary_accuracy: 0.8590\n",
      "Epoch 758/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3232 - binary_accuracy: 0.8588\n",
      "Epoch 759/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3239 - binary_accuracy: 0.8581\n",
      "Epoch 760/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3201 - binary_accuracy: 0.8596\n",
      "Epoch 761/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3212 - binary_accuracy: 0.8591\n",
      "Epoch 762/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3217 - binary_accuracy: 0.8578\n",
      "Epoch 763/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3215 - binary_accuracy: 0.8589\n",
      "Epoch 764/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3232 - binary_accuracy: 0.8569\n",
      "Epoch 765/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3207 - binary_accuracy: 0.8585\n",
      "Epoch 766/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3218 - binary_accuracy: 0.8583\n",
      "Epoch 767/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3212 - binary_accuracy: 0.8594\n",
      "Epoch 768/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3211 - binary_accuracy: 0.8593\n",
      "Epoch 769/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3230 - binary_accuracy: 0.8582\n",
      "Epoch 770/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3224 - binary_accuracy: 0.8577\n",
      "Epoch 771/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3216 - binary_accuracy: 0.8595\n",
      "Epoch 772/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3207 - binary_accuracy: 0.8588\n",
      "Epoch 773/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3218 - binary_accuracy: 0.8584\n",
      "Epoch 774/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3207 - binary_accuracy: 0.8593\n",
      "Epoch 775/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3212 - binary_accuracy: 0.8593\n",
      "Epoch 776/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3209 - binary_accuracy: 0.8591\n",
      "Epoch 777/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3204 - binary_accuracy: 0.8596\n",
      "Epoch 778/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3211 - binary_accuracy: 0.8584\n",
      "Epoch 779/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3209 - binary_accuracy: 0.8587\n",
      "Epoch 780/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3223 - binary_accuracy: 0.8590\n",
      "Epoch 781/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3205 - binary_accuracy: 0.8596\n",
      "Epoch 782/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3198 - binary_accuracy: 0.8591\n",
      "Epoch 783/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3204 - binary_accuracy: 0.8585\n",
      "Epoch 784/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3211 - binary_accuracy: 0.8583\n",
      "Epoch 785/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3197 - binary_accuracy: 0.8591\n",
      "Epoch 786/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3217 - binary_accuracy: 0.8584\n",
      "Epoch 787/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3201 - binary_accuracy: 0.8593\n",
      "Epoch 788/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3211 - binary_accuracy: 0.8586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3206 - binary_accuracy: 0.8586\n",
      "Epoch 790/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3186 - binary_accuracy: 0.8598\n",
      "Epoch 791/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3213 - binary_accuracy: 0.8593\n",
      "Epoch 792/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3203 - binary_accuracy: 0.8587\n",
      "Epoch 793/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3216 - binary_accuracy: 0.8583\n",
      "Epoch 794/800\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 0.3227 - binary_accuracy: 0.8574\n",
      "Epoch 795/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3208 - binary_accuracy: 0.8587\n",
      "Epoch 796/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3211 - binary_accuracy: 0.8582\n",
      "Epoch 797/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3190 - binary_accuracy: 0.8607\n",
      "Epoch 798/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3195 - binary_accuracy: 0.8592\n",
      "Epoch 799/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3201 - binary_accuracy: 0.8592\n",
      "Epoch 800/800\n",
      "60000/60000 [==============================] - 0s 2us/step - loss: 0.3207 - binary_accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.hstack((train_x_neu,df2)),  \n",
    "                    train_y, \n",
    "                    epochs=800,\n",
    "                    batch_size=10240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "神经网络预测时drop了非比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_results=model.predict(np.hstack((scaler.transform(test_x),df_p2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6543188 ],\n",
       "       [0.00107792],\n",
       "       [0.00235346],\n",
       "       ...,\n",
       "       [0.15694824],\n",
       "       [0.99873555],\n",
       "       [0.77276313]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission9.17neu_normalized_92feature_model.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in neu_results:\n",
    "        f.write(str(i[0])+\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p= pd.read_csv('./hackathon_datasets/predict/ClaimInfo_Pred.csv') \n",
    "\n",
    "datetime_cols=['report_date','accident_date','policy_effective_date','original_policy_effective_date','policy_expiry_date','birth_date']\n",
    "for i in datetime_cols:\n",
    "    df_p[i]=apply_datetime(df_p[i])\n",
    "\n",
    "df_p['birth_date']=df_p['birth_date'].apply(lambda x:x.year-2000)\n",
    "df_p['time_f1']=(df_p['accident_date']-df_p['report_date']).apply(lambda x:x.days)\n",
    "df_p['time_f2']=(df_p['policy_effective_date']-df_p['report_date']).apply(lambda x:x.days)\n",
    "df_p['time_f3']=(df_p['original_policy_effective_date']-df_p['policy_effective_date']).apply(lambda x:x.days)\n",
    "df_p['time_f4']=(df_p['policy_expiry_date']-df_p['policy_effective_date']).apply(lambda x:x.days)-365\n",
    "df_p=df_p.drop(['report_date','accident_date','policy_effective_date','original_policy_effective_date','policy_expiry_date'],axis=1)\n",
    "df_p=handle_missing(df_p)\n",
    "df_p2=add_ratio(df_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux_p= pd.read_csv('./hackathon_datasets/predict/ClaimBillingInfo_Pred.csv') \n",
    "df_aux2_p= pd.read_csv('./hackathon_datasets/predict/DiseaseInfo_Pred.csv')\n",
    "df_aux3_p= pd.read_csv('./hackathon_datasets/predict/MedicineFeeInfo_Pred.csv')\n",
    "df_aux_p=df_aux_p.merge(df_aux2_p).merge(df_aux3_p)\n",
    "df_aux_p=pd.concat([df_aux_p.groupby(['report_no'])['billing_no'].agg(len),pd.concat([df_aux_p,pd.get_dummies(df_aux_p.charge_type),pd.get_dummies(df_aux_p.billing_type),pd.get_dummies(df_aux_p['100major_disease_flag'],prefix='major100'),pd.get_dummies(df_aux_p.chronic_disease_type,prefix='chronic'),pd.get_dummies(df_aux_p.focus_disease_inpatient_flag,prefix='focus'),pd.get_dummies(df_aux_p.medicine_fee_category)],axis=1).groupby(['report_no']).agg('sum')],axis=1)\n",
    "for i in df_aux.columns:\n",
    "    if i not in df_aux_p.columns:\n",
    "        df_aux_p[i]=0\n",
    "df_aux_p=df_aux_p[df_aux.columns]\n",
    "df_p=df_p.merge(df_aux_p.reset_index(),'outer',on=['report_no']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=df_p.iloc[:,2:]\n",
    "'''\n",
    "test_x_imputed=imp.transform(test_x)\n",
    "test_x=pd.DataFrame(test_x_imputed,columns=train_cols)\n",
    "'''\n",
    "test_x_ohe=ohe.transform(test_x[one_hot_cols].values)\n",
    "test_x=pd.concat([test_x.drop(one_hot_cols,axis=1),pd.DataFrame(test_x_ohe)],axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.49373101e-01, 2.42934461e-05, 6.71576518e-02, ...,\n",
       "       3.60672285e-01, 9.96355786e-01, 8.48187958e-01])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.03592209e-01, 5.37506684e-05, 1.77545329e-02, ...,\n",
       "       2.72812309e-01, 9.94423106e-01, 8.48584979e-01])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(np.hstack((test_x,df_p2)))  # 输出的是概率结果  \n",
    "\n",
    "# 导出结果  \n",
    "threshold = 0.5  \n",
    "results=[]\n",
    "for pred in preds:  \n",
    "    result = 1 if pred >= threshold else 0  \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission9.17_only_lgb_tuned.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in results:\n",
    "        f.write(str(i)+\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8229, 0: 11771})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission9.18_only_xgb_tuned.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in xgb_results:\n",
    "        f.write(str(int(round(i)))+\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6543188 ],\n",
       "       [0.00107792],\n",
       "       [0.00235346],\n",
       "       ...,\n",
       "       [0.15694824],\n",
       "       [0.99873555],\n",
       "       [0.77276313]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.49373101e-01, 2.42934461e-05, 6.71576518e-02, ...,\n",
       "       3.60672285e-01, 9.96355786e-01, 8.48187958e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.7587547e-01, 7.1525358e-04, 2.0423869e-02, ..., 1.9650458e-01,\n",
       "       9.8620439e-01, 5.9757233e-01], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[i[0] for i in neu_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目前配比8：2最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for i,j,k in zip(a,preds,xgb_results):\n",
    "    tmp=0.15*i+0.75*j+0.1*k\n",
    "    result = 1 if tmp >= 0.5 else 0  \n",
    "    lst.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission9.18_mix3_model_t0.5_15751new.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in lst:\n",
    "        f.write(str(i)+\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(xgb_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([round(i),round(j),round(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for i,j,k in zip(a,preds,xgb_results):\n",
    "    tmp=sum([round(i),round(j),round(k)])\n",
    "    result = 1 if tmp >= 2 else 0  \n",
    "    lst.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission9.18_mix3_model_t0.5_vote.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in lst:\n",
    "        f.write(str(i)+\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission8.24.txt',encoding='utf-8',mode='r') as f:\n",
    "    a=f.read().split(',')[:-1]\n",
    "a=[int(i) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for i,j,k in zip(a,b,c):\n",
    "    tmp=0.2*i+0.4*j+0.4*k\n",
    "    lst.append(int(np.round(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission8.25_blending.txt',encoding='utf-8',mode='w') as f:\n",
    "    for i in results:\n",
    "        f.write(str(i)+\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
